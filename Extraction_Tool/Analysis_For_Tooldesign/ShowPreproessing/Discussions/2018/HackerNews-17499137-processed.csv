ID;Source;Creation Date;Content;Sentiment
17499137;HackerNews;2018-07-10;Title:Goodbye Microservices: From 100s of problem children to 1 superstar, Content: https://segment.com/blog/goodbye-microservices/;0

17523513;HackerNews;2018-07-13;you took the words right out of my mouthto summarize it seems like they made some mistakes microed their services in a kneejerk attempt to alleviate the symptoms of the mistakes realized microservices didn't fix their mistakes finally addressed the mistakes then wrote a blog post about microservices.i read the article a few days ago and was struck by what a poor idea it was to take a hundred or so functions that do about the same thing and to break them up into a hundred or so compilation and deployment units.if that's not a microservice antipattern i don't know what is!;0
17518584;HackerNews;2018-07-12;the failure her does seems like someone who have made microservices with the wrong bounded context domain driven design. when one splits a monolith up into microservices it is essential to not split a bounded context into several micoservices or 100 in this case.;0
17512129;HackerNews;2018-07-12;the issue is that it is rare and difficult to be able to synthesize all the changes happening in computing and to go deep. so a certain pop culture of computing develops that is superficial and cliched. we see this in many serious subjects pop psychology pop history pop science pop economics pop nutrition. some of these are better quality than others if they have a strong academic backing but even in areas such as economics we cant get to basic consensus on fundamentals due to the politicization difficulty of reproducible experiment and widespread popular concepts out there that may be wrong.concepts like microservices synthesize a bunch of tradeoffs and patterns that have been worked on for decades. theyre boiled down to an architecture fad but have applicability in many contexts if you understand them.similarly with agile it synthesizes a lot of what we know about planning under uncertainty continuous learning feedback flow etc. but its often repackaged into cliche tepid forms by charlatans to sell consulting deals or scrum black belts.alan kay called this one out in an old interview computing spread out much much faster than educating unsophisticated people can happen. in the last 25 years or so we actually got something like a pop culture similar to what happened when television came on the scene and some of its inventors thought it would be a way of getting shakespeare to the masses. but they forgot that you have to be more sophisticated and have more perspective to understand shakespeare. what television was able to do was to capture people as they were.so i think the lack of a real computer science today and the lack of real software engineering today is partly due to this pop culture.;0
17512051;HackerNews;2018-07-12;no im assuming they must be deployed on an ip network of some sort not necessarily the internet. a microservice by definition is a networked service. the whole reason the term was coined was to differentiate from services which often were developed and deployed monolithically as opposed to truly autonomous runtime processes aka. bounded contexts.services whether soa web services messaging services or network services etc as in soa describe a clientserver architecture with an api. usually these apis are designed by the principles of domain driven design where different teams map to bounded contexts that have their own published api.microservices are a form of soa where each api also runs in its own process and thus has independent deployment lifecycle. many in the soa world advocated for this 1015 years ago and often ignored and now the industry has gone back and coined a term for this practice.in an organization that does microservices properly at scale like amazon you have teams that build and run and upgrade their service autonomously from others. read the steve yegge rant about amazon and platforms to understand this. it allows tremendous parallelisation of effort and allows for thousands of deploys to production daily without breakage. this is hard to pull off though and a new initiative doesnt generally wont more than a small handful of services.if its a shared library then call it a shared library. it has a completely different lifecycle from a microservice. in your android example shared libraries by definition are controlled by whomever can dictate os updates not the app developer.;0
17510041;HackerNews;2018-07-11;iverification on the system boundaries means running the app not running a unit testiwhat is an app at the system boundaries if not a piece of code with dependencies?if you have a microservice fooservice that calls barservice. the system boundary you are trying to test is fooservice using a fake barservice. i'm assuming that you're calling fooservice via http using a test runner like newman and test results.in a monolithic application you have class foomodule that depends on barmodule that implements ibarmodule. in your production application you use create foomodulevar x foomodulenew barmoduley x.baz5in your unit tests you create your foomodulelvar x foomodulenew fakebarmodule actual x.baz5 assert.areequal10actualand run your tests with a runner like nunit.there is no functional difference.of course foomodule can be at whatever level of the stack you are trying to test even the controller.;0
17508513;HackerNews;2018-07-11;a huge point of frustration was that a single broken test caused tests to fail across all destinations. when we wanted to deploy a change we had to spend time fixing the broken test even if the changes had nothing to do with the initial change. in response to this problem it was decided to break out the code for each destination into their own reposwe went through this painful period. kept at it devoting a rotating pair to proactively address issues. eventually it stabilized but the real solution was to better decouple services and have them perform with more 9s of reliable latency. microservices are hard when done improperly and there doesn't seem to be a short path to learning how to make them with good boundaries and low coupling.;0
17508286;HackerNews;2018-07-11;how much of the code was shared among these services? it sounds like you essentially had mostly the same code running in 140 different configurations with only some translation logic and glue varying between each. i'm not surprised you found this untenable. this is akin to running a microservice per web page.;0
17507991;HackerNews;2018-07-11;microservices are a great tool for the toolbox. not everybody needs them. it has definitely seemed like a fad over the past few years to push everybody to use them even projects or orgs that don't need them. i suspect that is what happened here;0
17507741;HackerNews;2018-07-11;first of all i'm 54 and started coding at 15 on punch cards so i've seen pretty much every paradigm in the last 40 years.it's certainly a truism that technology can be cyclical but that's not relevant in this case.the op's statement and article goodbye microservices is anecdotal and incorrect.i have been on teams developing microservice architectures for about six years and this particular paradigm shift has proven to be a dramatic leap forward in efficiency especially between the business technical architecture and change control management.when you develop a domain model the business can ask questions about the model. the architects can answer them by modifying the model. the developers can improve services by adopting model changes in code. this is the fundamental benefit of domain driven design and works fluidly with a microservice architecture.there's still a pervasive belief in technology circles that software should be developed from a purely technical perspective. this is like saying the plumber electrician and drywaller should design a house while they're building it. they certainly have the expertise to build a house and they may actually succeed for a time but eventually the homeowner will want to change something and the ad hoc design of the house just won't allow for it. this is why we have architects. they plan for change within the structure of a house. they enable modification and addition.software development is no different. the segment developers have good intentions but they needed to work with the business to properly model everything then build it. granted it sounds like they're a fast moving and successful business so there are tradeoffs. but once the business settles they really should go back to the drawing board model the business then build segment 3.0.;0
17507668;HackerNews;2018-07-11;lots of people judgingbashing the author and team that they made bad choices jumpinng on the microservice bandwagon when it clearly wasn't the correct thing to do.sure but at the same time the team learned some valuable lessons gained experience and hopefully matured. i applaud alexandra for opening up and sharing that with us.;0
17507615;HackerNews;2018-07-11;thanks for sharing this video.when she's discussing compensations she mentions that the transaction ti can't have an input dependency on ti1. what are some things i should be thinking about when i have hard ordered dependencies between microservice tasks? for example microservice 2 m2 requires output from m1 so the final ordering would be something like m1 m2 m1.currently i'm using a highlevel coordinating service to accomplish these longrunning async tasks with each m just sending messages to the toplevel coordinator. i'd like to switch to a better pattern though as i scale out services.;0
17507223;HackerNews;2018-07-11;i kind of get what systemizer is saying. people may think of evolution of technologies as cycles but it is never that. a new technology 'y' is always developed because the incumbent 'x' has some shortcomings. and even after a period of disillusionment when we revert back to 'x' it is not always the same. we synthesize the good points of 'y' back to 'x'.coming to this topic i see microservices as a solution to the problem of continuous delivery which is necessary in some business models. i can't see those use cases reverting back to monolith architecture. for such scenarios the problems associated with microservices are engineering challenges and not avoidable architecture choices.;0
17507201;HackerNews;2018-07-11;ugh. sounds like a severe case of resumedriven architecture.in my experience you won't know whether you need microservices until you're on at least v2.0 of your application. by then you have a better understanding of what your real problems are.;0
17507180;HackerNews;2018-07-11;that's basically how microservices are operated on orchestrators like kubernetesjust substitute container for vm which is a mostlyacademic difference from the perspective of your application. operations toolingdistributed tracing monitoring logging...is essential.;0
17507176;HackerNews;2018-07-11;i think you are exactly right. microservice architectures are definitely not automatically good and there is nothing wrong with a well architected monolith.;0
17507112;HackerNews;2018-07-11;ive seen the hype swing from micro services to soa and back to micro services a few times already.soa and microservices are the same thing microservices is just a new name coined when the principles were repopularized so that it didn't sound like a crusty old thing.;0
17507084;HackerNews;2018-07-11;it's much easier to process the test output and debug the microservices than monolithic applications.you easier to debug endtoend tests of a microservice architecture that monolith? that's not my experience. how do you manage to put side by side all the events when they are in dozen of files?;0
17507027;HackerNews;2018-07-11;ii am a strong believer that microservices is over hyped.iin general i fully concur there are very few services that actually warrant a microservice architecture.;0
17507011;HackerNews;2018-07-11;a model checker is a software program you use to validate a given mathematical model of a system. if the proposed properties of the model hold the model checker will let you know. more interestingly if the properties fail to hold you'll get a trace back into where your assumptions fell apart.tla is one such system that includes a language for writing models and a model checker to verify them for you. in the context of microservices you would write a model of your services and the checker would help you to verify that certain properties of your model will hold for all possible executions of the model. properties people seem to be interested in are consistency and transaction isolation. you can develop a model of your proposed microservices architecture and work out the errors in your design before you even write a lick of code.or if you already have a microservice system you could write a model of it and find if there are flaws in its design causing those annoying error reports.amazon wrote a paper about how they use it within the aws team 0. highly worth the read. and if any of this sounds interesting i suggest checking out hillel wayne's course he's building 1.0 1;0
17506945;HackerNews;2018-07-11;i have tests which verify dna analysis. the test data vectors are large a few hundred mb here a couple gb there. the hundreds of tests that use these test vectors still run in a few seconds.if you're using a tape drive or sd cards sure. but even a 10 year old 5400rpm on an ide connection should be able to satisfy your tests' requirements in a few seconds or less.i suspect your tests are just as monolithic as you think microservices shouldn't be. break them down into smaller pieces. if it's hard to do that then redesign your software to be more easily testable. learn when and how to provide static data with abstractions that don't let your software know that the data is static. or if you're too busy then hire a dedicated test engineer. no not the manual testing kind of engineer. the kind of engineer who actually writes tests all day has written thousands or hundreds of thousands of individual tests during their career. and listen to them about any sort of design decisions.;0
17506451;HackerNews;2018-07-11;sounds like a typical case of hype driven development. when faced with a problem they threw buzzwords at it hoping it would go away.had they taken the time to explore the root causes of these problems and how to best approach them they probably wouldnt have taken the microservices approach to begin with.i see this far too often. instead of looking for solutions to problems people look for problems to try the new hot solution they read about. happened with mlai nosql microservices blockchain;0
17506376;HackerNews;2018-07-11;all of these things you mentioned are either also required for a monolith like dnsdhcp or are required for neither isolated environments.does that mean that because of all the work required to properly set those up for a monolith we better stay with microservices?;0
17506246;HackerNews;2018-07-11;i am a strong believer that microservices is over hyped. i usually resist when senior management asks for us to use it that proves the point of hype.but by reading the first paragraphs of the article you see that the guys from segment made a series of grave mistakes on their microservices architecture the most important one being the use of a shared library on many services. the goal of microservices is to achieve isolation and sharing components with specific business rules between them not only defeats the purpose but results in increased headaches.without deep knowledge of the solution it's hard to judge but it seems this was never the case for microservices. they needed infrastructure isolation when the first delay issues surfaced but there wasn't anything driving splitting the code up.sam newman discusses on his book how to find the proper seams to split services ddd aggregates being the most common answer and it seems to people are making rather arbitrary decisions.;0
17506213;HackerNews;2018-07-11;i remember using bea tuxedo 15 years ago and i can't help wondering if theoretically one could do microservices using it or some oltp to achieve consistency when needed. has it progressed over the years? is there any free alternative to it? or is it dead tech? when i used it it was hard and too much extra work but it did the job successfully.;0
17506161;HackerNews;2018-07-11;i've worked with microservices a lot. it's a neverending nightmare. you push data consistency concerns out of the database and between service boundaries.this exactly. me too. data consistency concerns in sufficiently large real world projects can be practically dealt with only 2 ways imo transactions or spec changes.;0
17506117;HackerNews;2018-07-11;i was too of course a distributed system could also be built with dcom and mtc later com and the dtc distributed transaction coordinator could be used when you needed a transaction across services or dbs or mqs. obviously the dtc was developed in recognition of the fact that distributed transactional service calls were a real requirement something that current microservice architectures over http rest don't seem to support.;0
17506075;HackerNews;2018-07-11;it will be interesting to read your post in a few months time when you hit the issues caused by using a monolith which could be resolved by splitting that service apart.introducing components to match on various forms of value seems odd. ideally standardise on those names but if that's not possible and you're using microservices why not have a service to correct the name rather than a library deployed to every endpoint? then you call that service with data containing firstname or givenname and it returns that message with the standardised form. or have a global key service where you send the source system name and value and have that translated for the destination via a lookup allowing any field names or defined values to be translated by a generic reusable component as for handcrafted xml... the alternative looks like handcrafted code... for translation a language like xslt which was designed for translating data from one format to another seems like a good choice. you can also use this to get around your translation issue by defining a central universal format so you can have xslts to translate messages from source systems to the universal format then other xslts to translate from universal to the destination so that adding or removing a system service only impacts that system you don't need to rewrite every pointtopoint interaction of that service with another ok not point to point since we have microservices but if they're not adding value by abstracting you away from point to point then essentially you've just got complex pointtopoint interactions rather than simple pointtopoint.;0
17505922;HackerNews;2018-07-11;the whole thing is released and deployed together which is the usual distinction between microservices and not. i don't think anyone's advocating not using modules and folders to structure your code in your repository certainly i hope not but a single deployment artifact makes life a lot easier.;0
17505910;HackerNews;2018-07-11;the big problems with microservices come from distributed transactions being difficult and clocks getting out of sync. multiple services on a single machine don't have that problem.;0
17505882;HackerNews;2018-07-11;you avoid them. you design your system a set of microservices in such a way that you don't need a transaction across service boundaries or rather database boundaries;0
17505807;HackerNews;2018-07-11;microservices are damn hard to implement correctly. think how much math and algorithms must there be to correctly test version your model and api load balance gather logs collect logs archive logs grep in logs setup vmsdockers dnsdhcp and firewalls load balance databases masterslaves? and your services horizontal scaling maybe? manage privileges and access manage disk space store and collect useruploadedgenerated files isolate environments...if you don't understand these concepts and how much work must be don't to correctly implement microservice architecture you should stay with monoliths they are much easier.;0
17505651;HackerNews;2018-07-11;oh man this is just the tip of the iceberg with microservices. there is nothing micro about them they are so difficult to deal with that it becomes impossible to actually iterate or build user value and introduces loads of difficult to debug problems.we have architects here that dictate the design of the system but imo they have not done the simplest implementation of anything. we have kafka to provide ways of making each service eventually consistent so we delete something out of our domain service but it requires absolutely huge amounts of code in various different other services to delete things in each place listening for events. every feature is split across n different services which means n times more work n times more difficult to debug n times more difficult to deploy.the system has been designed with buzzwords in mind go and grpc have been a disaster in terms of how quickly people have developed software as has concourse so many man hours wasted trying to run our own ci infrastructure it's unreal loads of small services that are individually difficult to deploy and configure and come with scary defaults like shared secret keys for auth use a dev jwt on prod for example. the difficulty in dealing with debugging the system there simply aren't the tools to understand what is going wrong or why you have to build dashboards yourself and make your application resilient to services not existing.never ever try to build microservices before you know what your customers ireallyi want we've spent the last 6 months building a really buggy crud app that doesn't even have c and d fully yet. love your monolith.;0
17505610;HackerNews;2018-07-11;you may also want to look into the saga pattern i found to be a handy high level overview for applying it to microservices.although personally i've never felt the need to try and apply it specifically but the idea is interesting.;0
17505538;HackerNews;2018-07-11;i wonder if microservices will have a similar evolution as microkernels. while some microkernels almost closed the performance gap to monolith kernels the communication overhead killed them. it turned out that the kernel's complexity could be reduced by moving some functions to the applications library os. linux kernel drivers are only accepted when the functionality can't be done in user space. the extreme version is running single purpose highly specialized unikernels on a hypervisor.;0
17505459;HackerNews;2018-07-11;this isnt an article about how microservices architecture is somehow bad its an article about how bad segments engineering team is.wow. this is the level of discourse we've reached here now.why the ad hominem? if you have an actual point to make on technical merit by all means make it. were you passed on in a job interview at segment? why the hostility? honest question;0
17505440;HackerNews;2018-07-11;can't wait to write sane monolith with libraries instead of microservices.;0
17505262;HackerNews;2018-07-11;interesting perspective. i think that seeking and naming patterns microservices agile etc. is useful. it provides something like a domain specific language that allows a higher level conversation to take place.the problem as your identify is that once a pattern has been identified people too easily line up behind it and denigrate the contrasting pattern. the abstraction becomes opaque. we're used to simplistic narratives of good vs evil my team vs your team etc. and our tendency to embrace these narratives leads to dumb pointless conversations driven more be ideology than any desire to find truth.;0
17505238;HackerNews;2018-07-11;what exactly are you trying to accomplish? good test must verify the contract on the system boundaries in case of the api it's verification done by calling the api. we are discussing two options here integrated application hosting multiple apis and microservice architecture. verification on the system boundaries means running the app not running a unit test unit tests are good but serve different purpose. feature flags make it only worse because testing with them covers only nonproduction branches of your code. your initial assumptions were incorrect. with nearly 20 years of engineering and management experience i know very well how modern testing is done.;0
17505205;HackerNews;2018-07-11;it is weird that they took on some problems so easy. shared libraries is one point. to get them right for hundreds slightly different services is something i don't even want to think about. the only strategy i can come up with is to maintain them as if they're a 3rd party lib and cannot contain business logic. so you're forced to build solutions around them and not with them.then there have been quite a few warnings to not use shared code in microservices.;0
17505131;HackerNews;2018-07-11;as a microservice agnostic i wonder how you can deal elegantly with transactions across services concurrent access amp locks etc. disclaimer i have not read the article yet;0
17505111;HackerNews;2018-07-11;another article with the tldr similar to we jumped blindly on the bandwagon did obvious mistakes along the way and microservices are the root of all evil.thanks but no thanks.;0
17505040;HackerNews;2018-07-11;it's hard to do right.this is correct i'd argue doing microservices right is even harder than doing a monolith right like keeping the code base clean.;0
17505000;HackerNews;2018-07-11;ive been tracking the comments and my sense is that almost no one here believes the business domain drives the technical solution.microservices when constructed from a welldesigned model provides a level of agility ive never seen in 33 years of software development. it also walls off change control between domains.my take from the segment article is that they never modeled their business and just put services together using their best judgment on the fly.thats the core reason for doing domain driven design. when you have a highly complex system you should be focused on properly modeling your business. then test this against ux reporting and throughput and build after youve identified the proper model.as for databases there are complexities. some microservices can be backed by a keyvalue store at a significantly lower cost but some highthroughput services require a 12cylinder relational database engine. the data store should match the needs of the service.one complexity of microservices ive seen is when realtime reporting is a requirement. this is the one thing that would make me balk at how i construct a service oriented architecture.see eric evans book and vaughn vernons follow up.;0
17504993;HackerNews;2018-07-11;going back from 100 microservice to 1 monolith is another extreme to me...perhaps you can have 10 macroservices.and shared library shouldn't contain business logic...;0
17504980;HackerNews;2018-07-11;ito summarize it seems like they made some mistakes microed their services in a kneejerk attempt to alleviate the symptoms of the mistakes realized microservices didn't fix their mistakes finally addressed the mistakes then wrote a blog post about microservices.iyou try to remove the critique from microservices but for me these issues are actually good arguments against microservices. it's hard to do right.;0
17504950;HackerNews;2018-07-11;it looks to me that the shared library issue got solved by the monorepo approach. they could have gone the monorepo way and still have microservices. managing a lot of repos and keeping them consistent with regards do dependencies is not easy. in reality you do not want everyone to use a different version of a dependency. you might allow deviations but ultimately you wand to minimize them.they also just might have had too many repos.;0
17504811;HackerNews;2018-07-11;this is a common pattern when it come to semiidealistic memes like microservices or agile. i think it's a bad idea to have such hairy abstract ideas travel too far and wide.they become a bucket of clichés and abstract terms. clichéd descriptions of problems you're encountering like deployments being hard. clichéd descriptions of the solutions. this let's everyone in on the debate whether they actually understand anything real to a useful degree or not. it's a lot easier to have opinions about something using agile or microservice standard terms than using your own words. i've seen heated debates between people who would not be able to articulate any part of the debate without these clichés they have no idea what they are actually debating.for a case in point if this article described architecture a b amp c without mentioning microservices monoliths and their associated terms... 1 ifari fewer people would have read it or had an opinion about it. 2 the people who do will be the ones that actually had similar experiences and can relate or disagree in their own wordsthoughts.what makes these quasiiideologicali in my view is how things are contrasted generally dichotomously. agile vs waterfall. microservices vs monolithic architecture. this mentally limits the field of possibilities of thought.so sure it's very possible that architecture style iswas totally besides the point. dropping the labels of microservices architecture frees you up to 1 think in your own terms and 2 focus on the problems themselves not the clichéd abstract version of the problem.basically microservice architecture can be great. agile hr policies can be fine. just... don't call them that and don't read past the first few paragraphs.;0
17504729;HackerNews;2018-07-11;you are assuming that microservices must be deployed on the internet however they can be deployed on another type of network or on a single os installation which would prevent them from being completely transparently updated.shared libraries can be an implementation of micro services. on a platform e.g. android it can be that a shared library is updated and then all consumers are forced to update.;0
17504682;HackerNews;2018-07-11;the disadvantage is obviously that creating such's a 'perfect architecture' is hard to do because of different concerns by different parties within the companyorganisation.i think you get at two very good points. one is that realistically you will never have enough time to actually get it really right. the other is that once you take realworld tradeoffs into account you'll have to make compromises that make things messier.but i'd respond that most organizations i see leave a lot of room for improvement on the table before timetradeoff limitations really become the limiting factor. i've seen architects unable to resolve arguments engineers getting distracted by sexy technologiesmethodologies microservices bad requirements gathering business team originated feature thrashing technical decisions with obvious anticipated problems...;0
17504561;HackerNews;2018-07-11;iit seems like they made some mistakes microed their services in a kneejerk attempt to alleviate the symptoms of the mistakes realized microservices didn't fix their mistakes finally addressed the mistakes then wrote a blog post about microservices.ithat seems... appropriate?this is the general problem with the microservices bandwagon most of the people touting it have no idea when or why it's appropriate. i once had a newly hired director of engineering two weeks into a very complicated codebase which he spent nearly zero time looking at ask me hey there's products here! how about a products microservice? he was an idiot that didn't last another two months but not before i and the rest of the senior eng staff quit.i'm fully prepared to upvote more stories with the outline of imicroservices were sold as the answer! but they weren't.i;0
17504506;HackerNews;2018-07-11;i imagine that your development velocity with this monolith is enabled by the modularity of your code that was enforced as microservices. this benefit will wane and if you had started with a monolith would be much worse.;0
17504453;HackerNews;2018-07-11;what do you mean by model checking? usually anything with the keyword design like design patterns for microservices have no science or mathematics to back it up.;0
17504357;HackerNews;2018-07-11;it seems like splitting into separate repos was a rash response to lowvalue automated tests. if tests don't actually increase confidence in the correctness of the code they're negative value. maybe they should have deleted or rewritten a bunch of tests instead. which is what they did in the end anyway. a huge point of frustration was that a single broken test caused tests to fail across all destinations. when we wanted to deploy a change we had to spend time fixing the broken test even if the changes had nothing to do with the initial change. in response to this problem it was decided to break out the code for each destination into their own reposthey also introduced tech debt and did not responsibly address it. the result was entirely predictable and they ended up paying back this debt anyway when they switched back to a monorepo. when pressed for time engineers would only include the updated versions of these libraries on a single destinations codebase... eventually all of them were using different versions of these shared libraries.to summarize it seems like they made some mistakes microed their services in a kneejerk attempt to alleviate the symptoms of the mistakes realized microservices didn't fix their mistakes finally addressed the mistakes then wrote a blog post about microservices.;0
17504319;HackerNews;2018-07-11;youre oversimplifying.architecturally speaking there are some similarities between micro services and libraries because theyre both forms of modularization and usually have an api but there are some stark differences beyond the dispatch mechanism.the main difference is that a services deployment lifecycle is completely up to the service admin. microservices are like websites they can continuously evolve within their apis contract without asking permission from consumers. this is their main superpower and why theyre a way of scaling a development organization without slowing it down too much.in the case of a shared library its completely up to the host admin as to when to upgrade. in the case of a static library its up to the consuming software to determine when to upgrade. a service can upgrade when it feels like it.issues of api backwards compatibility forwards compatibility extensibility self descriptiveness versioning etc. are old issues but usually have different answers when upgrades are truly happening all the time and not just in theory. it tends towards much fewer hard versions and more evolutionary backwards compatibility.iow microservices arent a cure all but they do encourage a set of behaviors. many articles detracting from them seem to have not wanted those behaviors in their org in the first place.;0
17504289;HackerNews;2018-07-11;it appears to me that this isn't so much a case of microservices don't work as it is the case of several poor architectural choices. it is always really easy to be part of the crowd in the peanut gallery and say hah you are doing it wrong but when actually at the coalface the pressures and perspectives are different. having said that the microservices story isn't half as interesting as the centrifuge story they link to in the article. their approach queues for everything didn't work for them at their scale so they invented something different centrifuge that does. poorly thoughtout choices around microservices has little to do with the issue they solved.;0
17504220;HackerNews;2018-07-11;it seems like their initial problems were1. tests hitting 3rd party apis are flakey amp slow 2. the job queuing mechanism can cause all jobs to be slowed by a single 3rd party api outageslowdowneventually they arrived at1. replay responses to speed up http based tests 2. create a smarter queuing mechanism in housei'm not sure what microservices has to do with any of this. anyway kudos to them for having the courage openness to share their learning from mistakes!;0
17504211;HackerNews;2018-07-11;it took me longer than it probably should have to realize that the term imicroservicesi was made by analogy to the term imicrokerneli. i think that part of my main issue with the microservices is that it conflates highly technical semantics with word forms that are a bit more wishy washy in meaning i.e. a service is something formed more of human perception not rooted directly in operating system abstractions.;0
17503970;HackerNews;2018-07-11;glad you think so too.the title and opening paragraphs gave me the impression they felt they were moving away from microservices but maybe i didn't those bits correctly.;0
17503604;HackerNews;2018-07-11;3 full time engineers. no wonder they crashed and burned with microservices. even a slightly distributed system what i call miniservices with an api and login server and half a dozen regular apps on top is way too much for such a small team. in a similar but much smaller setup i estimate at one point our two person team was spending as much as 25 of their time on crossservice between the app and api login server concerns that would simply not exist with a monolith or something not distributed. that's 3 months out of every year of development time wasted on concerns that shouldn't even exist.;0
17503522;HackerNews;2018-07-11;the practices of doctors are based off of science and theory. design patterns and microservices while technical are not based off of science. they are ideas without quantitiative basis or science.;0
17503500;HackerNews;2018-07-11;from an architectural perspective there is absolutely no difference between a micro service and a library. the only real difference is in the dispatch mechanism.i always tell people if you can't write and maintain a library then don't do microservices.;0
17503441;HackerNews;2018-07-11;microservices do have various organizational tradeoffs. individual teams can now own deployment operation language and tooling choices for better or worse. this is probably advantageous for large companies where the number of teams scales beyond what a hierarchical control structure can support. in other words a single devops team can't make good decisions and prescriptions about languages tooling deployment etc nor effectively react to feedback from the dev teams. control power and responsibility becomes distributed instead of centralized with all the tradeoffs that entails.;0
17503317;HackerNews;2018-07-11;iwith separate microservices and databases you could just pause that microservice. with one application and one database all teams need to be aware of the highest sla requirements when doing their respective deployments and design for it. it is certainly doable but requires a higher level of alignment between the development teams.ithats easily accomplished with a bluegreen deployment. as far as the database youre going to usually have a replication set up anyway. so your data is going to live in multiple databases anyway.once you are comfortable that your blue environment is good you can slowly start moving traffic over. i know you can gradually move x of traffic every y hours with aws. i am assuming on prem load balancers can do something similar.;0
17503295;HackerNews;2018-07-11;i saw this at my last company. even worse breaking it into microservices allowed teams of 2 or 3 to start building entire realms where only they could commit and used it for internal politics.i witnessed someone that wanted to leverage their service into a promotion so they started pushing for an architecture where everything flowed through their service.it was the slowest part of our stack and capped at 10tps.;0
17503189;HackerNews;2018-07-11;segment is very much built around microservices. they just consolidated 100 of these destination services into a single one. that's it.;0
17503045;HackerNews;2018-07-11;what this actually looks like is a case of very imperfect knowledge transfer within the technology industry. what's interesting about the entire craze of microservices and containers and the cloud is that they are not a new technology. this entire architecture the socalled lambda architecture has been the standard approach to developing highperformance trading systems on wall st. since the early 90s. the architecture is literally 30 years old and certain technologies event sourcing event driven architecture are even older.the problem is that the all the best knowledge has clearly not made it out. for example this design introduces a centrifuge process that redirects requests to destination specific queues... congratulations you've just reinvented a message bus a technology that goes back to the 80s. there is absolutely nothing new about virtual queues as described here but unfortunately the authors are likely not at all aware of the capabilities of real enterprise messaging systems even free opensource ones like apache artemis and certainly not aware of the architecture and technologies and algorithms that underlie them and the admittedly much more expensive bestofbreed commercial systems.i won't even go into the craziness of 50 repos. that's just pure cargo cult madness.watching the webjavascript reinvent these 30 year old technologies is a little disheartening but who knows they may come up with something new. then again recently the javascript guys have discovered the enormous value of repeatable builds. unfortunately the implementations here all pretty much suck. still we ought to perhaps ask ourselves why this situation has come about...;0
17503032;HackerNews;2018-07-11;microservices benefits large teams. theres just too much operational overhead for a small team to manage microservices. large teams with monolith applications benefit from microservices as the communication issue of large teams is reduced by splitting the team into cross functional teams.;0
17502950;HackerNews;2018-07-11;i must agree. seems like every step could have been solved without jumping to the conclusion that it was because we didn't use a monolith.i've never understood the false dichotomy of microservices vs monolith... just split things when it makes sense. ¯ツ¯;0
17502882;HackerNews;2018-07-11;its easier to just press a button and have your application go to all of your servers based on a deployment group.it's not so much about the deployment process itself i agree with you that this can be easily automated but rather about the deployment granularity. in a large system your features provided by either components or by independent microservices usually have very different slas. for example credit card transactions need to work 24x7 but generating the monthly account statement for these credit cards is not timecritical. now suppose one of the changes in a less critical component requires a database migration which will take a minute. with separate microservices and databases you could just pause that microservice. with one application and one database all teams need to be aware of the highest sla requirements when doing their respective deployments and design for it. it is certainly doable but requires a higher level of alignment between the development teams.i agree with your remark about refactoring. in addition when doing a refactoring in a microservice you always need a migration strategy because you can't switch all your microservices to the refactored version at once.;0
17502843;HackerNews;2018-07-11;i don't think you reverted to a monolith. i think you built a singular service with more cohesion than when it was split into 140 repos. and it sounds like the split wasn't because of the microservices architecture but because you didn't have a good solution for the queue problem.;0
17502840;HackerNews;2018-07-11;it seems like splitting off small repos for everything is a solution looking for a problem. some of the most successful software companies out there have monolithic repos but not monolithic services.the real solution is microservices in monorepos.;0
17502829;HackerNews;2018-07-11;i've heard of even unicorns throwing consistency out the window. apparently netflix has a bunch of cleanup jobs that comb the database for various inconsistencies that inevitably show up.you can't have consistent microservices without distributed transactions. if a service gets called and inside that call it calls 3 others you need to have a roll back mechanism that handles any of them failing in any order.if you write to the first service and the second two fail you need to write a second undo call to keep consistent.worse this undo state needs to be kept transactionally consistent in case it's your service that dies after the first call.in reality nobody does this so they're always one service crash away from the whole system corrupting the hell out of itself. since the state is distributed good luck making everything right again.microservices are insane. nobody that knows database concepts well should go near them;0
17502767;HackerNews;2018-07-11;my problem with imicroservicesi is the word 'micro'. it should just be iservicesi.problem domains along with organizational structures inherently create natural architectural boundaries... certain bits of data computation transactional logic and programming skill just naturally clump together. imicroiservices ignore this natural order. the main driving architectural principle seems to be i'm having trouble with my eventdriven dynamicallytyped metaprogrammed ballofmud so we need more services!.;0
17502762;HackerNews;2018-07-11;the shared libraries made building new destinations quick. the familiarity brought by a uniform set of shared functionality made maintenance less of a headache. however a new problem began to arise. testing and deploying changes to these shared libraries impacted all of our destinations. it began to require considerable time and effort to maintain. making changes to improve our libraries knowing wed have to test and deploy dozens of services was a risky proposition. when pressed for time engineers would only include the updated versions of these libraries on a single destinations codebase.iwhen pressed for time engineers would only include the updated versions of these libraries on a single destinations codebase.ii think i see the problem and it wasn't with microservices.;0
17502682;HackerNews;2018-07-11;this might come off as being snide but i'm genuinely curious was their solution really just having all the services in one repository? that doesn't seem like a problem with microservices at all but more of a devops problem. to be clear i'm not arguing for microservices i'm just trying to understand if this was really a problem with splitting off multiple repos. maybe i'm just really dense and someone can set me straight.i've actually had experiences with seemingly this same problem at a previous startup. once we started spinning off individual repositories for small pieces of business logic stuff started to go downhill as the logistics of communicating and sharing one another's code became more and more complex.;0
17502648;HackerNews;2018-07-11;been there. otoh my last job was at a startup that used a lamp stack but made enough money to be selfsufficient and not depend on vc money to keep running.when the legacy systems started to hurt us because they were written by the founder in a couple of weeks in the most hacky way we decided against microservices and went to improve the actual code into something more performing and more maintenablealso moving from php5 to php7.as much as we all wanted to go microservices and follow the buzz we were rational enough to see that it didn't make any sense in our case.;0
17502644;HackerNews;2018-07-11;recall that the original motivation for separating each destination codebase into its own repo was to isolate test failures. however it turned out this was a false advantage. at least they finally got to the right conclusion they were on the wrong path to begin with.people seem to be blaming microservices when they werent even close to understanding what they were doing and why. id be much more interested in an article about issues faced with microservices where they actually tried to slice their functionality based on their domain.;0
17502633;HackerNews;2018-07-11;if you're using microservices why are you using shared libraries? wouldn't it make sense to break the common portion into a separate service and define an api for it?i swear more people writing microservices need to read about flowbased programming and perhaps the actor model.;0
17502549;HackerNews;2018-07-10;see the below response for more details. but thats not how modern testing works neither is my feature flag suggestion. it works similarly in almost every language.ifor a certain class of applications and organizational constraints i also would prefer it. but it requires a much tighter alignment of implementation than microservices e.g. you can't just release a new version of a component you always have to release the whole application.iwhy is that an issue with modern cicd tools? its easier to just press a button and have your application go to all of your servers based on a deployment group.with a monolith with a statically typed language refactoring becomes a whole lot easier. you can easily tell which classes are being used do globally guaranteed safe renames and when your refactoring breaks something you know st compile time or with the correct tooling even before you compile.;0
17502494;HackerNews;2018-07-10;i found the frustrations with microservices too setting up a pretty substantial etl system using amazon lambda among other services.originally you couldn't trigger lambda functions from sqs seemingly the most obvious integration. you could use kinesis but small print says lambda concurrency is restricted to the kinesis streams which gets very expensive.visibilitymonitoring into most microservices is not good iron.io is quite nice but any concurrency is really expensive. i don't like the workflow for deployment and testing either.so i shifted to single ec2 instance with my application and beanstalkd w my own configurable workers. way cheaper easier to manage normal programming workflow etc.for some usecases lambda and other services are really nice and efficient but there's usually a lot of hidden limitations so be sure to spend a lot of time evaluating before committing. you often spend way more time fighting the microservice drawbacks than the benefits are worth.;0
17502420;HackerNews;2018-07-10;getting the feeling segment didn't really stop using microservices.sounds like they just redrew their service boundary from integration apis to business function.centrifuge sounds like a new service deals with connecting to integration apis so they've replaced 140 services with one.another service they've spun up is traffic recorder and its responsibility is to eliminate the need for http requests when testing integrations.feels like the biggest change is going from so many repos to a monorepo.;0
17502415;HackerNews;2018-07-10;what exactly are you trying to accomplish?if you are testing a single microservice and dont want to test the dependent microservice if you are trying to do a unit test and not an integration test you are going to run against mock services.if you are testing a monolith you are going to create separate test assembliesmodules that call your subject under test with mock dependencies.they are both going to be part of your ci process then and either way you arent going to publish the artifacts until the tests pass.your deployment pipeline either way would be some type of deployment pipeline with some combination of manual and automated approvals with the same artifacts.the whole discussion about which is easier is moot.edit i just realized why this conversation is going sideways. your initial assumptions were incorrect.iyou may want to test only a with monolithic architecture you'll have to produce another build of the application that contains mock of b or you need something like osgi for runtime module discovery.ithats not how modern testing is done.;0
17502401;HackerNews;2018-07-10;i have been doing some tech advice jobs on the side to see what's going on in the world and it's really scary what i found. only yesterday i was talking with the cto of a niche social networking company that has a handful of users and probably won't get much more who was telling me the tech they use node go rust mongo kafka some graph db i forgot redis python react graphql cassandra blockchain for their voting mechanism... some document database i had never heard of and a lot more. a massive brittle slow ! bag of microservices and technologies tied together where in 'every micro part' they used best practices as dictated by the big winners facebook google whatever in medium blogs. it was a freak show for a company of 10 engineers. but this is not the first time i encounter it 3 weeks ago on the other side of the world i found a company with about the same 'stack'.people really drink the koolaid that is written on these sites and it is extremely detrimental to their companies. postgresql with a nice boring java.net layer would blow this stuff out of the water performance wise for their iactual real life usecasei would be far easier to manage deploy find people for etc. i mean using these stacks is good for my wallet as advisor but i have no clue why people do it when they are not even close to 1100000th of facebook.;0
17502400;HackerNews;2018-07-10;i like that they highlight the tradeoffs between isolating faults and optimizing resource utilization. however you don't need microservices to achieve isolation. you can have different worker pools of the monolith configured to handle different destinations. the monolith actually gives you more flexibility in how you approach the tradeoff. with microservices you're forced into one pool of workers per destination but with the monolith you can choose any mapping of pools to destinations that makes sense.;0
17502379;HackerNews;2018-07-10;the thing people failed to realize is that microservices are a way of structuring people in teams in an organization not a way of structuring a product architecture.to use words that are mine microservices are a hack on conway's law. one team should be responsible for 23 microservices and should have a lot of autonomy.;0
17502325;HackerNews;2018-07-10;the problem is it's not clear when to use what. some get confused and use it in the wrong place. here are some questions to ask before you use microservices.does the service need an independent and dedicated team to manage its complexities or is it a part time job? try a stored procedure first if its the second.is the existing organization structure command hierarchy prepared and ready for a dedicated service? conway's law remember sharing a service introduces a dependency between all service users. sharing ain't free.do you really have a scalability problem or have you just not bothered to tune existing processes and queries? don't scrap a car just because it has a flat tire.;0
17502271;HackerNews;2018-07-10;every microservice on its own little cluster of vms for ha and performance...a couple of hundred vms is nothing in a scenario like that. good luck trying to debug anything.;0
17502258;HackerNews;2018-07-10;you will end up with something like osgi. that can be the right choice but is also a quite 'heavyweight' architecture.for a certain class of applications and organizational constraints i also would prefer it. but it requires a much tighter alignment of implementation than microservices e.g. you can't just release a new version of a component you always have to release the whole application.;0
17502221;HackerNews;2018-07-10;thesis monoliths in one repoantithesis microservices in separate repossynthesis microservices in a monorepo;0
17502174;HackerNews;2018-07-10;i agree completely.i think that regardless of whether microservices works for anyone or not they came about to address a real issue that we still have but that im not sure anyone has fully solved.i think that microservices are an expression of us trying to get to a solution that enables loose coupling hard isolation of compute based on categorical functions. we wanted a way to keep bob from the other team from messing with our components.i think most organizations really need a mixture of monolithic and microservices. if anyone jumps off the cliff with the attitude that one methodology is right or wrong they deserve the outcome that they get. a lot of the blogs at the time espoused the benefits without bothering to explain that microservices were perhaps a crescent wrench and really most of the time we needed a pair of pliers.;0
17502137;HackerNews;2018-07-10;i recall that the original motivation for separating each destination codebase into its own repo was to isolate test failures.ithis seems like a weird reason to adopt microservices. can't you isolate tests within the same repo using folders?;0
17502130;HackerNews;2018-07-10;i once scoffed at microservices.then i was tasked with building a scalable platform around a message broker system.then the switch clicked. i get it now.;0
17502121;HackerNews;2018-07-10;this misses the mark completely. a separate repo and service simply for different serialization and routing? each performing the same basic function. thats not a legitimate usecase for microservice separation and was doomed from the start.;0
17502120;HackerNews;2018-07-10;it's exactly the other way aroundif you can afford all your components sharing the same database without creating a big dependency hell then your problem is too small for microservices.if your problem is so large that you have to split it up to manage its complexity start considering microservices it might still not be the right option for you.;0
17501902;HackerNews;2018-07-10;ii'd wager that microservices a lot of the time are basically used as a management structureiconways law in action or in reverse;0
17501896;HackerNews;2018-07-10;yeah. we're currently in a second push to introduce microservices and this time i'm on board. the first time was more about enforcing code ownership and such and that was going to be a mess.now people are pondering things like ok management of elasticsearch has performance issues and it's a general pain if the elasticsearch documents change. so let's try to move the schema of elasticsearch documents into a strictly semver'd artifact. and let's move management of our search indexes into a service depending on that artifact so the schema changes in a controlled way. and ops and the search team can scale and optimize the service as they need to minimize search outages.creating smaller services based on problems is a good thing. creating smaller services because of ... reasons... not so much.;0
17501730;HackerNews;2018-07-10;didn't take long for we used shared libraries and then found out we couldn't deploy independently. sounds like you weren't quite doing microservices?;0
17501685;HackerNews;2018-07-10;they're both bad. it feels like a reverse sophie's choice to have to pick one.the real friction in the system is always in the boundaries between systems. with microservices it's all boundaries. instead of a ball of mud you have trees and no forest. refactoring is a bloody nightmare. perf analysis is a game of finger pointing that you can't defuse.;0
17501557;HackerNews;2018-07-10;we should bring categorical concepts into microservices. maintain composeability between entities rather than forming a graph of intercommunicating objects similar to oop.i don't know if adhering to these principles will make microservices better.;0
17501549;HackerNews;2018-07-10;there's actually no reason you can't architect microservices like this. you can put rabbitmq or some amqp service as a comm layer between services. but then you have to architect your system to be eventdriven. it's not a bad approach.;0
17501542;HackerNews;2018-07-10;well we can think of the synthesis as returning to monolithic services with the understanding the sufferings of microservices.;0
17501467;HackerNews;2018-07-10;this is really missing the point. microservices are not about code organisation they are about runtime separation.and even kernels have kernel threads which are basically local microservices. anything which needs to scale beyond a single system is more deserving of microservices than a kernel.;0
17501462;HackerNews;2018-07-10;but does this timeline apply to microservices or monoliths? methinks both...;0
17501451;HackerNews;2018-07-10;i can't help but think that this is an experience report covering microservicesdonewrong considered harmful. there are definitely pitfalls to the microservice approach but there are canonical answers to all of these issues. that said the right approach is the one that fits with your team's disposition skillset and experience level so ditching microservices might well have been the correct choice in this case. eventually all of them were using different versions of these shared libraries. we couldve built tools to automate rolling out changes but at this point not only was developer productivity suffering but we began to encounter other issues with the microservice architecture.in the extreme case where you have 150 microservices and 3 devs i think that spending a few days to build a tool that autoupdates your common deps and reruns your tests would be a good investment. or you could pay someone else to do this with a service like . handling common code is one of the known pain points in microservices so it's worth tackling headon. last i saw netflix handles this by the rule no services can share code unless it's by an open source library which encourages common code to be thoughtfully packaged and released. the additional problem is that each service had a distinct load pattern. some services would handle a handful of events per day while others handled thousands of events per second. for destinations that handled a small number of events an operator would have to manually scale the service up to meet demand whenever there was an unexpected spike in load.i can see this being tricky to tune and am hesitant to opine without knowing the details but if you can fix the problem by bundling all the services into a single monolith i.e. aggregating all load into n nodes then you should also be able to fix the problem by using a cluster scheduler like k8s with equivalently sized nodes. as long as you don't have bursts that are an integer factor of your baseline system load both approaches should work equivalently to the first order. it sounds like they were running individual instances per microservice which isn't a good fit for very bursty services.and as a bonus with a cluster scheduler you get a number of primitives to do resource reservation which you don't get for free if you're merging all of your services back inside a single monolith. this means the problem of backpressure from a single misbehaving endpoint which was one of the reasons they moved to microservices in the first place will probably come up in some form down the road. recall that the original motivation for separating each destination codebase into its own repo was to isolate test failures. however it turned out this was a false advantage. tests that made http requests were still failing with some frequency. with destinations separated into their own repos there was little motivation to clean up failing tests. this poor hygiene led to a constant source of frustrating technical debt.i don't have anything to say here except... don't do this? if your tests are failing you should be fixing your tests or removing them if they aren't adding value not adding new integrations. consistentlyfailing tests are a big warning sign that your cicd process is not in good shape and a healthy cicd process is a strict precursor to doing microservices successfully. the outbound http requests to destination endpoints during the test run was the primary cause of failing tests. unrelated issues like expired credentials shouldnt fail tests.your uts shouldn't be hitting your external dependencies the correct solution here is the one that they eventually landed on i.e. to either recordreplay real http requests or to mock out the http responses manually. you still need real integration and smoke tests in a productionlike environment to make sure that you've not missed a change in the remote api schema. ime this is one of the biggest challenges of working with external apis and i don't envy the task of maintaining 150 integrations however this issue seems unrelated to microservices.;0
17501431;HackerNews;2018-07-10;for biz code i've seen this kind of libifying architecture provide a nice microservices workflow. the unifying heuristic is any dependency goes into the lib project. anything unique to the service that requires no dep should usually go into the service project. the nice thing about this is it modular with fast compiles and preserves optionality. since everyone is using the same deps the code can live in the svc project or the lib project. a bit of namespacing convention makes it's trivial to shuttle the code between the two projects to wherever it's most natural to have it.;0
17501375;HackerNews;2018-07-10;the model in gp is useful but it doesn't account for the unequal distribution of information. e.g. some people are perceiving the cycle at a different phase and can be convinced to work harder not smart for an interval to shift their position within the cycle.e.g. let's get really good at microservices so we don't need a monolith. iow there's no consensus about when to dig in and go deeper. and even if there was some people would leverage that information and try to pull ahead of the others digging in.;0
17501322;HackerNews;2018-07-10;easy until you have 100000 of them anyway in which case it's expensive and slow to run it for every dev. at that point you have enough devs that microservices 100 make sense though;0
17501319;HackerNews;2018-07-10;the whole article reads like bs to me.so the initial problem was a single queue? well then split the queue no need to go all crazy splitting all the code.switching to 100 microservices? there is no need to switch to 100 repos too runtime services don't need to have one repo per service just use a modular approach or even feature flags.100 microservices some of them with much lower load than others? then consolidate the lower load ones no need to consolidate all of the microservices at once.library inconsistencies between services? no just no always use the same library version for all services. automate importingupdating the libraries if you need to.a single change breaks tests in a way you need to fix unrelated code? wtf don't you have unit tests to ensure service boundary consistency and api contracts?little motivation to clean up failing tests? yeah... you're doing it wrong.only then you figure out to record traffic for the tests? huge facepalm that's the first thing you should do when dealing with remote services!;0
17501314;HackerNews;2018-07-10;i think what was missed in the article is that the fundamental problem was centered around a shared architecture of destinations and shared code.you cannot possibly have every destination be a separate repo and then have the development lifecycle of your shared code be so active that it ultimately puts at risk the architecture of your entire organization.what makes shared code so perfect is having stability such that you extract your variant code into your nonshared code. shared code should evolve at a much slower pace than your nonshared code or you risk this very outcome.microservices are not dead nor are they the solution to everything. we need better architects.;0
17501308;HackerNews;2018-07-10;i'm not sure how worthwhile it is writing any more microservices are dumb articles all the people who have spent the last 5 years leaving microservice messes in their wake appear to have moved on to creating serverless messes of lambda functions which people like you and me are going to be going around tidying up in about 5 years from now.;0
17501296;HackerNews;2018-07-10;a a prototype b a set of applications that share a database.you would have to have an oddly disconnected schema if modifications to the program don't result in programs accessing parts of the database that other programs are already accessing. if this isn't a problem it means you're using your database as nature intended and letting it provide a languageneutral shared repository with transactional and consistency guarantees.so maybe not microservices but fine nonetheless.edit two more comments this is exactly what relational databases were designed for. if people can't do this with their microservices maybe their choice of database is the issue. microservice as the original post suggests is not synonymous with good. monolith is only synonymous with bad because it got runover by the hypetrain. if you have something that works well be happy. most people don't.;0
17501225;HackerNews;2018-07-10;one example i'm familiar with that isoundsi like microservices is the robot operating system ros. at its heart it's just a framework for pubsub over ip it just happens to be targeted towards robotics. a ros system comprises of 'nodes' for each logical operation e.g. image acquisition camera calibration analysis output.the system is defined by a graph of these nodes since you can pipe messages wherever they're needed all nodes can be manymany. each node is a selfcontained application which communicates to a master node via tcpip like most pubsub systems a master node is requried to tell nodes where to send messages. so you can do cool stuff like have lots of seprate networked computers all talking to each other fairly easily.it works pretty well and once you've got a particular node stable e.g. the node that acquires images you don't need to touch it. if you need to refactor or bugfix you only edit that code. if you need to test new things you can just drop them into an existing system because there's separation between the code e.g. you just tell the system what your new node will publishsubscribe and it'll do the rest.there is definitely a feeling of duct tape and glue since you're often using nodes made by lots of different people some of which are maintainted others aren't different naming conventions etc. however i think that's just because ros is designed to be as generic as possible rather than a side effect of it running like a microservice.;0
17501224;HackerNews;2018-07-10;in my experience there's a lot of cargo culting around microservices. the benefits are conferred by having a strong team that pays attention to architecture and good engineering practices.regardless of whether you are a monolith or a large zoo of services it works when the team is rigorous about separation of concerns and carefully testing both the happy path and the failure modes.where i've seen monoliths fail it was developers not being rigorousconscientiousintentional enough at the module boundaries. with microservices... same thing.;0
17501208;HackerNews;2018-07-10;i'm thinking it's more of a software business life cycle. microservices are somewhat easier to deploy which makes it easy for developers to add capabilities to be used by ux developers. once the eye candy and rough functionality is in place the sales team signs up new clients. the company draws down investment in developers and puts more money into infrastructure. the product moves from developer land to system land which is monolithic and can handle heavier loads.;0
17501175;HackerNews;2018-07-10;ii'd wager that microservices a lot of the time are basically used as a management structure rather than for their benefits as pure techia lot of software is used to control or impose someone's will on others organizationally.;0
17501150;HackerNews;2018-07-10;how on earth did you end up with 100s of services?i can't imagine you have applied conway's law.i think there's some serious confusion between faas and microservice architecture.;0
17501138;HackerNews;2018-07-10;microservice based architecture will continue to be used quite a bit as many weaker engineering leads have latched onto it as a way to solve interpersonal problems on their team and letting everyone have their own little fiefdoms. it creates a terrible scenario and a very dysfunctional team but the hype cycle and a few high scale orgs mentioning it means its part of the mainstream now and something that illinformed leads will be pushing for the next decade whether it makes sense for the specific context it doesn't or not.;0
17501108;HackerNews;2018-07-10;i have had thinkings on how efficient micro services are compared to a monolith.in a micro service architecture the request bounces through different service layers json serialization network transfers.in a monthlith normal application especially if its on one machine the request touches main memory and then cpu cache.latency numbers every programmer should know i especially think of the send 1k bytes over 1 gbps network vs cache latency of microservicesmonolith. ie instead of micro services 10000 ns for a network transfer you could fetch within 10ns from cpu cache in a monolith that is 1000 times more efficient.are we beyond the peak of inflated expectations on micro services and towards the plateau of productivity?;0
17501088;HackerNews;2018-07-10;just as bad just in a different way.actually worse in many ways harder to test harder to debug harder to deploy harder to monitor harder to reason about refactor changeadd functionality you've basically turned a lot of the operations your services need to perform into rpcs probably killing performance on top of everything else leading to more complexdemanding or just moar infrastructure requirements higher dev maintenance and infrastructure costs slower delivery of value to the business and customers potentially crippling opportunity costsit surprises me how often people don't see this coming. seriously keep your systems as simple as you possibly can. unless you're netflix dozens or hundreds of microservices probably isn't as simple as you possibly can.;0
17501083;HackerNews;2018-07-10;our initial microservice architecture worked for a time solving the immediate performance issues in our pipeline by isolating the destinations from each other. however we werent set up to scale. we lacked the proper tooling for testing and deploying the microservices when bulk updates were needed. as a result our developer productivity quickly declined.well i'm not surprised. microservices are made possible by advances in automated testing ci and deployment. you should have those things anyway even if you have a monolith but to go to microservices without them is a pretty bad decision.;0
17500967;HackerNews;2018-07-10;i think that with the rise in popularity of functions as a service lambda gcf azure we are heading more and more towards nanoservices.there are some pretty big asterisks next to running nanoservices. mostly how expensive they actually are to run at large scale and the weird caveats that can happen due to them not always being up.and i wouldn't advocate for alwaysup nanoservices.the basic answer to both nanoservices and microservices is do what you think is right but don't go too far. there are good reasons to make a nanoservice and good reasons not to same with microservices.;0
17500945;HackerNews;2018-07-10;this coincides with my own experiences in the financial sector. distributed computing is undoubtedly the way to scale but the trick is making the distributed nature of the system completely invisible or as much as possible to the developers the applications and the supporting staff.i have seen this phenomena of thinking that a large system broken down into tiny parts is somehow easier to manage time and time again over 30 years of development. in every case the one thing the central thinkers fail to realize is that complexity is like conservation of energy it can be transformed but it cannot be destroyed.also when it comes to large teams i have seen one thing work when it comes to sharing a resources critical to a larger system shared pain. if the centralreusable codeservice breaks everyone's stuff then everyone forms a team to immediately address the problem before continuing on. the solution is almost never find a way to let the other teams continue while something important is on fire. it seems like a major motivation for a microservices architecture seeks to avoid the pain which perhaps is not the best reason to use microservices.i like the idea of unseen but indispensable complexity. for instance the human brain is probably the most complex thing in the world but the interface is fairly simple;0
17500931;HackerNews;2018-07-10;if you have 140 somewhat similar entities that all share common code then they don't fullfill the very important microservice criterion of being independent. in your case i would recommend to use a plugin based system. do it the other way around have 1 application that contains the common code previously shared library code and create 140 plugins. this way you can update the single application load all plugins execute the tests check if everything is fine and deploy the application. every plugin can live in its own repository and can be versioned separately but a new version can only be deployed if it works with the latest version of the application.;0
17500902;HackerNews;2018-07-10;it's worse than that it's my observation that most microservice architectures just ignore consistency altogether we don't need no stinking transactions! and blindly follow the happy path.if two microservices have to share databases they shouldn't be microservices.one microservice should have write access to one database and preferably all read requests run through that microservice for exactly the reason you mentioned.i've never quite understood why people think that taking software modules and separating them by a slow unreliable network connection with tedious handwired rest processing should somehow make an architecture better.if you're running microservices between regions and communicating with each other outside of the network it is living in you're probably doing it wrong.microservices shouldn't have to incur the cost of going from sf to china and back. if one lives in sf all should and you can colocate the entire ecosystem 1 for only huge companies with big requirements should do microservicesustomers couldn't care less except that it now takes far longer to implement features that cross multiple services which if you've decomposed your services zealously enough is pretty much all of them.again that is an example of microservices gone wrong. you'll have the same amount of changes even in a monolith and i'd argue adding new features is safer in microservices no worries of causing side effects etc.i will give you 1 on that anyway because i designed a microservice that ended up being 3 microservices because of dumb requirements. it probably could've been a monolith quite happily.;0
17500887;HackerNews;2018-07-10;its basically a feature flag. i dont like feature flags but it is a thing.but if you are testing an artifact why isnt the artifact testing part of your ci process? what you want to do is no more or less an anti pattern than swapping out mock services to test a microservice.im assuming the use of a service discovery tool to determine what gets run. either way you could screw it up by it being misconfigured.;0
17500884;HackerNews;2018-07-10;i'd wager that microservices a lot of the time are basically used as a management structure rather than for their benefits as pure tech so less mature teams can silo themselves off and avoid communication e.g. i can work just on my backend image processing bit without dealing with the react guys now now the cto won't be on my back so much or whatever.the irony being that anything approaching soa or microservices requires exactly the same amount of communication. more likely they require more since it's almost certain that such a decision introduced chaos.;0
17500880;HackerNews;2018-07-10;look at the package dependency tree of an average linux program. they are absolutely examples of microservices talking to each other.;0
17500872;HackerNews;2018-07-10;the first item on the list was to consolidate the now over 140 services into a single service.software engineering walks in circles. nosql people seem to be growing up and learning about consistency and transactionality. i'm waiting for somebody to discover threads and shared variables back as a revolutionary way to improve performance and greatly simplify the implementation of a system of actors.joking aside i think greatest reason for segment's microservices failure was that they didn't use kubernetes.;0
17500870;HackerNews;2018-07-10;sometimes i've seen a lack of regard for data consistency within a monolith.that is not completely on the developer either. pre 4.0 mongodb for example does not do transactions. on the other hand i've seen some pretty flagrant disregard for it just because there are not atomicity guarantees.microservices makes reasoning on that harder.;0
17500869;HackerNews;2018-07-10;surely this is no true scotsman? they've tried microservices and it didn't work for them you're saying that if only they'd fixed their microservices architecture it would have worked?;0
17500861;HackerNews;2018-07-10;a number of comments touched on this that microservices are also an organizational strategy you have a team that manages that particular service.my company is probably typical in that we implicitly use microservices because we have consume dozens of microservices iprovided by other companiesi.we only have a handful of services we maintain each with dedicated engineers.and what becomes a service? you want to answer two questions1. does it have a concrete business justification? 2. does it have clear functional requirements?if it has a business justification it will get people assigned to keeping it running. if it has clear functional requirements it will make sense to the people working on it which service does what.that's still pretty vague so you want to look at who has done it well and why it worked for them.companies like aws have been extremely successful in using microservices because every last one service has a business rationale it's either directly making money ec2 s3 sqs iori it supports the needs of customers who are using a service that makes money vpc cloudformation all their internal auth billing provisioning security and such.the caveat there is that the big b2b service providers are not a great model for companies that have a lot of business logic.;0
17500857;HackerNews;2018-07-10;if you're going to go microservices you want service a to use service b's public api mq or rpc or whatever not to quietly depend on the schema b happened to choose. and sharing a database server instance turns overloads into cascading failures unless the stack is iveryi good at enforcing resource limits on noisy neighbors.;0
17500851;HackerNews;2018-07-10;to be blunt its news to a lot of people but it also isn't wrong. microservices really shouldn't share a database and if they do then they aren't microservices.;0
17500817;HackerNews;2018-07-10;running e2e blackbox test is equally simple for all kinds of architectures especially today when it's so easy to create a clean test environment with multiple containers even on developer's machine. it may be harder to automate this process for a distributed system but frankly speaking i don't see a big difference between a dockercompose file or a launch script for monolith i've been writing such tests for distributed systems casually for several years and from my personal experience it's much easier to process the test output and debug the microservices than monolithic applications.;0
17500814;HackerNews;2018-07-10;reading this postmortem was very useful and i appreciate the segment engineering team sharing it.it seems like the primary problem causes were flakyunreliable tests and difficulty making coordinated changes across many small repositories.having worked on similar projects before and currently with a small team driving microservices oriented projects i would probably recommend1 single repository to allow easy coordinated changes.2 a build system that only runs tests that are downstream of the change you made bazel is my favorite here but others exist. this means all services use the head version of libraries and you find out if a library change broke one of the services you didn't think about. this also allows for faster performance.3 emphasis on making tests reliable. mock out external services or if you must reach out to dependencies use conditional test execution like golang's skip or junit's assume if you can't verify a working connection.if you still can't build a reliable service with those choices then it's time to think about changing the architecture.;0
17500794;HackerNews;2018-07-10;they used microservices to paper over poor testing hygiene and software architecture. forking one service into a bunch of different flavors of the same service multiplied the maintenance complexity. servicesmicroservices that are tightly coupled to shared libraries with lots of surface area are an antipattern. instead i would make the shared libraries into a service and make a standard interface for the destinations as plugins.;0
17500755;HackerNews;2018-07-10;op can correct me if i'm wrong but i believe the comment around segements engineering team was most likely referencing the original decision to create hundreds of microservices in the first place.;0
17500735;HackerNews;2018-07-10;the fix then is to put that commonality into a new microservice the other microservices call.the more i read about the problems people have with microservices the more i'm convinced they've never read about flowbased programming.;0
17500668;HackerNews;2018-07-10;packages and ports are both collections of microservices in your analogy so you can't really assert the whole thing is a monolith.;0
17500661;HackerNews;2018-07-10;the important part here that the parent addressed is the statement small team as an organizational structure distinct from say a large team which has the opportunity to experience conway's law.it sounds like segment very much prematurely optimized. microservices is probably not a great approach below 20 developers and becomes necessary past 100 at least in my experience.;0
17500657;HackerNews;2018-07-10;this is a classic case of not understanding micro services and trying to fit a problem around a tool.at work we have close to 50 servicesno one calls them microservices but they do not suffer from this brittleness. we segregate our services based on languages. so all c services go under coco all java services go under jumanji all go services go under goat all js services go under js. this means everytime you touch something under a repo it affects everyone. you are forced to use existing code or improve it or you risk breaking code for everyone else. what does this solve? this solves the fundamental problem a lot of leetcodehackerrank monkeys miss programming is a social activity it is not a go into a cave and come out with a perfect solution in a month activity. more interaction among developers means engineers are forced to account for trade offs. software engineering in its entirety is all about trade offs unlike theoretical comp science.anyway this helps because as engineers we must respect and account for other engineers decisions. this methods helps tremendously to do this. no one complains everyone who wants 1000 more microservices usually turns out to be a code monkey entangled in new fad or who doesn't want to work with other engineers.you want to use rust? there is a repo named fe2o3 go on. accountability and responsibility is on your shoulders now.if you think about it an engineer is tied to his tools why not segregate repos at language level instead of some arbitrary boundary no one knows about in a dynamic ecosystem?;0
17500651;HackerNews;2018-07-10;working at a large tech company we tend to approach microservice division as information authority division.if the data doesn't need to exist in the same database put it in a new service with a separate database or at least completely independent tables.ideally there is no shared code between services and there shouldn't need to be because each service owns completely disparate data so the only coupling is the api definitions.each service is free to use whatever internal architecture they see fit as long as they honor the api definitions they provide to their dependent services.in the case outlined in the article the fact that each microservice had similar enough concerns to all use some common libraries and the same database makes me doubt that this should ever have been built as microservices to begin with.;0
17500639;HackerNews;2018-07-10;iamleppert does address that. as they said microservices are supposed to mirror the structure of your teams.a single team should never be maintaining 140 different microservices. that's not a failing of the microservices architecture that is a failing of massively abusing the microservices architecture. arguably a small team should never be managing more than 10 services totally arbitrary number but it seems like the upper limit to what a human can focus on.;0
17500620;HackerNews;2018-07-10;that doesn't really say anything though things were bad and it felt out of control because of microservices. they didn't work and actually made things worse and more complex. the things that were supposed to be good were bad. we didn't do good work we did bad work and slowly.how do you address something like that coherently? i sort of agree with the op it kinda sounds like they just didn't know what they were doing. or maybe that e wasn't really the meat of their complaint?;0
17500613;HackerNews;2018-07-10;i'm hardly a microservice apologist but sharing code or data across services is a major smell. it means these things are related and should likely be bundled together. don't just break a service apart because it's de rigueur.;0
17500605;HackerNews;2018-07-10;usually microservices have their own databasesthat's news to me and seems insane.unless you mean their own database tables not database servers. but that's just the same as having multiple directories and files in a unix filesystem.;0
17500600;HackerNews;2018-07-10;microservices is the architecture du jour? there is nothing new about microservices. they've been a hot topic for far longer than segment has been an idea.;0
17500592;HackerNews;2018-07-10;when i was designing a microservices architecture for a former employee the justification for it was security. we needed separation of the components in the system because we were going to be handling money. it used zeromq for communication because i wanted something more lightweight and falutresistant for message passing in such a sensitive application we didn't want to trust the network. although it was of course fun to design microservices weren't my first choice. it just made sense to us to use it in that particular scenario.;0
17500588;HackerNews;2018-07-10;nothing you said addresses the issues they mentioned in early 2017 we reached a tipping point with a core piece of segments product. it seemed as if we were falling from the microservices tree hitting every branch on the way down. instead of enabling us to move faster the small team found themselves mired in exploding complexity. essential benefits of this architecture became burdens. as our velocity plummeted our defect rate exploded.;0
17500578;HackerNews;2018-07-10;but there is a big difference. these small targeted programs are invoked in user land usually by the user. microservices get invoked directly by the user when debugging is going on. otherwise they are expected to automagically talk to each other and depending on the abstraction even discovery each other automatically.also i can pipe these tools together from the same terminal session like you don't have that in general with microservices. unix tools iarei lego microservices aren't. they are domino at best.probably one could come up with an abstraction to do lego with microservices but we're not there yet.;0
17500577;HackerNews;2018-07-10;before you go down the path of splitting your app up into microservices you should grok erlangbeamotp. lots of thinking went into its creation that leads to highly reliable real time systems and at the very least some of the ideas can be lifted in informing how to best design things. but really you should probably just use it instead.;0
17500549;HackerNews;2018-07-10;some people call this... microservices! common advice is that a microservice should align with a bounded context in domain driven design which can involve a lot of code.many large companies have millions of loc behind their microservices. your average startup probably doesn't.;0
17500536;HackerNews;2018-07-10;with web apps the main concern is data consistency between relations. on the os level you have these same concerns with memory and disk and there's databaselike systems in the kernel and drivers to handle it. essentially all these utilities are running within the same database which is disk and memory management handled by the kernel. usually microservices have their own databases which is where consistency hell begins;0
17500525;HackerNews;2018-07-10;in this case it sounds like they started with a microservice architecture but cicd automation necessary for robust testing and autoscaling was not in place. the problem of queues getting backed up might have been addressed by adding a circuit breaker but instead they chose to introduce shared libraries again without necessary testing and deployment which resulted in very tight coupling of the socalled microservices.;0
17500519;HackerNews;2018-07-10;yes but monolithic web applications can be built in the same way. it might not be a 100 accurate usage of the term but microservicesoa advocates love to call modular applications monliths anyways to the point that it's something that most people seem to do.;0
17500517;HackerNews;2018-07-10;i dont see any reason you shouldnt always design a system as domain specific micro services.now those micro services shouldnt always be out of process modules that communicate over httpqueues etc. a microservice can just as easily be separately compiled modules within a monolithic solution with different namespaces public versus private classes and communicate with each other in process.then if you see that you need to share a service across teamsprojects or a module needs to be separately deployed scaled its quite easy to separate out the service into versioned packages or a separate out of process service.;0
17500484;HackerNews;2018-07-10;i think this is probably true for larger or more distributed corporate environments but i think a modular monolith is going to be a more productive and flexible architecture for most teams and should be the default option for most startups many of whom are doing microservices from day 1 it seems.1. is autoenforced modularity separation of concerns etc actually better than enforcing these things through development practices like code review? why are you paying people a 6 figure salary if they can't write modular software?2. is the flexibility you gain from this loose coupling worth the additional costs and overhead you incur? and is it really more flexible than a modular system in the first place? and how does their flexibility differ? with an api boundary breaking changes are often not an option. in a modular codebase they can easily be made in a single commit as requirements change.3. is bringyourownlanguage actually a good idea for most businesses? is there a net benefit for most people beyond attracting and retaining talent? what about the ability to move developers across teams and between different business functions? having many different tech stacks is going to increase the cost of doing this.i do see the appeal of some of these things but imo the pros outweigh the cons for a smaller number of businesses than you've mentioned. and the above is only a small sample of that. most things are just more difficult with a distributed system. it's going to depend on the problem space of course but most backend web software could easily be written in a single language in a single codebase and beyond that modularization via libraries can solve a lot of the same problems as microservices. i'm iveryi skeptical of the idea that microservices are somehow going to improve reliability or development speed unless you have a large team.;0
17500481;HackerNews;2018-07-10;teams have a lot to do with microservice use. if you have a small team a monolith can work well. if you have a large team microservices have some significant advantages. and in some cases you might have a microservice in swift when you need high performance but other less intensive services might be in ruby or some other language etc.right took for the job should be the goal as opposed to chasing fashion. microservices are definitely overused but they do have many legitimate use cases. your crud web application probably doesnt need microservices but complex build systems might.imagine the complexity of amazon.com or netflix were a monolith. but something like basecamp is probably better as a monolith.there is also the issue of scale. an ml processor might need more and different hardware than a user with system.right tool and architecture for the job.;0
17500462;HackerNews;2018-07-10;seems like an application of sturgeon's law there is a tendency to do what is new because it is new. a well designed microservice architecture can be a tremendous boon for a product. a well designed monolith can be a tremendous boon for a product. about 90 of both are poorly done. it's interesting how often people favor any motion vs motion in the correct direction.;0
17500454;HackerNews;2018-07-10;it's quite possible to do a monolithic app well and correctly. it's also quite possible to do a big pile of microservices as a cohesive app well and correctly.in my professional experience where i've run into numerous examples of good and bad examples of both microservices tend to win because it's a lot easier to unwind the badly implemented microservices compared to the badly implemented monolithic service.of course this is just another small set of anecdata.;0
17500412;HackerNews;2018-07-10;people might read this article as an argument against microservices. it's not in my opinion. it's an argument against impractical design. their system should never have been 50 separate repos in the first place in terms of design it's all one app that would benefit hugely from being a single coordinated system.microservices work when they are separate independent singleconcern systems that coordinate using apis. people often go overboard in splitting apps up into small pieces even when those pieces logically belong to a single system. start with figuring out the subsystems then considering whether they are worth splitting in the first place.it's worth pointing out that microservices don't mean separate repos or even codebase separation. what matters the most is encapsulation. monoliths grow horrible because they end up being balls of spaghetti and forcing modularization at the service level is a way to avoid such messes by reducing the individual parts manageable sizes allowing a part to be replaced without being concerned about its tendrils having grown through the whole system.for me the biggest value of microservices is composition of thinking abou modules as offtheshelf components that you use as parts to build something bigger. using a complete enough set of microservices i can build a frontend or client that has zero appspecific backend code. for example if i have a generic data layer think firebase a user database layer with oauthoidc and a way to store images then i can build instagram from scratch with no backend development at all. that's very powerful.but once i need some specialized appspecific stuff business rules such as rating of photos commenting moderation etc. then those probably wouldn't be microservices! the concerns are unified there for the most part and disentangling them would just lead to annoying fragmentation. a single usecase specific service monolith that would exist at the center of it all.on the other hand composition is mostly useful if your pieces are going to be reusable. if i intend to build more than one instagram or maybe a facebook which also needs data storage and logins and photos etc. then the individual pieces would be reusable and could just be shared between the apps. but if i'm just building instagram for 5 years and i'm not building a series of apps for different use cases reusability has zero importance and i might as well just move everything into a single monorepo and forget about making anything generalpurpose. each piece should be generalpurpose ienoughi but they usually don't need to be so generic that you could opensource it for everyone.i never liked the word microservice and i think we'd be better off if we called them say modules or subsystems.;0
17500411;HackerNews;2018-07-10;use erlangelixir. you get the benefits of the monolith iandi the benefits of the microservices;0
17500398;HackerNews;2018-07-10;microservices are an organizational and design choice that is intended to mirror the structure of the teams or engineers the actual human beings doing this stuff.it seems like segment didnt really understand this at all and instead decided to have seemingly arbitrary and rediculous service boundaries that had no relationship to the real world.see also people who create poor abstractions in their code and other sources of technical debt.this isnt an article about how microservices architecture is somehow bad its an article about how bad segments engineering team is. you can make the same argument for anything. at the end of the day some architecture or process or programming language or tech cant replace real thinking about your problem and correct application.;0
17500393;HackerNews;2018-07-10;microservices aren't some magic bullet for scaling. if anything they conform to conway's law 1. i'd agree though if a single engineer is singularly responsible for 2 microservices that are only supporting a single product...you're doing it wrong.1;0
17500385;HackerNews;2018-07-10;right but the thing that makes linux actually useful isn't really the kernel is it? i would say what makes it useful is all the various small targeted programs some might call them microservices it lets you interact with to solve real world problems.if linux tried to be an entire computing system all in one code base sed vim grep top etc. etc. what do you think that would look like code basemaintainability wise? sounds like a nightmare to me.;0
17500381;HackerNews;2018-07-10;not really. for example it's easier to mock a microservice than a module for testing purposes. let's say you have component a and component b a depends on b dependency implemented via runtime sync or async call b is computationally intensive or has certain requirements on resources that make it harder or impossible to test on developer's machine. you may want to test only a with monolithic architecture you'll have to produce another build of the application that contains mock of b or you need something like osgi for runtime module discovery. when both components are implemented as microservices you can start a container with mock of b instead of real b.;0
17500363;HackerNews;2018-07-10;along with not following the basic rule of services put together first split later.agreed. i treat services like an amoeba. let your monolith grow until you see the obvious split points. the first one i typically see is authentication but ymmv.notice i also do not say 'microservices'. i don't care about micro as much as functional grouping.;0
17500360;HackerNews;2018-07-10;it's refreshing to read an article which challenges common wisdom.i've endured a lot of suffering at the hands of the microservices fan club. it's good to see reason finally prevail over rhetoric.it would have been nice if people had written articles like this 2 years ago but unfortunately people with such good reasoning abilities would probably not have been able to find work back then.software development rhetoric is like religion. if you're not on board you will be burned at the stake.so many times during technical discussions i had to keep my mouth shut in the name of selfpreservation.;0
17500352;HackerNews;2018-07-10;i liked the rundown and agree there are tactical benefits for building monolithic api's but one of the core tenants of microservice architecture coming out of the domain driven design space is that monolithic systems hide business logic. i'm pretty sure by moving everything back to a monolith you've abandon ddd entirely. from a strategic perspective that's bad for your business.if you get your devops ducks in order a lot of the issues you have with standing up and maintaining individual microservices should be manageable. i certainly understand the pain of dependency management but that's also a part of good architecture.i'm willing to hear more of these stories though. we can always learn about edge cases or even new paradigms that come out of current thinking.;0
17500347;HackerNews;2018-07-10;microservices aren't a magic bullet and won't save you from a poorly designed application. you already need to have very good separation of concerns within your application to make it out of microservices and at that point an api that communicates over http isn't much different from one that communicates over the application stack.;0
17500335;HackerNews;2018-07-10;that's exactly it. but when you start doing 'microservices' you get the architecture astronauts who go and see into how many silly little services a monolith can be broken up. the end results are as predictable as the original monolith both end up as an unmaintainable mess in a couple of years.i predict the same will happen to the 'superstar' it just isn't old enough yet and at least it was built with some badly needed domain knowledge.;0
17500323;HackerNews;2018-07-10;i probably don't understand their architecture well enough since they don't try and explain it in detail. the blame is also put on microservices whereas it's the architecture that can be fixed to improve performance and the cost of deployment.a shared library works up until a certain point. if every service uses a shared library then you are already getting to a world of a monorepo. a monorepo for different services should work fine if the overall architecture is feasible.;0
17500320;HackerNews;2018-07-10;1i felt this article is more about how to use microservices right way vs butchering the idea. it is not right to characterize this as microservices vs monolith service. initial version of their attempt went too far by spinning up a service for each destination. this is taking microservices to extreme which caused organizational and maintenance issue once number of destinations increased. i am surprised they did not foresee this.the final solution is also microservice architecture with a better separation of concernsfunctionalities. one service for managing in bound queue of events and other service for interacting with all destinations.;0
17500276;HackerNews;2018-07-10;as with j2ee ejbs microservices conflates two things a strong api between components network callsthe former is a very good idea that should be implemented widely in most code bases especially as they mature using techniques like modules and interfaces.the latter is incredibly powerful in some cases but comes at a huge cost in system complexity performance and comprehensibility. it should be used sparingly.;0
17500233;HackerNews;2018-07-10;people look at microservices as a solution to the big ball of mud and then confuse a solution with the solution.you really do have to modularize. in some languages you can even use separate compilation units for separate modules to enforce the separation.you can do all of that but get simultaneous deployment which cuts out whole classes of integration nightmares.;0
17500230;HackerNews;2018-07-10;it's worse than that it's my observation that most microservice architectures just ignore consistency altogether we don't need no stinking transactions! and blindly follow the happy path.i've never quite understood why people think that taking software modules and separating them by a slow unreliable network connection with tedious handwired rest processing should somehow make an architecture better. i think it's one of those things that gives the illusion of productivity i did all this work and now i have leftpadasaservice running! look at the little green status light on the cool dashboard we spent the last couple months building!programmers get excited about little happily running services these are real to them. customers couldn't care less except that it now takes far longer to implement features that cross multiple services which if you've decomposed your services zealously enough is pretty much all of them.;0
17500209;HackerNews;2018-07-10;100's of problem children sounds like a step too far.a few services monolithmonolith 100's of services.the big trick with any technology is to apply it properly rather than dogmatically and if you are breaking up your monolith into a 100's! of microservices you are clearly not in control of your domain. that's a spaghetti of processes and connections between them rather than a spaghetti of code. just as bad just in a different way.;0
17500149;HackerNews;2018-07-10;too many smart folks that i've worked with for some reason just stop thinking critically when it comes to certain ideas.i was a product manager on a team of really rockstar developers. they all earn at least 200k a year.instead of demanding more ambitious projects you could keep about 99 of them happy by just letting them use the new framework of the week to build their next web app. their excitement when they were greenlighted to use react was mindboggling. building another dumb website with the new framework yay.mindlessly applying microservice architecture is the same issue at heart.;0
17500147;HackerNews;2018-07-10;i feel that when it comes to making any decision about separating things out you really do have to consider the size of the team you've got before you commit to it. if you've got three devs and they all work across all of the microservices then what on earth do they add except a hell of a lot of overhead?if you had ten teams of seven and they managed two services each... it's easier to see how that architecture could actually help.same as if you have a two person team building a webapp and they go for clientserver architecture rather than a basic full stack web framework. if you're both working the frontend and backend at the same time save yourself the extra ops effort.;0
17500140;HackerNews;2018-07-10;not that i disagree with microservices easily going awry the problem here seems to be traced to shared library code. each microservice should be as standalone as possible. your contract with that service is the service contract. not some shared library.as soon as you have shared library you now have coordinated deployments. and that is just not fun and will cause problems.the trick here is that this does mean you will duplicate things in different spots. but that duplication is there for a reason. it is literally done in two places. when you update the service you have to do it in a backwards compatible way. and then you can follow with updates to the callers. this makes it obvious you will have a split fleet at some point but it also means you can easily control it.;0
17500131;HackerNews;2018-07-10;microservices typically have two goals performance and modularity. however porting a typical webapp to a fast modular compiled language will typically achieve at least one often two orders of magnitude performance improvement over a typical interpreted language. we are seeing this to be true more often than not and a large performance gain off the bat like that may even obviate a lot of the desire to move to microservices.furthermore if one uses modules as one should one can arbitrarily and somewhat trivially run those modules either inprocess compiled in or outofprocess via rest grpc capn proto or another rpc system e.g. in a separate servicemicroservicewhatever you want to call it. this gives you a best of both worlds approach where code can be arbitrarily run in a monolith or a separate service asneeded. this changes the thought dynamics from a rigid monolith vs. microservice decision to a more fluid process where things can be rather easily changed on a whim. when modularity is the goal then services become something of a secondary concern.microservices are used as something of a sledgehammer to force modularity and performance in languages that lack proper modularity andor are innately slow or otherwise inefficient while suffering orchestration costs and the performance penalties of copying data across multiple processes and networks as well as making it harder to derive a singlesource of truth in some cases.probably a good approach for a typical webappp looking to improve performance would be to first port core logic to a modern fast compiled language with modules then evaluate the performance from there and then determine if any modules should be split out into separate processes or services.like nosql microservices can be but not always are a case of the cure being worse than the disease however they can also be useful in certain situations or architectures. like anything in engineering there are tradeoffs and it depends on your situation.;0
17500111;HackerNews;2018-07-10;personally i dont like the terms microservices or nanoservices. whats the value add in describing the relative size of the service? the domain should drive what becomes its own service. every service should handle the business logic within a particular domain. its definitely a goldilocks problem though in that theres a toosmall and toolarge and were looking for the justright fit!;0
17500096;HackerNews;2018-07-10;am i understanding correctly that they had 3 engineers and 140 microservices? microservices definitely have their own costs and tradeoffs but 140 services and 3 engineers sounds like just a terrible engineering choice.;0
17500086;HackerNews;2018-07-10;i agree and their conclusion even features this salient bithowever we werent set up to scale. we lacked the proper tooling for testing and deploying the microservices when bulk updates were needed. as a result our developer productivity quickly declined.my impression after reading this post was that microservices were symptoms of problems in how their organization wasn't set up to implement them effectively rather than the actual cause of those problems.;0
17499999;HackerNews;2018-07-10;so they split everything apart because their tests were failing and they didn't want to spend time fixing them and they they merged it back together by spending time fixing and improving their tests?it seems like the problem here was bad testing and micro repos not microservices.;0
17499928;HackerNews;2018-07-10;what kind of issues you faced while working with microservices?;0
17499842;HackerNews;2018-07-10;agreed.reading about their setup and comparing with some truly large scale services i work with i'm left with the idea that segment's service is roughly the size of one microservice on our end.perhaps the takeaway is don't go overboard with fragmenting services when they conceptually fulfill the same business role. and regardless of the architecture of the system there are hard state problems to deal with in association with service availability.;0
17499807;HackerNews;2018-07-10;i've always said if the linux kernel can be a giant monolith in c no less than there's maybe 100 web applications in the world that need to be split into multiple services.i've worked with microservices a lot. it's a neverending nightmare. you push data consistency concerns out of the database and between service boundaries.fanning out one big service in parallel with a matching scalable db is by far the most sane way to build things.;0
