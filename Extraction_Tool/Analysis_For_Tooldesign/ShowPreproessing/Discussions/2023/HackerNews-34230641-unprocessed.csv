ID;Source;Creation Date;Content;Sentiment
34230641;HackerNews;2023-01-03;Title:Modules, not microservices, Content: http://blogs.newardassociates.com/blog/2023/you-want-modules-not-microservices.html;0

34284642;HackerNews;2023-01-07;"I would never claim that our setup uses microservices. Probably just more plainly named &quot;services&quot;.<p>And yes, that is correct, we agree that once we expose a view, we won't remove columns or change types of columns. Theoretically we could effectively deprecate a column by having it just return an empty value. Our use cases are such that changes to such views happen at an acceptable rate, and backwards incompatible changes also happen at an acceptable rate.<p>Our views are also often joins across multiple tables, or computed values, so even if it's often quite close to the underlying tables, they are intentionally to be used as an abstraction on top of them. The views are designed first from the perspective of, what form of data do others services need?";0
34279551;HackerNews;2023-01-06;This only works if you apply backward compatible changes all the time. Sometimes you do want to make incompatible changes in your implementation. Database tables are an implementation detail, not an API which you're trying to expose as a view, etc.<p>But hey, every team and company has to find their strategy to do things. If this works for you, that's great!<p>It's just not a microservice by definition.;0
34279318;HackerNews;2023-01-06;"<i>&gt; Apologies for the delay in a reply.</i><p>Not at all. I'm in no rush.<p><i>&gt; Secondly, what I think actually happens is that most companies using microservices aren't this disciplined and just end up bodging or implicitly coupling services.</i><p>If an organization is sufficiently large you may have no way to get another team on the line to even try. At that scale the other teams may as well work for other companies and that is what microservices models. If your organization is small, I tend to agree that you won't succeed. You can't beat Conway's Law.<p><i>&gt; I find little value in providing that specification through the TDD approach or associated ceremony.</i><p>But, ultimately, what's the difference between writing your spec in an executable way or writing it in a Word document beyond the superficial differences in the languages? What is communicated to other developers ends up being the same.<p><i>&gt; I prefer as few tests as possible at as high a level as possible with as few mocks as possible. I'll take a single test that takes 15 seconds to run over 1000 tests running in milliseconds.</i><p>Seemingly not all that common, interestingly, but Go comes to mind as a language that provides constructs to define separation between specification (TDD) and developer tests. Conceivably you could exclude your TDD specs from execution, only running the tests that help in your development process.<p>The value of TDD isn't in the execution, but in what is communicated to other developers. That the specs are executable is merely a nice side benefit to help with confirming that the implementation conforms to the spec. You still get 90% of the benefit of TDD even if you never run the executable, albeit granted at that point it <i>is</i> just a fancy Word document.<p><i>&gt; I think there's a lot of healthy debate to be had about how much testing is needed. </i><p>Perhaps, but TDD isn't about testing. TDD is about providing documentation. I think there is less room for debate there. I'm not sure anyone who has ever inherited a codebase has wished it gave less insight into what the 'business needs' of the program are. Again, a Word document can provide the same documentation, but if you're going to write that Word document anyway why not go the extra mile and gain the additional benefits that come with execution?";0
34271446;HackerNews;2023-01-06;"I really miss the old days where when an app was down it was obvious... Now apps just go unresponsive because of connectivity issues between services... We used to have frameworks that could communicate errors in one log, it was a beautiful thing. As cloud infrastructure became more powerful to better host so called &quot;monolithic&quot; systems, it was all scrapped to move to microservices, which were made for less powerful infrastructure. Everything was refactored to the point where it's expensive to go back... Pretty crazy how much money the industry wastes on refactoring...<p>On top of that, the tendency to get complacent with unstructured data in a lot of systems is really creating a very complicated lock-in when systems are developed for unique services on each cloud provider... Bowls of spaghetti.<p>Hire Solutions Architects for dev projects, make your apps future proof... I warn you. Too much microservice customization leads to vendor lock in and expensive operational costs... This is why a lot of apps get sunsetted early.";0
34270797;HackerNews;2023-01-06;Unfortunately, people keep forgetting that microservice also requires organizational change. Otherwise, it's just a heavy overhead.;0
34267860;HackerNews;2023-01-05;The argument is simply the empirical observation that the vast majority of microservices deployments don't operate anywhere near the scale that actually requires microservices and is not going to operate at that scale in the foreseeable future. When scalability is the primary argument in favor of microservices, how is that absurd?;0
34266531;HackerNews;2023-01-05;"&gt; The ability to load balance across nodes is not, as you claimed, a particular advantage of microservices.<p>Are you replying to the right comment? I made no such claim.";0
34266165;HackerNews;2023-01-05;"&gt; I'm comparing specifically against a monolith where you have an &quot;uber executable doing literally everything&quot;.<p>I doubt that anyone here is advocating for a system that it literally everything in one OS process. I bet even you would say that a process with a RDMBS connection is a monolith, even though it doesn't fit your definition.<p>As for modules - they can run as a separate process on the same machine, to isolate security critical elements.<p>Conversely, I doubt that any reasonable microservices architecture has every instance of a microservice in its own subnet with a firewall and strict network access permissions... including one off generated API keys.<p>Most, at best, use a static API key per microsoervice inside one large &quot;secure&quot; network... which leads me back to my point - they're not exactly easier to secure. Methods may differ a little bit, but the techniques are the same.<p>Then your example of a buffer overflow is going to be as bad for microservices, as for monolith.<p>Unless you're going to invest in a variety of systems, programming languages and OSes in your stack - your one buffer overflow, turns into buffer overflow on every other microservice... making your claim of &quot;easier to isolate&quot; a little bit delusional. (Classic example of Log4J bug, where monolith or microservices - once you're breached &quot;game over&quot;)";0
34258675;HackerNews;2023-01-05;"His point was that the comment was unclear if you'd also read it hastily :-)<p>I imagine his logic was something like: &quot;How can OOMs happen less often if you run more processes (possibly on the same machine)?&quot;, while your comment actually wants to say: &quot;if a specific service is affected by an OOM, with microservices only that specific microservice goes down, since it's probably running on its own hardware&quot;.";0
34256170;HackerNews;2023-01-05;Right I'm not advocating for one over the other, I was just explaining issues solved by microservices. Now instead of the OOM Killer taking your service down, you have a flaky NIC on another microservice box and now you need to figure out how to gracefully degrade.<p>I love working with microservices at the scale of $WORK, but we're Big Tech. I can't imagine why a 5 person startup would want k8s and microservices. You don't need that scale until you have more than 2 teams, and you're pushing at the very least 15 engineers at that point and usually the sales and marketing staff to make that investment worth it.;0
34254600;HackerNews;2023-01-05;I started at Amazon in 2001 when we had around 400 servers running the website, it was large, but it was around the scale that most Fortune 500 companies operate at.<p>I'll agree that a team of developers with 20 microservices sounds obviously wrong (which is really my point that the site should be divided around data and the orgs should probably reflect the needs of the data--not the other way around).  And Amazon back then didn't have that problem.;0
34252742;HackerNews;2023-01-04;I was part of a project that did exactly this - same monolithic code base with config flags that transformed it into web server, worker or scheduler. It allows scaling all parts separately, but I can confirm it's easy to introduce bugs if you're not careful. Since you're sharing the same DB, migrations also need to be backwards-compatible.<p>A cool side-effect is that you can usually run the whole thing in one app for development by just enabling all profiles - as opposed to some microservice architectures where you need  dozens of containers and DBs for replicating inter-service bugs.;0
34250197;HackerNews;2023-01-04;No, because that's not the service API. That's just a view over a table - an internal data structure used to represent some business domain model which should be properly exposed through some implementation-agnostic API. Service B should not care how service A implements it.<p>And the fact you must keep backward compatibility ( see the OP answer above) at the implementation level shows how fragile this approach is - you will never be able to change a database schema <i>as you wish</i> just because you have consumers that rely on the internal details of your implementation - a table. If you want to change a field from char to int, you can't. How is it important for service B to know that level of detail? An API could still expose a domain model as char, if you want to, and maybe introducing new fields, new methods, whatever way. Or maybe nothing at all, maybe it's not necessary because the database field is never exposed but only used internally (!!).<p>On the other hand, if you expose a database agnostic API (e.g., http, rpc, ... whatever) you can even swap the underlying database and nobody will notice.<p>A good rule of thumb is: if I change the implementation, do I need to ask/tell another team? If the answer is yes, that is not a microservice.;0
34250116;HackerNews;2023-01-04;I was arguing the opposite, coordinated deployments already presumes more maturity than I was considering. I've only been at one company with same-day deployments. All the other places have been free-for-alls where each group determines their own release schedule, with their own pipelines. Managing deployments between dependent services thus requires significant coordination overhead (or none, because you are stuck with what you get until the other teams deliver your needs on their own timeline).<p>In chaotic environments like that, microservices help with defining clear ownership of operational responsibility, though at the cost of clear responsibility for the overall distributed system. This comes at the cost of making it hard to develop, let alone ship, changes that impact multiple microservices (outside the scope of a single team, or closely related sibling teams).<p>The main point I was making was that, with a more monolithic system, managing that kind to organization disfunction, necessitates top-down, waterfall like control. So moving to microservices enables non-coordinated agility removing one layer of coordination problem (a the cost of other problems).;0
34249775;HackerNews;2023-01-04;I do think using something like Flatbuffers or CapnProto where the SerDe is removed (aside from the travel over the network) could be a huge win. Another thing I have always wanted to try is to develop a system using microservices with a RPC layer that uses immutable objects so you can later combine the services and convert RPCs to function calls.;0
34249558;HackerNews;2023-01-04;"&gt; Separate process vaults, HSMs and other techniques of offloading security credentials<p>How do give one module access to the vault/HSM without also giving any other code in the same process access? Even in the event of a security compromise. And that still doesn't address the problem of a vulnerability anywhere in the monolith potentially exposing any sensitive data in processes memory (such as user data including password).<p>&gt; The implication that anything other than a microservice architecture must be exclusively an uber executable doing literally everything, is naive.<p>Ok, replace &quot;microservices&quot; with &quot;service oriented architecture&quot;. I'm comparing specifically against a monolith where you have an &quot;uber executable doing literally everything&quot;.";0
34248958;HackerNews;2023-01-04;Yeah... The issue lies in cases where the decomposition is so extreme, that you end up not able to deploy independently.<p>And any benefit of a microservice owning it's own rDB is still, that schema changes aren't easily reversible. Specially when new, non predefined, data has been flowing in.<p>Stateless microservices are great, in the sense that you don't have to build multiple versions of APIs... but stateful microservices are just a PITA.;0
34248862;HackerNews;2023-01-04;"Apologies for the delay in a reply. I think this has been a constructive discussion certainly for how I think about things.<p>&gt; Interfaces don't change under microservices. Communication by contract enshrines a contract. You must ensure that your API does not break legacy users no matter what changes you want to make going forward. You have committed to behaviour forevermore once you submit the contract to other teams.<p>I think this entails a couple of things.<p>Firstly, it's a trade-off. If we discover some incorrect assumption is baked in to both sides of an interface we're kind of stuck and have a hard time with the migration path going forward. This isn't unsolvable and paths exist to correct it, but they're substantially harder than just updating both parts in the same commit. It moves coordination overhead as a trade-off.<p>Secondly, what I think actually happens is that most companies using microservices aren't this disciplined and just end up bodging or implicitly coupling services. Probably the pattern I'm talking about is &quot;distributed monolith&quot;. Not the good kind where you just scale out your monolith but where you drink the microservices kool-aid and create &quot;microservices&quot; by adding network boundaries at random. This is the real-world application of microservices I have seen where I've seen it. I don't doubt some people can use it correctly with proper rigour. But my theory is the pattern took hold because using &quot;distributed monolith&quot; (appears to help / ) helps tame the complexity of a dynamic monolith. I find it incredibly hard to believe the niche pattern of microservices done correctly would have become so popularized otherwise.<p>&gt; You find little value in writing a specification for your work or you find little value in automatic validation that the program works according to your spec?<p>I find little value in providing that specification through the TDD approach or associated ceremony. I prefer as few tests as possible at as high a level as possible with as few mocks as possible. I'll take a single test that takes 15 seconds to run over 1000 tests running in milliseconds.<p>Again for me this is a question of &quot;what popularized this pattern?&quot;.<p>I think there's a lot of healthy debate to be had about how much testing is needed. I think TDD appeared to provide the kind of guarantees that are really helpful in a dynamic language and gained a lot of advocates that way. When I had to write some (type hint free) Python I naturally defaulted to writing TDD since keeping a large system in your head and error free is basically impossible without an exhaustive suite of tests. It's an approach that works very well in one context that applied to other contexts unquestioningly delivers a lot of pain.<p>Maybe you're lucky to have only worked with very deliberate and rigorous engineers in your career. Outside the top tier we're working with architecture astronauts and people who jump on whatever hype cycle happens to be passing which explains my anger with these concepts.";0
34248600;HackerNews;2023-01-04;"Giving me an example that is created to work explicitly at system/container level isn't the &quot;gotcha&quot; you think it is.(IAM profiles have their own limitations)<p>Separate process vaults, HSMs and other techniques of offloading security credentials - are the same for microservice architecture, as &quot;monolith&quot;.<p>The implication that anything other than a microservice architecture must be exclusively an uber executable doing literally everything, is naive.";0
34248267;HackerNews;2023-01-04;"Hey, we have a system like that at my company. Microservices are self contained and responsible for exposing their interface via SDKs created with a tRPC like library. Jump to definition works across the entire monorepo like a charm. Could you take a look and give me any feedback?  <a href=""https://github.com/rectech-holdings/umbrella-corp-boilerplate"">https://github.com/rectech-holdings/umbrella-corp-boilerplat...</a>";0
34248216;HackerNews;2023-01-04;Every organisation I've worked at that had microservices has had all of them released every other Thursday at the same time by the same pipeline because they are tied to the organisation scrum schedule. Also, most changes are part of epics that span multiple microservices. If you are gonna argue that properly done microservices don't have that problem you are free to practice your perfect microservices alongside perfect scrum, oop, and communism.;0
34247639;HackerNews;2023-01-04;"&gt; Boring tech club ftw<p>As a CTO, I couldn't agree more. For our internal product, we use 100% boring technologies. The most &quot;modern&quot; you'll find is a React SPA.<p>I sigh when clients want to go the microservices route for a team of just a few developers. When you want to use NextJs for their tables&amp;forms app. When they choose to use Kubernates instead of a couple EC2 instances.<p>Don't get me wrong, these technologies are great for us because we can charge more for the wasted human time developing these overengineered solutions. But I always, for my peace of mind, try to talk them out of them. Sometimes works, sometimes doesn't, at the end of the day it's their money.";0
34247592;HackerNews;2023-01-04;"A monolith can also scale vertically with mechanisms to redeploy on fatal errors. If all starts failing, you may have a problem. But you can get the same problems with a microservices that is in the critical path<p>Networks could have unexpected delays, routing errors and other glitches. At least with a monolith you can often find a stacktrace for debugging. I have seen startups that have limited traceability and logging when using micro services.<p>When a small startup has to manage &quot;scalable&quot; K8s infrastructure in the cloud, distributed tracing and monitoring is often not prioritized when you are a team of 5 developers trying to find a product market fit.<p>I am not against microservices (I work with them daily) but you just trade one type of stability problem with another";0
34246539;HackerNews;2023-01-04;"Sorry, you misunderstood.<p>When you book a cruise, your expectation is to get everything (including hotel stays before or after the cruise, along with flights to and from it) as a single package provided by the cruise vendor (or a travel agency).
So the &quot;reservation system&quot; must take care of all of that.<p>When I said &quot;4-5 different websites&quot; I was trying to explain the point that a 60 yo high-income guy is usually not interested in getting the cruise itself on Carnival.com, then go look for excursions on CarribeansExcursion.net and to book flights on Lufthansa.de or AirFrance.fr.<p>It was a remark on the way the Cruise business works, and why it is so, not about architecture.<p>(But, once again, I really believe that we are way off topic... personally I do not really feel like creating a &quot;Ask HN: are microservices a good choice for the cruise industry?&quot; but if someone feels like submitting one I will try to contribute).";0
34245487;HackerNews;2023-01-04;Not necessarily. But if the solution in this case is to start breaking up the monolith into smaller services owned by specific product teams, then you are moving towards microservices.;0
34245126;HackerNews;2023-01-04;Couple of calls is normal. But if you make everything a microservice. And there are dependencies between them, then by design its destined that some hotter loop eventually will contain rpc.;0
34244974;HackerNews;2023-01-04;Rewriting a module from one tech stack to another is not much harder when that module was a part of a monolith and not a separate service, except that you haven't paid the upfront cost of bootstrapping a new service, putting in RPC calls, etc. And in any case, starting a project as microservices is already a bad practice due to a number of reasons, the most important for me is that it's hard to change module boundaries, which you will most likely get wrong in a new project.;0
34244775;HackerNews;2023-01-04;If you have many app servers and they all run copies of the same app you can roll out new versions to a few servers at a time. You just have to handle the db update first but you need to do that with microservices anyway (they might use smaller databases and therefore making it somewhat easier).;0
34244741;HackerNews;2023-01-04;I think Amazon (and Google and other FAANG entities) work at another scale than 99.9% of the rest of the world. The problems they face are different, including the impact of data locality.<p>I've seen many systems where there are a few hundred to a few thousand users, not hundred of millions or billions of users. There can also be teams of 5-10 developers who manages +20 microservices. I still don't think those projects have the same needs and could have done something else.;0
34244732;HackerNews;2023-01-04;There are so many misconceptions about what microservices are or what problems they are trying to solve. Most people don't even experience the problems (yet or ever) they are meant to solve and they go straight to micro. 5 person teams making 5 services to power their product :faceplam:. A relatively simple b2b web application without any serious traffic also does not need microservices to handle its load.<p>People just read up on whatever seems to be the newest, coolest thing. The issue is that MS articles are usually coming from FAANG/ex-FANNG. These companies are solving problems that 99% of others do not.<p>As engineers we should be looking for the most effective solutions to a given business problem. Sadly, I see engineers with senior/staff titles just throwing cool tech terms/libs around. Boring tech club ftw;0
34244505;HackerNews;2023-01-04;So all your microservices implement sagas or other synchronisation patterns that ensure 100% data consistency?;0
34244230;HackerNews;2023-01-04;"I'm not making a case in favor of starting with microservices for your startup, that'd be insane, to say the least. I'm just disagreeing with &quot;scalability is a feature&quot;. A feature is every addition on top of your minimum viable product. If at some point it becomes apparent that the business needs scalability, then scalability becomes your minimum viable product.";0
34243670;HackerNews;2023-01-04;You can horizontally scale a monolith without going full microservices.;0
34243643;HackerNews;2023-01-04;I’d love for a language / framework that allows for an application to be composed of “modules” that can either be run in a single process, or deployed as multiple independently scalable processes, with a mostly transparent RPC system requiring minimal boilerplate.<p>My IDE should be able to easily traverse the call graph. My development environment should be simple to setup.<p>I’ve worked on microservices that required an insane amount of boilerplate to do simple things. Like 7 layers of controllers, clients, services, data services, etc, just to fetch a simple piece of data. And the developer experience of running dozens of services in a Kubernetes cluster running on my dev machine was awful.<p>Does anything like this exist?<p>I only dabbled many years ago but Erlang/OTP comes to mind.<p>And tRPC for TypeScript calls in browser and server.;0
34243505;HackerNews;2023-01-04;I don't completely agree here.<p>Yes, if you can't scale fast enough as you need to, it can hurt your business. Not being able to keep up with demand is a (luxury) problem that every business faces, not just in tech. They would often be called 'growing pains' in a business, and though they are bad, they rarely contribute to the failure of a company.<p>Starting a startup/service/platform with microservices before you even understand the bottlenecks/market fit/customers is usually not a good idea. You can come a very, very long way with a monolith before you hit performance and scalability limits. And once you do, you can always start breaking things up into smaller services for scalabity. Obviously you need to make sure you are scaling on time to keep up with demand.<p>'Nail it, then scale it', and 'premature optimization is the mother of all f-ups' are popular sayings for a reason.;0
34243492;HackerNews;2023-01-04;A benefit of microservices is that you can use specialised languages for different parts of the system. The core of your system might be written in Java but you might one to use Python for an ML heavy module. Nonetheless, I tend to agree that in an organisation with 100 microservices probably the ideal way would be to have 4 or 5 based on exceptions where you have modules that need a specific hardware profile (e.g. a lot of RAM) or a different programming language than your core system. Everything else could go into modules in a megaservice.;0
34243084;HackerNews;2023-01-04;"&gt; Servers can only get so big. If your monolith needs more resources than a single server can provide, then you can chop it up into microservices and each microservice can get its own beefy server. Then you can put a load balancer in front of a microservice and run it on N beefy servers.<p>I've almost never seen situations where a single request would need more resources available, than the entire server has (outside of large GPT models for text, though maybe that's because I couldn't afford beefy machines for that myself).<p>Instead, if your monolith needs X resources to run (overhead) and Y resources to serve your current load, then in case of increased load you can just setup another instance of your monolith in parallel with another set of X + Y resources (same configuration) and it will generally <i>almost</i> double your capacity.<p>Now, there can be some issues with this, such as needing to ensure either stateless APIs or sticky sessions, but both are generally regarded as solved problems (with a little bit of work). Monoliths themselves shouldn't be limited to running just a single instance and aren't that different from a scalability perspective than microservices.<p>Where microservices excel, however, is that you can observe individual services (e.g. systemd services or them running in containers) better and see when a particular service is misbehaving or scale them separately, as well as decrease that X overhead since each service has a smaller codebase when you have lots of instances running. This does come at the expense of increased operational complexity and possibly noisy network chatter, especially if you've drawn your service boundaries wrong.<p>However, at the same time I've seen actual monoliths that can never have more than one instance running due to problematic architecture, so therefore I propose the following wording (that I've heard elsewhere):<p><pre><code>  SINGLETONS - a monolithic application that can ever only have a single instance running, for example, when business processes are stored in memory for a bit, or have user sessions or something like that stored locally as well; these will ONLY ever scale VERTICALLY, unless you re-architect them
  MONOLITHS - applications that contain all of your project's logic in a single codebase, although multiple instances can be launched in parallel, depending on your needs; can be scaled BOTH VERTICALLY and HORIZONTALLY; they have more overhead though and observability can be a bit challenging
  MICROSERVICES - applications that contain a part of the total project's logic, typically across multiple separate codebases, possibly with shared library code, pieces of your project can be scaled separately, BOTH VERTICALLY and HORIZONTALLY; they are operationally more complex, can involve more network chatter and while you can observe how services perform, now you need to deal with distributed tracing
</code></pre>
Of course, there can be more nuance to it, like modular monoliths, that still have one codebase, but can have certain groups of functionality enabled or disabled. I actually wrote about that approach a while back, calling them &quot;moduliths&quot;: <a href=""https://blog.kronis.dev/articles/modulith-because-we-need-to-scale-but-we-also-cannot-afford-micro-services"" rel=""nofollow"">https://blog.kronis.dev/articles/modulith-because-we-need-to...</a><p>I don't actually expect anyone to use these particular terms, but I dislike when someone claims that monoliths have the issues of these &quot;singleton&quot; applications when in fact that's just because they've primarily worked with bad architectures. Sometimes they wouldn't need to shoot themselves in the foot with microservices if they could just extract their session data into Redis and their task queues into RabbitMQ. Other times, microservices actually make sense.";0
34242884;HackerNews;2023-01-04;I was initially quite enthusiastic about microservices as I saw Unix philosophy ingrained in it. Especially that each service would be lightweight and small. Instead, what I see is each service tending towards more complexity and code mass because people started adding more ideas to them like DDD. So, on top of the network and authentication code that now need to be added to each service, people started defining classes for each domain object, adding validation code and unit tests for them, layering each service like application, infrastructure, domain etc. Now we are building systems that are more complex both as individual services and aggregates. Much of that complexity does not serve any functional purpose and its utility is difficult to measure in other respects.<p>I'm glad that this post was written so that we can look at widely accepted ideas a little more critically.;0
34242517;HackerNews;2023-01-04;You have fifty (or 10,000) servers running your critical microservice in multiple AZs. You start a deployment to a single host. The shit hits the fan. You rollback that one host. If it looks fine, you leave it running for a few hours while various canaries and integration tests all hit it. If no red flags occur, you deploy another two, etc. You deploy to different AZs on different days. You can fail over to your critical service in different AZs because you previously ensured that the AZs are scaled so that they can handle that influx of traffic (didn't you?). You've tested that.<p>And that is <i>if it makes it to production</i>. Here is your fleet of test hosts using production data and being verified against the output of production servers.;0
34242502;HackerNews;2023-01-04;Microservices are one of the many AbstractAdapterVistorFactories of this generation of programmers.<p>Just because you can, doesn't mean you should.;0
34242443;HackerNews;2023-01-04;"&gt;As for slow startup, a server reboot can be quite excruciating when all these processes are competing to grind &amp; slog through their own copy of that 200+ MB and get situated.<p>You are writing microservices and then running them on the same server??";0
34242416;HackerNews;2023-01-04;"Modules vs Microservices, January 2023 edition<p>I've done monoliths and microservices. I've worked in startups, SMEs and at FAANGS. As usual, nothing in this article demonstrates that the person has significant experience of running either in production. They may have experience of <i>failure</i>.<p>In my experience, microservices are simply one possible scaling model for modules. Another way to scale a monolith is to just make the server bigger: the One Giant Server model.<p>If you have a fairly well defined product, that needs a small (&lt;30) number of engineers, then the One Giant Server model might be best for you. If you have a wide feature set, that requires &gt;50 engineers, then microservices is probably the way to go.<p>There is no noticeable transition from a well implemented monolith with a small team into a well implemented Giant Server with a small team. Possibly some engineers are worrying about cold start times for 1TB of RAM, but that's something that can happen well ahead of time, and hardware qualification is something one needs to do for microservices too. Some of the best examples of Giant Servers are developed by small teams of very well paid developers.<p>The transition from a monolith to a set of microservices, however is a very different affair. Unfortunately, the kind of projects that need to go microservices are often in a very poor state. Many such adventures one reads about are having to go to microservices because they've already gone to One Giant Server and those are now unable to handle the load. Usually these stories are accompanied by a history of blog posts about moving fast and breaking things, yolo, or whatever is cool. The transition to microservices is difficult because there are no meaningful modules: no modules, or modules that all use each other's classes and functions.<p>I don't believe that, once a particular scale is reached, microservices are a choice. They are either required or they are not. Either you can scale successfully with One Giant Server, or you can't.<p>The problem is that below a certain scale, microservices are a drag. And without microservices, it's very easy for inexperienced teams to fail to keep module discipline.";0
34242144;HackerNews;2023-01-04;"&gt;We are now attempting to solve this with caches and doing batch requests, but all of this created additional overhead that could have all been avoided by not using microservices.<p>&gt; especially since some of these services are not even in the same data center.<p>I think you need to answer why? If you can't put all of the services in one data center, then by definition you can't write a monolith either. If the monolith would happily run in one datacenter, then you should have all instances of your microservices in that one datacenter.<p>It surprised me that you would conclude that this is a problem with microservices. It's like if a particularly architect always punches you in the groin in every meeting, and you've concluded that architects are bad people, rather than this one architect is a bad person.";0
34242108;HackerNews;2023-01-04;That makes sense. I am still trying to understand why does it differ between a monolith and microservices. The app in the monolith can make the call to non-critical functionalities time-limited and fault-tolerant, just like a network call has a time-out and can return nothing (in a simplified manner, it can wrap that call with a timer and an exception handler).<p>I agree that microservices are suitable for large organization, where the organization practically has multiple products (which could be purchased from a vendor or sold to another company).;0
34242106;HackerNews;2023-01-04;"Each set of upstream hosts in nginx is a single instance of load balancing. You aren't load balancing across services, you're splitting traffic by service and then load balancing across instances of that service.<p>The split is inessential. You can just as easily have homogeneous backends &amp; one big load balancing pool. Instances within that pool can even have affinity for or ownership of particular records! The ability to load balance across nodes is not, as you claimed, a particular advantage of microservices.";0
34242049;HackerNews;2023-01-04;I don't see the affinity between microservices and locality. Any kind of distributed storage, including cache, is going to include a choice about how data are partitioned, ordered, and indexed. If you want certain records to be in memory on the same nodes, you should not need a separate cache cluster to accomplish that, let alone a separate cache service implementation.;0
34242018;HackerNews;2023-01-04;"Meta deploys as &quot;microservices&quot; with multiple monorepos...<p>Binaries are deployed and scaled independently as thrift services.<p>Tons of rpc.";0
34241952;HackerNews;2023-01-04;"&gt;scalability (being able to increase the amount of compute, memory and IO to the specific modules that need it).<p>I would like someone to spell this out. It seems to me people are claiming that if a single binary serves some CPU-bound requests and some memory-bound requests, and you give it more memory, then the memory gets &quot;wasted&quot; on the CPU-bound part. Or if you give it more CPU, the CPU gets wasted on the memory-bound part. But this kind of assignment of resources to code paths seems to be a <i>consequence</i> of microservices. In a single computer, single binary situation resources should not get used up unless the workload actually wants to use them. A compute-heavy thread doesn't cost heap. A big heap doesn't slow down a compute-heavy thread. What am I missing?";0
34241199;HackerNews;2023-01-04;I think all your points are correct but none of them address scalability. What do you do if your one efficient machine is too small for your problem? To be fair, not a lot of problems reach that point in practice, definitely not every problem a microservice is written for.<p>It might still be completely viable to rewrite something so that it's only 10% as efficient but you can scale it horizontally easily.;0
34241063;HackerNews;2023-01-04;Most features in a modern app are not critical functionality, though.<p>For instance, in a shopping site, why should a crash in the recommendations engine result in a non-functional webpage (rather than a working purchase page with no recommendations)?<p>Personally I think microservices start to make sense when you have several hundred developers (an environment I'm currently keen to never enter again - $work has 5 devs and might one day have 6).;0
34240461;HackerNews;2023-01-04;"&gt; Honestly a small shop probably shouldn't be doing microservices as a standard pattern outside of specific cases anyway though<p>And yet, that is exactly what gets done";0
34240449;HackerNews;2023-01-04;"Man, I wish my colleagues would read your comment (and at least question their believes for one brief moment)…<p>&gt; I disagree, in my opinion micro-services hinder scalability of deployment<p>…and of anything related to testing:<p>- Want to fire up the application in your pipeline to run E2E tests? Congratulations, you must now spin up the entire landscape of microservices in k8s. First, however, you need to figure out which versions of all those microservices you want to test against in the first place, since every service is living in a separate repository and thus getting versioned separately.<p>- Want to provide test data to your application before running your tests? Well, you're looking at 100 stateful services – good luck with getting the state right everywhere.";0
34240439;HackerNews;2023-01-04;"However, there's another &quot;bonus here&quot; is that you have integration tests that have a better coverage.<p>Microservices don't make builds radically faster for the majority. People still split systems into larger services.";0
34240417;HackerNews;2023-01-04;With microservices you have to have a tradeoff - a monolith is inherently more testable at integration level, than a microservice based architecture.<p>There's a significant overhead to build and run tests at API level, that includes API versioning... and there's less of a need to version API inside a monolith.;0
34240273;HackerNews;2023-01-04;"Microservices is a different perspective than modules, there is a business perspective, referencing DDD; there is a data perspective; there is also an operations and maintenance perspective; there is also a technical architecture perspective";0
34240223;HackerNews;2023-01-04;How so? If functionality A is critical to functionality B, how will wrapping it in an HTTP call (microservices) reduce the damage from breaking functionality A?<p>I can see an advantage regarding resource hogging, but the flip side is the extra point of failure of network calls in microservices.<p>Not saying which is better, but deployment is orthogonal to logical dependence and correctness.;0
34240197;HackerNews;2023-01-04;The same techniques used to restrict intrusion, can be applied to a monolith.<p>Microservices aren't inherently more secure.;0
34240144;HackerNews;2023-01-04;"&gt;I'm not saying it is worth it, but yes, sometimes you can just inefficiently throw hardware resources at scaling problems<p>Microservice scaling is also an inefficient hardware scaling option.";0
34240091;HackerNews;2023-01-04;Not worshiping the Microservice, doesn't mean that you avoid services in different languages.<p>Not all engineers need to move around - DS and MLEs are generally useless on the frontend, and vice versa.;0
34239713;HackerNews;2023-01-04;You design your microservices so that they gracefully degrade.<p>So if a database service is not available you simply return stale, cached data until the service is back up.;0
34239678;HackerNews;2023-01-04;I think microservices turn this around - the idea is that if we ignore them as technical units and treat them as <i>organisational units</i> we can invert conway's law - it's much easier to change how microservices talk to each other than it is to chnage how people do.<p>But if you chnage the dataflow in a few microservices so that the accounts team no longer deals / works directly with the sales team you have chnaged the organisation.<p>plus it's way easier to monitor activity etc;0
34239265;HackerNews;2023-01-03;Sometimes. If the services are all interrelated, you’re as dead on the water with Microservices was you would be in a monolith.;0
34239236;HackerNews;2023-01-03;"Those human scaling problems are also security scaling problems; the Unix process model (and, in fact, the von Neumann architecture) doesn't separate modules in security capabilities, nor is it practical to do so.<p>Microservices allow your permissions to be clear and precise. Your database passwords are only loaded into the process that uses them. You can reason about &quot;If there's an RCE in this service, here's what it can do&quot;. Trying to tie that to monoliths is hard and ugly.";0
34239214;HackerNews;2023-01-03;I disagree, in my opinion micro-services hinder scalability of deployment, and development - at least the way I see most businesses use them. Typically they break out their code into disparate repositories, so now instead of one deployment you have to run 70 different ci/cds pipelines to get 70 microservices deployed, and repo A has no idea that repo B made breaking changes to their API. Or lib B pulled in lib D that now pollutes the class-path of lib A, who has a dependency on lib B. Often you need to mass deploy all of your microservices to resolve a critical vulnerability (think log4shell)<p>The solution to this is to use the right tool, a build system that supports monorepos like Bazel. Bazel solves this problem wonderfully. It only builds / tests / containerizes /  deploys (rules_k8s, rules_docker)  what needs to be rebuilt, retested, recontainerized, and redeployed. Builds are much faster, developers have God like visibility to all of an organizations' code, and can easily grep the entire code base and be assured their changes do not break other modules if Bazel test //... passes. It is language agnostic so you can implement your services in whatever language best suits it. It allows you to more easily manage transitive dependencies, manage versions globally across your org's codebase.<p>Of course Bazel has a steep learning curve so it will be years before it is adopted as widely as Maven, Gradle etc. But in the banks I've worked at it would've saved them tens of millions of dollars.<p>Also git would need to catch up to large codebases. I think Meta released a new source control tool recently that is similar to git but could handle large monorepos.;0
34239211;HackerNews;2023-01-03;"&gt; This is something folks have been doing long before the microservices hype.<p>Yes, and that's the point.<p>&gt; server bottlenecks are not the only thing (micro)services are trying to address.<p>The only other real advantage is scale of network throughput and isolation from other processes (in case some service is particularly volatile or prone to errors). Even those are a stretch as they're both solved/solvable by modern infra and just isolating code into its own job server (technically a &quot;microservice&quot;).";0
34238591;HackerNews;2023-01-03;"&gt; A sane thing to do.<p>This is incredibly subjective, and contingent on the size and type of engineering org you work in. For a small or firmly mid-sized shop? yea I can 100% see that being a sane thing to do. Honestly a small shop probably shouldn't be doing microservices as a standard pattern outside of specific cases anyway though<p>As soon as you have highly specialized teams/orgs to solve specific problems, this is no longer sane.";0
34238498;HackerNews;2023-01-03;Tech zoo sometimes considered to be an anti-pattern in microservices. By introducing a different language into your organization, you decrease the mobility of developers between code bases and dilute technical knowledge.;0
34238326;HackerNews;2023-01-03;When you move to microservices -- or rather, when you split your data across several DBs --  you sometimes end up basically reimplementing DB synchronization in business logic layers that <i>could</i> (sometimes, and depending on scalability constraints) be solved by using DB transactions.<p>So instead of a single DB transaction, often with a single SQL roundtrip, microservices can sometimes force through coordination of separate transactions to several DBs.;0
34238290;HackerNews;2023-01-03;You can have more than one server per monolith.<p>I don't think you actually understand what microservices are. You don't put a load balancer to load balance between different services. A load balancer balances trafic between servers of the same service or monolith.<p>Microservices mean the servers of different services run different code. A load balancer only works together with servers running the same code.;0
34238239;HackerNews;2023-01-03;"How does exception capture protect from all failures? The most obvious one I don't see it relating to is resource utilization, CPU, memory, threadpools, db connection pools, etc etc.<p>&gt; we’re trying to compensate bad design<p>No I think we're trying to compensate for developer mistakes and naivety. When you have dozens to hundreds of devs working on an application many of them are juniors and all of them are human and impactful mistakes happen. Just catching the right exceptions and handling them the right way does not protect against devs not catching the right exceptions and not handling them the right way, but microservices does.<p>Maybe you call that compensating for bad design, which is fair and in that case yes it is! And that compensation helps a large team move faster without perfecting design on every change.";0
34238151;HackerNews;2023-01-03;"&gt; unless you apply a large degree of discipline and engineering excellence to only rebuild changed modules while making sure no API contracts are broken<p>Isn't that exactly what's required when you're deploying microservices independently of each other? (With the difference of the interface not being an ABI but network calls/RPC/REST.)";0
34238093;HackerNews;2023-01-03;"&gt; However one of the unexpected consequences is that we are now doing a lot of network calls between these microservices<p>I wouldn't call that entirely unexpected. :-) It's a rather well-known issue:<p><pre><code>  Microservices

  grug wonder why big brain take hardest problem, factoring system correctly, and introduce network call too

  seem very confusing to grug
</code></pre>
(from <a href=""https://grugbrain.dev"" rel=""nofollow"">https://grugbrain.dev</a>)";0
34238052;HackerNews;2023-01-03;"&gt; most companies will never experience the level of scale of 2013 Twitter<p>I fully agree with your argument. Then again, as mentioned elsewhere in this discussion, microservices are often not introduced to solve a scalability problem but an organizational one and there are many organizations that have more engineers than Twitter (had).<p>Personally, I still don't buy that argument because by solving one organizational problem one risks creating a different one, as this blog post[0] illustrates:<p>&gt; […] Uber has grown to around 2,200 critical microservices<p>Unsurprisingly, that same post notes that<p>&gt; […] in recent years people have begun to decry microservices for their tendency to greatly increase complexity, sometimes making even trivial features difficult to build. […] we experienced these tradeoffs first hand<p>I'm getting very strong Wingman/Galactus[1] vibes here.<p>[0]: <a href=""https://web.archive.org/web/20221105153616/https://www.uber.com/blog/microservice-architecture/"" rel=""nofollow"">https://web.archive.org/web/20221105153616/https://www.uber....</a><p>[1]: <a href=""https://www.youtube.com/watch?v=y8OnoxKotPQ"">https://www.youtube.com/watch?v=y8OnoxKotPQ</a>";0
34237943;HackerNews;2023-01-03;This is something folks have been doing long before the microservices hype.<p>That said, server bottlenecks are not the only thing (micro)services are trying to address.;0
34237804;HackerNews;2023-01-03;If you have a truly modularized monolith, you can have a directed graph of dependent libraries, the leaves of which are different services that can start up. You can individually deploy leaf services and only their dependent code will go out. You can then rationalize which services can go down based on their dependency tree. If email is close to a root library, then yes a regression in it could bring everything down. If email is a leaf service, its code won’t even be deployed to most of the parallel services.<p>You can then have a pretty flexible trade off between the convenience of having email be a rooted library against the trade off of keeping it a lead service (the implication being that leaf services can talk to one another over the network via service stubs, rest, what have you).<p>This is SOA (Service Oriented Architecture), which should be considered in the midst of the microservice / monolith conversation.;0
34237725;HackerNews;2023-01-03;"One other thing they give you at a large organization is flexibility in your stack<p>If a team wants to try out a different language, or hosting model, or even just framework/tooling, those things can be really hard to do within the same codebase; much easier when your only contract is handling JSON requests. And if your whole organization is totally locked into a single stack, it's hard to keep evolving on some axes<p>(I'm generally against microservices, but this is one of the more compelling arguments I've heard for them, though it still wouldn't mean you need to eagerly break things up without a specific reason)";0
34237677;HackerNews;2023-01-03;"&gt; scalability (being able to increase the amount of compute, memory and IO to the specific modules that need it).<p>I gave a talk [1] about scalability of Java systems on Kubernetes, and one of my recommendations is that Java-based systems - or any system on a runtime similar to the JVM, like CLR or even Go - should be scaled diagonally. Efficiency is the word.<p>While horizontal scaling can easily address most performance issues and load demand, in most cases it is the least efficient way for Java (and again, I risk saying .NET and Go), as these systems struggle with CPU throttling and garbage collectors.<p>In short, and exemplifying: one container with 2 CPUs and 2GB of RAM will allow the JVM to perform better, in general, than 2 containers with 1 CPU/1GB RAM each. That said, customers shouldn't be scaling horizontally to any amount more than what is adequately reasonable for resiliency, or unless the bottleneck is somewhere like disk access. For performance on the other hand, customers should be scaling vertically.<p>And Kubernetes VPA is already available. People just need to use it properly and smartly. If a Kubernetes admin believes a particular pod should double in number of replicas, the admin should consider: &quot;would this microservice benefit even more from 1.5x more CPU/Memory than 2x more replicas?&quot; and I bet to say that, in general, yes.<p>[1] <a href=""https://www.youtube.com/watch?v=wApqCjHWF8Q"">https://www.youtube.com/watch?v=wApqCjHWF8Q</a>";0
34237654;HackerNews;2023-01-03;"&gt;&gt;they force alignment of dependencies and their versions<p>&gt;A sane thing to do. Better yet to do it in a global fashion, along with integration tests.<p>But brutally difficult at scale. If you have hundreds of dependencies, a normal case, what do you do when one part of the monolith needs to update a dependency, but that requires you update it for all consumers of the dependency's API, and another consumer is not compatible with the new version?<p>On a large project, dependency updates happen daily. Trying to do every dependency update is a non-starter. No one has that bandwidth. The larger your module is, the more dependencies you have to update, and the more different ways they are used, so you are more likely to get update conflicts.<p>This doesn't say you need microservices, but the larger your module is, the further into dependency hell you will likely end up.";0
34237493;HackerNews;2023-01-03;"<i>&gt; Whether it's your HTTP API interface changing</i><p>Interfaces don't change under microservices. Communication by contract enshrines a contract. You <i>must</i> ensure that your API does not break legacy users no matter what changes you want to make going forward. You have committed to behaviour forevermore once you submit the contract to other teams.<p>This may be another reason why IPC is often preferred over straight function calls as some languages, particularly those with static types, make extending functionality without breakage quite hard. An HTTP API can more easily resort to tricks to return different results to different callers.<p><i>&gt; I think the red-green-refactor loop of TDD doesn't bring much.</i><p>You find little value in writing a specification for your work or you find little value in automatic validation that the program works according to your spec?<p>&quot;Red-green-refactor&quot; is a little more specific in that it says that you should write a spec only for the work you know you are going to work on in the short term, whereas TDD in general leaves room for things like writing the entire application's spec before getting down to business. I think this is most practical in the real world, generally speaking. Often you don't know what your entire application should do in the beginning, making writing a full spec unrealistic.<p><i>&gt; I've never seen it applied well on a statically typed codebase</i><p>Interesting, as I have only ever seen specifications (be it TDD or &quot;Word documents&quot;) written for work that is done in statically typed languages. In my experience, the dynamic programming languages tend to attract the cowboy coders who don't understand why other (future) developers need more complete documentation or why specs are important and have no care to see that those things are done.";0
34237473;HackerNews;2023-01-03;Proper design in a monolith would also protect you from failures of non-vital services (e.g. through exception capture).<p>So it seems like we’re trying to compensate bad design with microservices. It’s orthogonal IMO.;0
34237287;HackerNews;2023-01-03;"&gt; I don't really think microservices are fundamentally more scalable<p>It depends on what you are scaling. I think microservices are fundamentally more scalable for deployment, since changes can be rolled out only to the services that changed, rather than everywhere. Unless your language and runtime support hot-loading individual modules at runtime.";0
34237184;HackerNews;2023-01-03;"# Microservices<p>Agreed the same database gets difficult but I guess, where two things need to change dependently there's coordination overhead, that's inescapable. You can in general use e.g. schemas to keep domains fairly separate. Whether it's your HTTP API interface changing or the change needs to be coordinated in the same process I don't think you have a way to avoid these meetings. (or like the 3rd party team I work with you just change your HTTP API and break production without telling us :shrug:).<p>I guess my point is languages like Java and C# are much maligned for their &quot;boilerplate&quot; and it doesn't let 10x genius programmers go brrrrrr etc. But that boilerplate serves a purpose. Projects (in C#, I can't speak to Java but I believe it has a similar concept) compile to separate .dll's, or .so's. In general a project will publicly expose interfaces, i.e. contracts, and keep its internals encapsulated. Crucially projects all live in the same codebase in the same monolith, they're folder/directory level separation, but on steroids. There are tricks with attributes and reflection that can break this separation but with the additional constraint that dependencies cannot be circular you're forced to make decisions about where exactly things live. This is where the dynamic crowd throw up their hands and say &quot;there are so many layers of pointless abstraction!&quot;. I'd agree these languages tend to too many layers but the layers provide the foundation which can support a project growing from 1-2 devs all the way through to 50+.<p>I'm maybe finally becoming a grumpy old programmer and I'm glad much of the consensus is swinging away from the no-types, no schema, no rules position of the past decade. People forgot Chesterton's fence and decided the layers didn't provide anything, then they added them back, as network boundaries, which was indescribably worse and more of a headache.<p># Testing<p>I guess it's a semantics debate really. I think the red-green-refactor loop of TDD doesn't bring much. I've never seen it applied well on a statically typed codebase and where I've seen advocates try and apply it I've seen them tunnel-vision to suboptimal outcomes in order to fulfil the ceremonial needs of the process.<p>I think a few tests that take place at the project/dll/so boundary and use as much of the real dependencies as possible are far preferable to high coverage. This is probably a no-true-Scotsman area of debate. Maybe TDD has been done properly and productively by some groups, I've never seen it and no one I've met ever has (check out my confirmation bias!).";0
34237089;HackerNews;2023-01-03;What it is is using the wrong solution for a problem. Vice-versa the number of devs who justify monolithic apps is absurd. The justification of microservices is just as problematic.<p>It is about striking a balance. No reason should something be overly compounded or overly broken up.;0
34237080;HackerNews;2023-01-03;Another benefit of microservices is it allows you to have a permission boundary, which can restrict the scope of damage if a single server/service is compromised.<p>And for that matter it can (but not necessarily) limit how much damage a bad code release can do.<p>Of course you don't get those benefits for free just by using microservices, but impleminting those kind if boundaries in a monolith is a lot harder.;0
34237051;HackerNews;2023-01-03;"Answer is no.<p>It is about where the shoe fits.  If you become too heavily dependent on modules you risk module incompatibility due to version changes. If you are not the maintainer of your dependent module you hold a lot of risk. You don't get that with microservices.<p>If you focus too much on microservices you introduce virtualized bloat that adds too much complexity and complexities are bad.<p>Modules are like someone saying it is great to be monolithic. Noone should upright justify an overly complicated application or a monolithic one.<p>The solution is to build common modules that are maintainable. You follow that up with multi-container pods have them talk low level between each other.<p>Stricking that exact balance is what is needed not striking odd justifications for failed models. It is about, &quot;What does my application do?&quot; and answering with which design benefits it the most.";0
34236913;HackerNews;2023-01-03;"&gt;doesn't monolith usually refer to one really heavy app?<p>No. Backend Server clusters are around almost as long as the internet exists.<p>&gt;I would guess most of the time there's a high expense (lots of memory) in duplicating the entire monolith?<p>That's right, but there's a gotcha. Everytime you split your monolith into parts, that doesn't mean that each part will consume 1/n of original monolith startup resource. There will be a floor of memory usage.
Consider 1 monolith that eats up 1GB to startup vs 4 microservices that uses 512MB each. Right from start you doubled the wasted memory from 1GB to 2GB. That only gets worse the more services are created.
Another problem is that microservice/cloud folks loves to create anemic machines. Usually setting up 512MB RAM and half a core cpu to a service that needs 380mb minimum :) Thats 75% overhead and 25% of working memory. It's bonkers.";0
34236910;HackerNews;2023-01-03;Why would using microservices reduce the chance of outages? If you break a microservice that is vital for the system, you are as screwed as with a monolyth.;0
34236899;HackerNews;2023-01-03;"It sounds like creating problem, then spending time=money on fixing it and calling it a win?<p>There is a point when it all starts to make sense. But that point is when you go into billions worth business, hundreds of devs etc. And going there has large cost, especially for small/medium systems. And that cost is not one off - it's a day-to-day cost of introducing changes. It's orders of magnitude chaper and faster (head cound wise) to do changes in ie. single versioned monorepo where everything is deployed at once, as single working, tested, migrated version than doing progressive releases for each piece keeping it all backward compatible at micro level. Again - it does make sense at scale (hundreds of devs kind of scale), but saying your 5 devs team moves faster because they can work on 120 micoservices independently is complete nonsense.<p>In other words micoservices make sense when you don't really have other options, you have to do it, it's not good start-with default at all; and frankly Sam Newman says it in &quot;Building Microservices&quot; and so do people who know what they're talking about. For some reason juniors want to start there and look at anything non-microservice as legacy.";0
34236872;HackerNews;2023-01-03;"I am a front end dev, so microservice architecture is not something I am super familiar with my day-to-day, but I occasionally do work in our back end project, which is a service-oriented java project. The project is broken down into different services, but they are aggregated in &quot;parent&quot; projects, where the parent declares the modules in the pom.xml (in the &quot;modules&quot; xml declaration).<p>I like that architecture - the services are abstracted with clearly defined boundaries and they are easy to navigate / discover. Not sure if Java modules satisfy the concerns of the author or other HN users, but I liked it.";0
34236859;HackerNews;2023-01-03;"Unexpected?!<p>Either way, one of my biggest pet peeves is the near-ubiquitous use of HTTP &amp; JSON in microservice architectures.  There's always going to be overhead in networked servies, but this is a place where binary protocols (especially ones like Cap'n Proto) really shine.";0
34236840;HackerNews;2023-01-03;"I think microservices are fine for businesses which have a general idea of how 'big' things could get with respect to their platforms. But if you're more in a company that has many one-off programs, scripts, and the like then maybe microservices aren't a thing that you need. Better organization is good, but that shouldn't be just a microservices thing, everyone benefits when you've organized not just individual projects and their source code but also just organizing what does what with external documents that can be updated to explain their purpose is useful. There's nothing worse than looking at source code or an program by name only to ask, &quot;what is this thing?&quot;";0
34236753;HackerNews;2023-01-03;I have done a lot of service development for what would be called microservices.<p>The article gets it right in ny opinion.<p>1. It has a lot to do with organisational constraints.<p>2. It has a lot to do with service boundaries. If services are chatty they should be coupled.<p>3. What a service does must be specified in regards to which data it takes in and what data it outputs. This data can and should be events.<p>4. Services should rely and work together based on messaging in terms of queues, topics, streams etc.<p>5. Services are often data enrichment services where one service enrich some data based on an event/data.<p>6. You never test more than one service at a time.<p>7. Services should not share code which is vibrant or short lived in terms of being updated frequently.<p>8. Conquer and divide. Start by developing a small monolith for what you expect could be multiple service. Then divide the code. And divide it so each coming service own its own implementation as per not sharing code between them.<p>9. IaaS is important. You should be able to push deploy and a service is setup with all of its infrastructure dependencies.<p>10. Domain boundaries are important. Structure teams around them based in a certain capability. E.g. Customers, Bookings, Invoicing. Each team owns a capability and its underlying services.<p>11. Make it possible for other teams to read all your data. They might need it for something they are solving.<p>12. Don't use kubernetes or any other orchestra unless you can't it what you want with cloud provider paas. Kubernetes is a beast and will put you to the test.<p>13. Services will not solve your problems if you do not understand how things communicate, fail and recovers.<p>14. Everything is eventually consistent. The mindset around that will take time to cope with.<p>A lot more...;0
34236715;HackerNews;2023-01-03;It's not really about what's better, it's about whats been standardized upon.<p>I'm sure I could gain many of the advantages of microservices through an OSGi monolith, however, an OSGi monolith is not the hot thing of the day, I'm likely to be poorly supported if I go down this route.<p>Ideally I also want some of my developers to be able to write their server on the node ecosystem - if they so choose, and don't want updating the language my modules run on (in this case the JVM) to be the biggest pain of the century.<p>Besides, once my MAU is in the hundreds of thousands, I probably want to scale the different parts of my system independently anyway - so different concerns come in to play.;0
34236555;HackerNews;2023-01-03;Sure poorly implemented solutions  rarely solve problems well.<p>But implementing microservices is not an unsolvable problem.  It's a problem that 1000s of organizations have solved.;0
34236348;HackerNews;2023-01-03;"While we are on the topic, I would like to point out that the decoupled nature of microservices is governed by queuing theory. Microservices are especially susceptible to positive feedback loops and cascading failures.<p>Going back to systems thinking, flow control (concurrency and rate limiting) and API scheduling (weighted fair queuing) are needed to make these architectures work at any scale. Open source projects such as Aperture[0] can help tackle some these issues.<p>[0] <a href=""https://github.com/fluxninja/aperture"">https://github.com/fluxninja/aperture</a>";0
34236339;HackerNews;2023-01-03;"Yeah, it's bin packing, not straight efficiency. Also, people seem to exaggerate latency for RPC calls. I often get the feeling that people who make these latency criticisms have been burned by some nominal &quot;microservices&quot; architecture in which an API call is made in a hot loop or something.<p>Network latency is real, and some systems really do run on a tight latency budget, but most sane architectures will just do a couple of calls to a database (same performance as monolith) and maybe a transitive service call or something.";0
34236336;HackerNews;2023-01-03;Another way to look at this is microservices reduce the blast radius of problems.;0
34236326;HackerNews;2023-01-03;How do microservices help here? You can deploy a monolith 10 times and have the same risk distribution.;0
34236280;HackerNews;2023-01-03;So tell me, who is making microservices for calls that could be done wholly in memory? How are you handling rollbacks and such for this in memory logic?<p>Aren't you still writing out to external data stores?  If that's the case then its really not a comparison of in process to a RPC, it just two RPC hops now, no?;0
34236212;HackerNews;2023-01-03;"&gt; There's two technical problems that microservices purport to solve<p>There's a third technical problem that microservices solve, and it's my favorite: isolation. With monoliths, you provide all of your secrets to the whole monolith, and a vulnerability in one module can access any secret available to any other module. Similarly, a bug that takes down one module takes down the whole process (and probably the whole app when you consider cascading failures). In most mainstream languages, every module (even the most unimportant, leaf node on the dependency tree) needs to be scoured for potential security or reliability issues because any module can bring the whole thing down.<p>This isn't solved at the language level in most mainstream languages. The Erlang family of languages generally address the reliability issue, but most languages punt on it altogether.<p>&gt; The real reason that microservices may make sense is because they keep people honest around module boundaries.<p>Agreed. Microservices, like static type systems, are &quot;rails&quot;. Most organizations have people who will take shortcuts in the name of expedience, and systems with rails disincentivize these shortcuts (importantly, they don't <i>preclude</i> them).";0
34236200;HackerNews;2023-01-03;You'll need to support loading two versions of each DLL into memory and invoking both on some percentage of servers to be able to replicate a microservice though.<p>The important part of microservices isn't just API boundaries,  it's lifecycle management. This CAN be done with a DLL or JAR, but it's MUCH harder today.;0
34236158;HackerNews;2023-01-03;That's just a microservice enabled by configuration.;0
34236123;HackerNews;2023-01-03;"&gt; If done right microservices is a way to transform part of your organization challenge into a technical one, which for many organizations is the right move.<p>Famous last words, if done right...  Or you just multiply your organizational issue with a technical one.";0
34236106;HackerNews;2023-01-03;"&gt;How the hell... like... who decided to do Microservices in the first place if they didn't know this?<p>Microservices can have both design utility and simultaneously been a major fad.<p>Lurking reddit and HN you can watch development fashions come and go. It's really really profoundly hard to hold a sober conversation on splitting merits from limitations in the middle of the boom.<p>tl;dr: gartner_hype_cycle.png";0
34236075;HackerNews;2023-01-03;Microservices enable independent scale _domains_. This means they can be more scaleable and dense, but it's not necessarily true.;0
34236052;HackerNews;2023-01-03;"&gt; A better rule is for one service to own writes for a table, and other services can only read that table,<p>Been there: how do you handle schema changes?<p>One of the advantages that having a separate schema per service provides is that services can communicate only via APIs, which decouples them allowing you to deploy them independently, which is at the heart of microservices (and continuous delivery).<p>The way I see it today: everyone complains about microservices, 12 factor apps, kubernetes, docker, etc., and I agree they are overengineering for small tools, services, etc., but if done right, they offer an agility that monoliths simply can't provide. And today it's really all about moving fast(er) than yesterday.";0
34236043;HackerNews;2023-01-03;"&gt; but I don't see how monoliths can keep up with developer velocity when an organization reaches thousands of developers.<p>You're likely right.<p>I think what most detractors of microservices are pointing to is that most companies don't reach thousands of devs in size. Or even hundreds.";0
34235959;HackerNews;2023-01-03;That’s a really interesting point - something that could probably be addressed by module-level logging and metrics. That said, even as a pro-monolith advocate, I can see why it’s preferable to not allow any one module/service to consume all the resources for your service in the first place. The service boundaries in microservice architectures can help enforce resource limits that otherwise go unchecked in a larger application.;0
34235849;HackerNews;2023-01-03;I was working at Amazon when they started transitioning from monolith to microservices, and the big win there was locality of data and caching.<p>All of the catalog data was moved to a service which only served catalog data so its cache was optimized for catalog data and the load balancers in front of it could optimize across that cache with consistent hashing.<p>This was different from the front end web tier which used consistent hashing to pin customers to individual webservers.<p>For stuff like order history or customer data, those services sat in front of their respective databases and provided consistent hashing along with availability (providing a consistent write-through cache in front of the SQL databases used at the time).<p>I wouldn't call those areas where it makes things more efficient rare, but actually common, and it comes from letting your data dictate your microservices rather than letting your organiation dictate your microservices (although if teams own data, then they should line up).;0
34235714;HackerNews;2023-01-03;"If they wrote that using a bunch of LabVIEW microservices you could replace the services one-by-one with C/Ada until the whole thing was no longer LabVIEW.<p>This is generally what I think the best part about microservices are; an easy way to improve upon the MVP in any dimension. Re-writing a whole monolith can take forever and probably will introduce a ton of bugs. But incrementally re-writing microservices won't stop feature development and is easy to A/B test for correctness.";0
34235675;HackerNews;2023-01-03;"As a general rule of thumb, fully explore and exhaust your &quot;monolith&quot; options before you switch to Microservices. They quite often create more problems than they solve.";0
34235624;HackerNews;2023-01-03;"&gt; Servers can only get so big. If your monolith needs more resources than a single server can provide, then you can chop it up into microservices<p>200 threads, 12TB of RAM, with a pipe upwards of 200GB/s.  This isn't even as big as you can go, this is a reasonable off the shelf item.  If your service doesn't need more than this, maybe don't break it up. :)<p>I believe that this level of service can no longer accurately be described as &quot;micro&quot;.";0
34235493;HackerNews;2023-01-03;"&gt; Microservices are less efficient, but are still more scalable.<p>Not at all. You can run your monolith on multiple nodes just as you can do with microservices. If anything, it scales much better as you reduce network interactions.";0
34235466;HackerNews;2023-01-03;"I didn't get this article. It seems like it contains two things:
1. It was already invented before
2. All the wrong reasons why people decide to use microservices.<p>But author clearly avoided the real reasons why you actually need to split stuff into separate services:
1. Some processes shouldn't be mixed in the same runtime. Simple example batch/streaming vs 'realtime'. Or important and not important.
2. Some things need different stack, runtimes, frameworks. And is much easier to separate them instead of trying to make them coexist.<p>And regarding 'it was already in Simpsons' argument, I don't think it should even be considered as argument. If you are old enough to remember EJB, you don't need to be explained why it was a bad idea from the start. Why services built on EJB were never scalable or maintainable. So even if EJB claimed to cover the same features as microservices right now, I'm pretty sure EJB won't be a framework of choice for anybody now.<p>Obviously considering microservices as the only _right_ solution is stupid. But same goes for pretty much any technology out there.";0
34235432;HackerNews;2023-01-03;"I don't understand the argument around microservices purporting to fix scalability. Say your system has modules A, B and C in one app, and that A requires more resources while B and C are relatively unused. Won't B and C just <i>run less</i> and thereby use appropriately fewer resources from within the same system as A? Are microservices just an aesthetic separation (it feels nice to know you're &quot;only&quot; scaling up A)?";0
34235390;HackerNews;2023-01-03;"You are absolutely right: you do not know much about cruises.<p>The things you listed are ... 4-5 different <i>applications</i>, mostly running directly on the ship(s) and what is conspicuously missing are the parts that are managed shoreside, like:<p>Itinerary planning (your product is one or more cruises: therefore you need to preplan the itineraries, which ships to use, when you will enter each port and when you will leave it, and so on... try to imagine this like a mix between hotel management and flight company management)
Inventory management (i.e. Reservation).<p>You mention &quot;bookings&quot; like a microservice. This could work for <i>ferry</i> line, where you are basically selling a ticket for a single trip, most of the time with no personal accommodation (except maybe for the car).<p>A Cruise booking usually comes with a ton of ancillary services (e.g. I live in Berlin and I want to take a cruise in the Caribbeans... therefore I need a flight to get there and back. This could be provided by a charter flight or a normal airline ... in either cases the ticket will be part of the booking itself) - take in account that cruise customers are mostly middle-aged or older and relatively affluent, therefore the last thing they would like to do is to create their own itinerary by booking services on 4-5 different websites.<p>(But I suppose it is better to stop there, we are really OT now)";0
34235273;HackerNews;2023-01-03;"<i>&gt; Why can't the teams work on the same codebase and the same database?</i><p>The same database is tricky because one team might want to change the schema, breaking another team's work. You then need to have meetings to discuss the changes that will work for all parties and you've broken &quot;communicate only by contract&quot;, and therefore no longer doing microservices. If you can ensure that there is no way for teams to trample over each other then you could use the same database.<p>The same codebase is more feasible as long as the team boundary separation is clear. You are likely already doing microservices with other teams when you import third-party libraries. In practice, though, much like the database problem maintaining boundary separation is difficult if you can easily reach into other team's code, so often each team's work will be parted into distinct codebases using IPC between them to ensure that the separation is unbreakable. This certainly isn't a requirement, though, just one way to keep people in line.<p><i>&gt; Testing is certainly a way to provide a self-verifying application. TDD is a toxic, hype-driven, mess</i><p>Testing is a development tool to help test the functionality of a feature. If you are faced with a dynamic language you very well might write tests to ensure that types are handled correctly. Static types can, indeed, relieve the need for some tests.<p>TDD, on the other hand, is a documentation tool to relay to other developers what functionality is intended to provide and how it is meant to be used. It is strange to think that documentation is toxic. Before TDD we wrote &quot;Word documents&quot; containing the same information, but often found that the code didn't do what the documentation said it did. What TDD realized is if the documentation is also executable then you can have the machine prove that the application behaves according to spec. It's not exactly magic.";0
34235204;HackerNews;2023-01-03;"&gt; My take: do Microservices all you want, but don't organize teams around the services!<p>Exactly. In order to reap the benefits of modular/Microservices architecture, you need teams to be organized around product/feature verticals.<p>IMO it’s not about the internals of a product/service architecture, but about encapsulating, isolating, and formalizing inter-organizational dependencies.";0
34235159;HackerNews;2023-01-03;"Mostly valid, but...<p>On the RAM front, I am now approaching terabyte levels of services for what would be gigabyte levels of monolith. The reason is that I have to deal with mostly duplicate RAM - the same 200+ MB of framework crud replicated in every process. In fact a lot of microservice advocates insist &quot;RAM is cheap!&quot; until reality hits, especially forgetting the cost is replicated in every development/testing environment.<p>As for slow startup, a server reboot can be quite excruciating when all these processes are competing to grind &amp; slog through their own copy of that 200+ MB and get situated. In my case, each new &amp; improved microservice alone boots slower than the original legacy monolith, which is just plain dumb, but it's the tech stack I'm stuck with.";0
34235125;HackerNews;2023-01-03;Layers, Not Modules, Not Microservices Like donkeys, onions, caching, networking, my feelings and perceptions.;0
34235087;HackerNews;2023-01-03;"You know, I don't really think microservices are fundamentally more scalable.  Rather, they expose scaling issues more readily.<p>When you have a giant monolith with the &quot;load the world&quot; endpoint, it can be tricky to pinpoint the the &quot;load the world&quot; endpoint (or, as is often the case, endpoint*s*) is what's causing issues.  Instead, everyone just tends to think of it as &quot;the x app having problems.&quot;<p>When you bust the monolith into the x/y/z, and x and z got the &quot;load the world&quot; endpoints, that starts the fires of &quot;x is constantly killing things and it's only doing this one thing.  How do we do that better?&quot;<p>That allows you to better prioritize fixing those scaling problems.";0
34235045;HackerNews;2023-01-03;"# Microservices<p>I think at the root this idea that Microservices provide this technical solution to a social issue, coordinating teams at scale, hides the driving motivation.<p>Why can't the teams work on the same codebase and the same database? (again note my edited in disclaimer in the GP post that maybe at certain rare scales it's necessary). What is a well defined specification and why is it only a REST/proto/whatever network API? Why not a defined interface or project/library? Why aren't teams at this scale working in languages that support defining these things in code without adding a complicating, latency and error-inducing, network call?<p>Statically typed languages are just superior at encoding this &quot;well defined specification&quot;. It's a large part of their reason for being. Sure you can still bypass it and do reflection or other naughtiness, but we shouldn't pretend a network call is the only solution.<p># TDD<p><i>Testing</i> is certainly a way to provide a self-verifying application. TDD is a toxic, hype-driven, mess that has led many good developers astray. Static languages have their own devils here, mocking being chief among them (not to mention the Java clown brigade and their own enthusiastic adoption of -- originally Smalltalk conceived -- TDD).<p>I added TDD both to annoy people but also to illustrate the general point. These are both concepts derived from the obvious drawbacks of dynamically typed languages that are then treated as generalist answers to complexity in software.<p>If you'll allow me some pseudo-intellectual waffle, the complexity of a software system C_dynamic + C_software = C_total, that is, complexity of dynamically typed languages and their lack of rigour, plus complexity of software and the domain as a whole gives you total complexity. These approaches primarily target the dynamic complexity. Therefore introducing them and all attendant drawbacks in places where total complexity doesn't include the dynamic complexity because tools and approaches to remove this source of complexity are used actually worsens the entire field.";0
34235038;HackerNews;2023-01-03;If you really require that sort of isolation, then microservices are a bugridden, ad hoc implementation of half of Erlang.;0
34235011;HackerNews;2023-01-03;Any way you slice it, it's hard to manage/align/coordinate a 100 devs.<p>If done right microservices is a way to transform part of your organization challenge into a technical one, which for many organizations is the right move.<p>The biggest issue is if you aren't large enough to have challenging organizational issues it's much easier to just solve the very solvable organizational issues than implement and use microservices.;0
34234991;HackerNews;2023-01-03;"&gt; At the heart of microservices, we often find...<p>&gt; ... the Fallacies of Distributed Computing.<p>I feel like I’m taking crazy pills, but at least I’m not the only one. I think the only reason this fallacy has survived so long this cycle is because we currently have a generation of network cards that is so fast that processes can’t keep up with them. Which is an architectural problem, possibly at the application layer, the kernel layer, or the motherboard design. Or maybe all three. When that gets fixed there will be a million consultants to show the way to migrate off of microservices because of the 8 Fallacies.";0
34234977;HackerNews;2023-01-03;"Managers arranging work is _not_ why Conway's law is true though. I think it behooves one to look at the actual text of the &quot;law&quot;:<p>&gt; Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization's communication structure.<p>It doesn't matter WHO defines or does the work (the coders themselves in a team or the manager). It matters how communication is arranged. And communication naturally aligns itself along organizational and team boundaries.<p>When a group/person/whatever writes an API they are MOSTLY writing a document for other human beings. That is an act of communication. If you meet with someone everyday in a stand-up you're likely to put a less structured API between yourselves than if you meet with someone once a month, or once a year. You're also going to create a finer grained subdivision of the API for them as you're likely working on closely related posts of the problem.<p>Organization creates communication, and communication creates architecture. Therefore organization creates architecture.<p>&gt; Plus conway is just a ... neat idea, not a bound fate<p>It is in fact bound fate. Code is written to communicate with others.<p>People come together, they decide to solve a problem. They divide up that problem and create functions (an API), objects (an API), modules (an API), and services/microservices (an API). At each later they've written something that communicates with others. The structure of that code reflects the necessary communication to the other parties for their part of the problem. This the code is structured following the lines of communication in the organization.<p>Organization is how we structure communication (that's it's primary point) and thus organization = architecture + some wiggle room for communication paths defined outside that (say a SAFE feature team).";0
34234905;HackerNews;2023-01-03;"From what I can tell, Github transitioned over to micro-services ~2020 (<a href=""https://www.infoq.com/presentations/github-rails-monolith-microservices/"" rel=""nofollow"">https://www.infoq.com/presentations/github-rails-monolith-mi...</a>). By this point it had already grew to a scale that very few companies will ever reach.<p>I'm not sure at what point the monolith codebase became absolutely enormous, but I would bet that GitHub grew to 1M active users with a monolith just fine.<p>Micro-services might be necessary for the companies like Github, Twitter, Google that grow to be huge, but monoliths seem to work just fine for the vast majority of other companies.";0
34234904;HackerNews;2023-01-03;Microservices are less <i>efficient</i>, but are still more <i>scalable</i>.<p>Servers can only get so big. If your monolith needs more resources than a single server can provide, then you can chop it up into microservices and each microservice can get its own beefy server. Then you can put a load balancer in front of a microservice and run it on N beefy servers.<p>But this only matters at Facebook scale. I think most devs would be shocked at how much a single beefy server running efficient code can do.;0
34234879;HackerNews;2023-01-03;"The best experience I've had with modular code in the java space was osgi.  Very cool to be able to upload a new jar and have it start working just like that.  
Microservices and eda... not really a fan.  Yes you can release faster but operationalizing is a massive nightmare to me.  Of course one size doesn't fit all but I'm pretty convinced this is only a popular solution for now.";0
34234857;HackerNews;2023-01-03;Microservices, by definition, do not share a DB. If they do then you just have multiple processes in the same larger service.;0
34234840;HackerNews;2023-01-03;"I've been thinking for a while about how to architecture systems and I wonder if perhaps we could generalize something like Fuchsia's device driver stack design [1] for arbitrary systems and eliminate this monolithic vs microservice applications debate altogether.<p>In Fuchsia, the device driver stack can be roughly split into three layers:<p>* Drivers, which are components (~ libraries with added metadata) that both ingest and expose capabilities,<p>* A capability-oriented IPC layer that works both inside and across processes,<p>* Driver hosts, which are processes that host driver instances.<p>The system then has the mechanism to realize a device driver graph by creating device driver instances and connecting them together through the IPC layer. What is interesting however is that there's also a policy that describes how the system should create boundaries between device driver instances [2].<p>For example, the system could have a policy where everything is instantiated inside the same driver host to maximize performance by eliminating inter-process communication and context switches, or where every device driver is instantiated into its own dedicated driver host to increase security through process isolation, or some middle ground compromise depending on security vs performance concerns.<p>For me, it feels like the Docker-like containerization paradigm is essentially an extension of good old user processes and IPC that stops at the process boundary, without any concern about what's going on inside it. It's like stacking premade Lego sets together into an application. What if we could start from raw Lego bricks instead and let an external policy dictate how to assemble them at run-time into a monolithic application running on a single server, micro-services distributed across the world or whatever hybrid architecture we want, with these bricks being none the wiser?<p>Heck, if we decomposed operating systems into those bricks, we could even imagine policies that would also enable composing from the ground up, with applications sitting on top of unikernels, microkernels or whatever hybrid we desire...<p>[1] <a href=""https://fuchsia.dev/fuchsia-src/development/drivers/concepts/device_driver_model/protocol#process_protocol_mapping"" rel=""nofollow"">https://fuchsia.dev/fuchsia-src/development/drivers/concepts...</a><p>[2] <a href=""https://fuchsia.dev/fuchsia-src/development/drivers/concepts/device_driver_model/device-model#devices_drivers_and_driver_hosts"" rel=""nofollow"">https://fuchsia.dev/fuchsia-src/development/drivers/concepts...</a>";0
34234831;HackerNews;2023-01-03;Without the organizational benefits of a microservice you are just just making intermodular calls really slow, and fail intermittently.;0
34234813;HackerNews;2023-01-03;I don't think microservices are the answer to everything, but I don't see how monoliths can keep up with developer velocity when an organization reaches thousands of developers.<p>Monoliths are way slower to deploy than microservices, and when you have hundreds or thousands of changes going out every day, this means lots of changes being bundled together in the same deployment, and as a consequence, lots of bugs. Having to stop a deployment and roll it back every time a defect is sent to production would just make the whoe thing completely undeployable.<p>Microservices have some additional operational overhead, but they do allow much faster deployments and rollbacks without affecting the whole org.<p>Maybe I am biased, but I would love an explanation from the monolith-evangelist crowd on how to keep a monolith able to deploy multiple times a day and capable of rolling back changes when people are pushing hundreds of PRs every day.;0
34234796;HackerNews;2023-01-03;"Idk I feel like one of the benefits to uservices is isolation; not in design or architecture as many comments say, but isolation from one service affecting another.<p>If I run a monolith and one least-used module leaks memory real hard, the entire process crashes even though the most-used/more important modules were fine.<p>Of course it's possible to run modularised code such that they're sandboxed/resources are controlled - but at that point it's like...isn't this all the same concept? Managed monolith with modules vs microservices on something like k8s.<p>I feel like rather than microservices or modules or whatever we need a concept for a sliding context, from one function-&gt;one group of functions-&gt;one feature-&gt;one service-&gt;dependent services-&gt;all services-&gt;etc.<p>With an architecture like that it would surely be possible to run each higher tier of context in any way we wanted; as a monolith, containerised, as lambdas. And working on it would be a matter of isolating yourself to the context required to get your current task done.";0
34234790;HackerNews;2023-01-03;I just want to point out that for the second problem (scalability of CPU/memory/io), microservices almost always make things worse. Making an RPC necessarily implies serialization and deserialization of data, and nearly always also means sending data over a socket. Plus the fact that most services have some constant overhead of the footprint to run the RPC code and other things (healthchecking, stats collection, etc.) that is typically bundled into each service. And even if the extra CPU/memory isn't a big deal for you, doing RPCs is going to add latency, and if you get too many microservices the latency numbers can start really adding up and be very difficult to fix later.<p>Running code in a single process is MUCH lower overhead because you don't need to transit a network layer and you're generally just passing pointers to data around rather than serializing/deserializing it.<p>There are definitely some cases where using microservices does make things more CPU/memory efficient, but it's much rarer than people think. An example where you'd actually get efficiency would be something like a geofence service (imagine Uber, Doordash, etc.) where the geofence definitions are probably large and have to be stored in memory. Depending on how often geofence queries happen, it might be more efficient to have a small number of geofence service instances with the geofence definitions loaded in memory rather than having this logic as a module that many workers need to have loaded. But again, cases like this are much less common than the cases where services just lead to massive bloat.<p>I was working at Uber when they started transitioning from monolith to microservices, and pretty much universally splitting logic into microservices required provisioning many more servers and were disastrous for end-to-end latency times.;0
34234696;HackerNews;2023-01-03;"I always love that circular logic.<p>&quot;Hey our developers can't make modules correctly! Let's make the API boundaries using HTTP calls instead, then they'll suddenly know what to do!&quot;<p>And that unsupervised junior? At one place I joined, that unsupervised junior just started passing data he &quot;needed&quot; via query string params in ginormous arrays from microservice to microservice.<p>And it wasn't a quick fix because instead of using the lovely type system that TELLS you where the stupid method has been used, you've got to go hunting for http calls scattered over multiple projects.<p>All you've done is make everything even more complicated, if you can't supervise your juniors, your code's going to go sideways whatever.<p>Microservices don't solve that at all and it's pure circular logic to claim otherwise. If your team can't make good classes, they can't make good APIs either. And worse still, suddenly everything's locked in because changing APIs is much harder than changing classes.";0
34234357;HackerNews;2023-01-03;"&gt;You don't want to fracture knowledge and make hiring/training more difficult<p>these are not maxims of development, there can be reasons that make these consequences worth it. Furthermore you can still use just a single language with microservices*, nothing is stopping you from doing that if those consequences are far too steep to risk.<p>*:you can also use several languages with modules by using FFI and ABIs, probably.";0
34234324;HackerNews;2023-01-03;Dynamic typing + Microservices + Unit Tests just blows everything out of the water on Development Speed / Time to Market.<p>Most important thing for lots of startups and companies is Time to Market.<p>Traditional static typing based approachs are just a bad joke (3 times slower on average) in comparsion.<p>That's why we have the whole microservices and dynamic typing thing going on, because businesses that use it beat up businesses that don't. It's pretty simple really.;0
34234243;HackerNews;2023-01-03;"As a senior software engineer, the most tiresome type of software dev to deal with is not the junior developer, it's the highly opinionated intermediate-level dev.  They say things like &quot;we'll obviously build the system using modern microservices architecture using node.js&quot; before they even know the requirements.";0
34234192;HackerNews;2023-01-03;"yes, it's very common design. sometimes called a &quot;distirbuted monolith.&quot; it's not microservices because the number of additional services is usually small, and the codebase is still tightly coupled to itself (even if well factored in terms of modules). i.e., everything is still tested together, and there's still a single monolithic build and deployment process, and no team can go off and decide to write a service in a different language.";0
34234146;HackerNews;2023-01-03;"It's called &quot;Conway's law&quot;<p><a href=""https://ardalis.com/conways-law-ddd-and-microservices/#:~:text=Conway's%20Law%20states%20that%20%22any,Domain%2DDriven%20Design%20are%20adopted"" rel=""nofollow"">https://ardalis.com/conways-law-ddd-and-microservices/#:~:te...</a>.";0
34234111;HackerNews;2023-01-03;Perhaps we should coin the phase 'embedded microservices'.;0
34234072;HackerNews;2023-01-03;"It's easy to crap on EJB, lots to disagree with, but vendors like WebLogic were trying to do interesting things with them when they were ascending.  I recall they had a nifty feature where if you were trying to call a remote EJB and the container knew it was deployed locally, it would automatically do a cheaper local call instead of RMI.  It was awkward as hell, but it did do that, and it was faster.  J2EE also had the concept of people _roles_ as part of its prescribed SDLC, something we could benefit from exploring, especially the _deployer_ role.<p>Ideally we could flexibly deploy services/components in the same way as WebLogic EJB.  Discovery of where components live could be handled by the container and if services/components were deployed locally to one another, calls would be done locally without hitting the TCP/IP stack.  I gather that systems like Kubernetes offer a lot of this kind of deployment flexibility/discovery, but I'd like to see it driven down into the languages/frameworks for maximum payoff.<p>Also, the right way to do microservices is for services to &quot;own&quot; all their own data and not call downstream services to get what they need.  No n+1 problem allowed!  This requires &quot;inverting the arrows&quot;/&quot;don't call me, I'll call you&quot; and few organizations have architectures that work that way - hence the fallacies of networked computing reference.  Again, the services language/framework needs to prescribe ways of working that seamlessly establish (*and* can periodically/on-demand rebroadcast) data feeds that our upstreams need so they don't need to call us n+1-style.<p>Microservices are great to see, even with all the problems, they DO solve organizational scaling problems and let teams that hate each other work together productively.  But, we have an industry immaturity problem with the architectures and software that is not in any big players' interest in solving because they like renting moar computers on the internet.<p>I have no actual solutions to offer, and there is no money in tools unless you are lucky and hellbent on succeeding like JetBrains.";0
34234052;HackerNews;2023-01-03;But, I am <i>trying</i> to feel my way towards the idea that <i>that was true when managers arranged systems for workers to follow</i>, and then we came along to automate the current process.  But if we have a system where the workers are the CPUs, then the people doing the managing are the coders.<p>The point ebing is that if workers are CPUs and coders are managers, then why worry about how the <i>managers of the coders</i> are arranged.  Get rid of that management layer.  Conway is not implying the financiers of the organisation affect the architecture.<p>This basically means that the microservices a company is built out of should more readily align to the realities of the business model.  And instead of shuffling organisations around it would behove executives to look at the microservices.<p>One can more easily measure orders transferred, etc, if the boundaries are clearer.<p>Plus conway is just a ... neat idea, not a bound fate.<p>There is a caveat with the architecture reflecting the organisation of the software teams, but that usually follows the other to-be-automated structure as well.;0
34234043;HackerNews;2023-01-03;is this a common nomenclature/design? how does a monolith that makes IPC/RPC calls to submodules not basically microservices?;0
34233968;HackerNews;2023-01-03;"Whilst I don't know much about cruises. Let me make up an example for you.<p>Let's suppose we are Acme Cruise Lines running a Cruiseliner:<p>Microservice - National Coastguard Ship Arrival System Feed Handler<p>Database - Logs incoming messages on the feed<p>Microservice - Asian and Australian Joint Ship Monitoring System<p>Database - Logs incoming messages on the feed<p>Microservice - Cruiser Arrival and Departure Times<p>Database - Cruiser Arrival and Departures Times in a Standard Format<p>Microservice - Customer Bookings and Payments<p>Database - Customer Bookings and Payments<p>Microservice - Fuel Management System<p>Database - Ship Fuel Levels &amp; Costs of fuel at Various Ports.<p>It's that high level of split up.<p>(AWS Lambdas aren't quite the same thing as microservices.)";0
34233917;HackerNews;2023-01-03;"&gt; as far as I know, there's no way to granularly scale up a monolith. if the monolith has 20 or 50 or 100 modules and you need 1 or 2 of them scaled, you have to scale up the entire thing which is huge, expensive, etc.<p>not necessarily. yes, you do pay for executable bloat and some memory overhead from loading code into memory, but the argument here is that you can still deploy a &quot;Service B&quot; from the same deployable that only services certain kinds of requests in order to scale parts of the application horizontally.<p>&gt; this is interesting. a monolith with some form of IPC? why not do microservices at that point? that sounds like microservices-ish?<p>no, because again, you're still deploying the same single codebase, it's just the instance on the other end of the queue is configured just to consume and process messages.";0
34233916;HackerNews;2023-01-03;Just wait until you decide you need some kind of distributed transaction support across multiple microservices… You should aim to spend a considerable amount of time in the design and discovery phases.;0
34233912;HackerNews;2023-01-03;"The way it usually works, if 1 of your 100 modules needs to be scaled, it probably means the overall monolith only needs a small amount of extra resources, since that module is only using 1% of the total. So it's not like you need to double the instances of the whole thing.<p>The benefit though is you get a bit of 'free' scaling. Most of the modules don't even have to consider scaling at all, as long as they are growing ~average or slower. So this saves a lot of operational burden for many teams. Conversely with microservices <i>every</i> team <i>has to</i> consider scaling, no matter how simple their service is.<p>(If you do have 1 module out of 100 that takes up 40% of the resources, then it may be appropriate to split it up. Monolith doesn't literally mean &quot;exactly one service&quot;, after all, just a small number of big ones.)";0
34233829;HackerNews;2023-01-03;We've done the round trip of splitting up a monolith into microservices and then going back the other way. Network API overhead being the biggest reason. This kind of hell is totally unnecessary until it <i>absolutely</i> is (i.e. hard information theory requirements demand you spread your app across more than 1 physical computer).<p>Monolith is better in almost every way. The only thing that still bothers us is the build/iteration time. We could resolve this by breaking our gigantic dll into smaller ones that can be built more incrementally. This is on my list for 2023.;0
34233788;HackerNews;2023-01-03;"&gt; you have to scale up the entire thing which is huge, expensive, etc.<p>Yes, yet people still do it that way. This is tradeoff against the costs of microservices. I'm not saying it is worth it, but yes, sometimes you can just inefficiently throw hardware resources at scaling problems.<p>&gt; this is interesting. a monolith with some form of IPC? why not do microservices at that point? that sounds like microservices-ish?<p>Because you are incrementally changing an existing monolith, but still getting some of the benefits of scaling distinct workloads independently. If you do this right, it does lend it self to reworking the new &quot;service&quot; to be become its own microservice. Or you can just keep going with the shared codebase.";0
34233675;HackerNews;2023-01-03;Which is irrelevant, as many microservices do the same inside of them, and the libraries that they consume.;0
34233672;HackerNews;2023-01-03;Bring back the monoliths! Divided up into modules and each of those modules being developed by another team, but essentially still the same deliverable (binary).<p>You only need to agree on an API between the modules and you're good to go!<p>Microservices suck dick and I hate the IT industry for jumping on this bandwagon  (hype) without thoroughly discussing the benefits and drawbacks of the method. Debugging in itself is a pain with Microservices. Developing is a pain since you need n binaries running in your development environment.;0
34233650;HackerNews;2023-01-03;1 microservice. It's up to the software engineer to scope out the microservices properly.;0
34233646;HackerNews;2023-01-03;We keep regurgitating this, because most microservices are the 2nd coming of big data that fits into a USB stick.;0
34233595;HackerNews;2023-01-03;The maintenance cost is a debt that must be paid by all means. and microservices may be the cleanest solution if there are teams that develop businesses completely independent of each other.;0
34233557;HackerNews;2023-01-03;Then why cannot you have separate repos and review processes for modules? This has nothing to do with microservices vs modules.;0
34233480;HackerNews;2023-01-03;I felt suspicious as soon as I saw Jon Carmack’s website being mentioned in a conversation about Microservices.;0
34233370;HackerNews;2023-01-03;You never want code with shared ownership to tolerate feature creep. That’s impossible to keep on the rails. If you’re going to use SOLID anywhere, it’s in shared code.<p>If your org doesn’t suffer feature creep willingly, I believe that means you can have a lot more flexibility with respect to Conway’s Law. A low-churn project can maintain a common understanding. Not all of them will of course, but it’s at least possible. Feature factories absolutely cannot, and you shouldn’t even try.<p>What really kills a lot of projects though is an inverted dependency tree. And by inverted I mean that the most volatile code is at the bottom of the call graph, not the top. In this case every build, every deploy, or in the microservices scenario every request, can have different behavior from the previous one because some tertiary dependency changed under you. Now you need all sorts of triggers in your CI/CD pipeline to guarantee that integration tests are rerun constantly to figure out where the regressions are being introduced. Your build pipeline starts to look like one of those server rooms with loose wires everywhere and a bucket under the AC unit. Nothing is stable and everything is on the verge of being on fire at a moment’s notice.;0
34233260;HackerNews;2023-01-03;Yeah, I think this is one of the very few places where splitting out something as a microservice makes sense. For example, you (mostly) never want to open/process/examine/glance at user-provided PDFs on a box with any sort of unfiltered network access. Ideally you do what you need to do within a sandbox that has _no_ network access, but that's really hard to do performantly.<p>The primary reason for this is that PDFs can contain executable code and the common tools used to process them are full of unpatched CVEs.;0
34233233;HackerNews;2023-01-03;People keep regurgitating this “you aint going to be google” mantra but I worked there and in reality generic microservice stack is in a totally different league of complexity and sophistication of what google and co have. This argument is basically reductio ad absurdum;0
34233200;HackerNews;2023-01-03;Monoliths r hard.  Microservices r hard.  Pick your poison and get good.;0
34233198;HackerNews;2023-01-03;"&gt; the technical and organisational measures you need in place to do it safely are an extra step you need to take whereas with microservices they're built in<p>They aren't built in, it's just that the need for them is impossible to ignore. Developers (and management) can't help but recognize and respect modularity in microservices because the separation of services and the APIs between them make the modularity obvious. When the separation between modules only exists in code, and even then only when seen through the eyes of someone who understands the modular architecture of the codebase, it is easily ignored, inevitably forgotten, and might as well not exist at all.";0
34233175;HackerNews;2023-01-03;"Yes and no. The &quot;central&quot; part of data flowed naturally through services (i.e. passed in requests and webhooks, not in responses). Microservices maintained local state as well, though it was mostly small and disposable due to whole-intra crashonly design. For example, we didn't hesitate to shut something down or hot-fix it, except for bus-factor periods when there's only few of them. They could also go down by themselves or by upstream, and routers avoided them automatically.";0
34233153;HackerNews;2023-01-03;"&gt; there is no need to have the microservices built along Conways Law<p>This is a misunderstanding of Conway's Law. Your code _will_ reflect the structure of your organization. If you use microservices so will their architecture. If you use modules, so will the modules.<p>If you want a specific architecture, have your organization reflect the modules/microservices defined in that architecture.";0
34233138;HackerNews;2023-01-03;But there are rules of blame.<p>With microservices, as long as you maintain the contract with caller services, you can deploy whenever you want. If you have some kind of issue, your team is solely responsible. If the caller services do weird things, they are responsible for fixing them.<p>If you are pushing changes to a module as part of a more monolithic, or wrapper service - if you do a deploy and break the whole big service, you are now responsible for the entirety of any issue, which is now more likely due to integration risk and unrelated changes from others, especially because now there need to be coordination across many teams integrating - hopefully via tests and observability. But this requires a high-degree of maturity for automated quality assurance and site reliability. If you don't have that, the operational risks are very high. So that alternative is having some ops-like function, or other integration team responsible. Or doing more top-down waterfall coordination.<p>Given the service maturity needed is rare, microservices distributes that operational ownership in a way where there is more accountability.;0
34233097;HackerNews;2023-01-03;For code modularity to serve the same purpose, I think there needs to be explicit language-level support, because on a medium-sized or larger project, when the modularity exists only in the minds of developers, it might as well not exist at all. You need virtually all of your developers to understand the design and respect the seriousness of violating it, and beyond a certain project size, that isn't possible.<p>Developers do a much better job with microservices. I think it's easy for them to respect the seriousness of designing and changing the API of a microservice. In contrast, they often don't respect or even realize the seriousness of making a change that affects the modular design of code.<p>Language-level support for defining and enforcing module interfaces might help developers invest the same level of care for module boundaries in a modular monolith as they do in a microservices architecture, but I've yet to work in a language that achieves this.;0
34233020;HackerNews;2023-01-03;Microservices has little to do with tech. It is a way of organizing teams of <i>people</i>, funnelling all communication between teams through well defined specifications instead of ad-hoc meetings. It is not clear where static typing, or lack thereof, comes into play here.<p>TDD is a method of documenting your application in a way that happens to be self-verifying. You <i>could</i> use a Word document instead, but lose the ability for the machine to verify that the application does what the documentation claims that it should. Static typing does provide some level of documentation as well, but even if you have static typing available static typing isn't sufficient to convey the full intent that your documentation needs to convey to other developers.;0
34233016;HackerNews;2023-01-03;"devil's advocate:<p>&gt; A few ways, the easiest being to scale up the whole monolith with more instance<p>as far as I know, there's no way to granularly scale up a monolith. if the monolith has 20 or 50 or 100 modules and you need 1 or 2 of them scaled, you have to scale up the entire thing which is huge, expensive, etc.<p>&gt; Another way is run multiple &quot;services&quot; using the same codebase, so you have workload segmentation, either via synchronous network calls, or async worker systems.<p>this is interesting. a monolith with some form of IPC? why not do microservices at that point? that sounds like microservices-ish?";0
34232952;HackerNews;2023-01-03;"I think it runs a bit deeper than that.  Microservices are how the business views its self.<p>Look, once upon a time managers designed the system that <i>workers</i> implemented. The factory assembly line, or the policy manual.<p>But now the <i>workers</i> are CPUs and servers. The managers designing the system the workers follow are <i>coders</i>.  I say coders are the new managers.<p>Now this leaves two problems. The first is that there are a lot of &quot;managers&quot; who are now doing the wrong job.  (and explains perfectly why Steve Jobs gets involved in emails about hiring coders.) But that's a different post.<p>For me the second problem is microservices represent the atomic parts of a business.  They should not be seen as a technical solution to anything, and because the first problem (managers arent managing workers anymore) there is no need to have the microservices built along Conways Law.<p>And so if you want to build a microservice it is not enough to consider the technical needs, it is not enough to automate what was there, you need to design an atomic building block of any / your company.  They become the way you talk about the company, the way you think about the processes in a company.<p>An mostly the company becomes programmable.  It is also highly likely the company becomes built mostly of interchangable parts.";0
34232927;HackerNews;2023-01-03;"While I mostly agree, I don't think it's so black and white on the enforcement part and I actually think that a lot of recent developments actually put holes into this.<p>The typical example is that when you have to explain something is the job of X and Y. Usually this means that X and Y are breaking those boundaries. Just make a semi-private (or even public) API only used for that thing and you have a broken boundary again. Or push it on a message queue, etc.<p>I think, it certainly helps, but then again it doesn't prevent it. Having modules you have the same effect.<p>So in the end you get more spots where things can get wrong and more operational complexity. If you stick to using them right, I think you can also stick to using modules right with less complexities, better performance, easier debugability, fewer moving parts.<p>Hackers will find a way to do hacky things everywhere. ;)<p>Also this whole discussion reminds me of Linus discussing how he thinks micro kernels add complexity a very long time ago. Not sure if they should be considered modules or microservices though.<p>Sharing global state and so on while maybe it shouldn't be done lightly, without thinking about it can and does make sense. And in most modern environments it's not like the most quoted issues can happen too easily.<p>Also I strongly agree with pointing out that this is actually a niche topic. It's mostly big because that niche is where probably the majority of HN and &quot;startup&quot; people spend their time.";0
34232865;HackerNews;2023-01-03;100% true for certain classes of problem.<p>If I want to calculate the price of a stock option, that's an excellent candidate to package into a module rather than to expose as a microservice. Even if I have to support different runtimes as presented in the article, it's trivial.<p>A different class of problem that doesn't modularize well, in shared library terms, is something with a significant timing component, or something with transient states. Perhaps I need to ingest some data, wait for some time, a process the data, and then continue. This is would likely benefit from being an isolated service, unless all of the other system components have similar infrastructure capabilities for time management and ephemeral storage.;0
34232847;HackerNews;2023-01-03;"&gt;And also with modules you need the business processes to coordinate deployments across teams, because they all live in the same wrapper application. That's what stops them being independent.<p>If we're being technical some languages support hot swapping modules so no restart would be needed. Setting that aside, restarting an application isn't anything that needs coordination today.  You wouldn't even restart the application.  You'd deploy a new version, swap over, and shut down the old version.<p>&gt;You don't restart the network every time you deploy a microservice.<p>No, but something changes in the network configuration so that the other microservices are aware of the deployment.";0
34232836;HackerNews;2023-01-03;"&gt; That backplane is not an implementation, but a set of understood guiderails for inter-module communication.<p>Then why is the author even discussing microservices in the first place? Following your logic, they are an implementation detail just like modules.";0
34232817;HackerNews;2023-01-03;"&gt; But most people need it a lot less than they think. Normally the database is your bottleneck and if you keep your application server stateless, you can just run lots of them<p>At my last job, there were quite a few times where being able to scale some small &quot;microservice instance&quot; up from 2 -&gt; 4 instances or 4 -&gt; 8 or 8 -&gt; 12 was a lot easier/quicker than investigating the actual issue. It'd stop production outages/hiccups. It was basically encouraged.<p>Not sure how that can be done with a &quot;it's all modules in a giant monolith&quot;.";0
34232689;HackerNews;2023-01-03;"The biggest appeal to me for microservices (which might be in the list in terms of &quot;maintainability&quot; but isn't explicitly called out) is that it <i>enforces</i> the modularization. Yes I want modules. But no, I don't have the discipline to actually keep a code base modular. Platforms and languages have evolved for rapid development and convenience, and realities for modularization that aren't architectural, for example compilation units or deployment.<p>A failed lookup of a function is greeted by &quot;Do you want to import X so you can call foo()?&quot;. Having a battery of architectural unit tests or linters ensuring at module foo doesn't use module bar feels like a crutch.<p>Now, it might seem like making microservices just to accomplish modularization seems like a massive overkill and sa huge overhead for what should be accomlished at the language level - and you'd be right.<p>But that leads to the second largest appeal, which is closely related. The one thing that kills software is the big ball of mud where you can't <i>really</i> change that dependency, move to the next platform version or switch a database provider. Even in well-modularized code, you still share dependencies. You build all of it on react, or all the data is using Entity Framework or postgres. Because why not? Why would you want multiple hassles when one hassle is enough? 
But this really also means that when something is a poor fit for a new module, you shoehorn that module to use whatever all the other modules use (Postgres, Entity Framework, React...). With proper microservices, at least in theory you should be able to use multiple versions of the same frameworks, or different frameworks all together.<p>It should also be said that &quot;modules vs microservices&quot; is also a dichotomy that mostly applies in one niche of software development: Web/SaaS development. Everywhere else, they blur into one and the same, but sometimes surfacing e.g. in a desktop app offloading some task to separate processes for stability or resource usage (like a language server in an IDE).";0
34232681;HackerNews;2023-01-03;I have to believe these anti-microservices articles tend to be written by people who just don't need microservices, and maybe who also don't have much experience applying them to useful effect. Amazon, cited in the article as an originator of the practice, is a perfect example of where microservices are virtually unavoidable and central to the success of the company. There is no way to Amazon could have been built on on a small number of monoliths. None.;0
34232656;HackerNews;2023-01-03;Modules aren't an alternative to microservices in a reasonable way though.  And for all modules solve the modularization problem at the code level, they don't really solve modularization at the service level.  The main alternative to microservices is monoliths and for many applications I far prefer microservices to monoliths. I want modularization in how I scale my app, I don't want to spin up a whole bunch of servers that can serve almost any possible function in production. I'd prefer more delineated responsibilities. I don't think modularization solves this if after the modules you just throw all your modules in one big bucket and serve that up.;0
34232623;HackerNews;2023-01-03;Transaction boundaries are a critical aspect of a system.<p>I've often noticed that these boundaries are not considered when carving out microservices.<p>Subsequently, workarounds are put in place that tend to be complicated as they attempt to implement two phase commits.;0
34232568;HackerNews;2023-01-03;And also with modules you need the business processes to coordinate deployments across teams, because they all live in the same wrapper application. That's what stops them being independent.<p>You don't restart the network every time you deploy a microservice.;0
34232504;HackerNews;2023-01-03;You need to do additional steps in both cases:<p>With modules you need some sort of wrapper application to bring it all together.<p>With microservices you need some sort of network layer so that the microservices can talk to each other.;0
34232472;HackerNews;2023-01-03;"&gt; I'm not so positive on every microservice maintaining its own copy of state, potentially with its own separate data store. I think that usually adds more ongoing complexity in synchronization than it saves by isolating schemas. A better rule is for one service to own writes for a table, and other services can only read that table, and maybe even then not all columns or all non-owned tables.<p>I’ll go one step further and say that you should treat your data stores as services in and of themselves, with their own well-considered interfaces, and perhaps something like PostgREST as an adapter to the frontend if you don’t really need sophisticated service layers. The read/write pattern you recommend is a great fit for this and can be scaled horizontally with read replicas.";0
34232456;HackerNews;2023-01-03;"The biggest draw of microservices to those just adopting them is not scalability or separation of concerns, but independent deployability (move fast and deploy new features in a particular area unencumbered).<p>Good LUCK getting that property with a monolithic or modular system. QE can never be certain (and let's be honest, they should be skeptical) that something modified in the same codebase as something else does not directly break another unrelated feature entirely. It makes their life very difficult when they can't safely draw lines.<p>Two different &quot;modules&quot; sharing even a database when they have disparate concerns is just waiting to break.<p>There's a lot of articles lately dumping on microservices and they're all antiquated. News flash: there is no universal pattern that wins all the time.<p>Sometimes a monolith is better than modules is better than microservices. If you can't tell which is better or you are convinced one is always better, the problem is with <i>you</i>, not the pattern.<p>Microservices net you a <i>lot</i> of advantages at the expense of way higher operational complexity. If you don't think that trade off is worth it (totally fair), don't use them.<p>Since we are talking about middleground, one I'd like to see one day is a deploy that puts all services in one &quot;pod&quot;, so they all talk over Unix socket and remove the network boundary. This allows you to have one deploy config, specify each version of each service separately and therefore deploy whenever you want. It doesn't have the scalability part as much, but you could add the network boundary later.";0
34232439;HackerNews;2023-01-03;"Or hardware. I worked on an HPC product which used &quot;microservices&quot; of a kind but many of them were tied to specific hardware nodes. So much of what we think of as &quot;microservices&quot; relies on a fairly narrow set of assumptions, and mostly makes sense in specific contexts, i.e. cloud, APIs, etc.";0
34232422;HackerNews;2023-01-03;"Microservices as a named architectural pattern are over a decade old at this point. Anyone jumping on them because they're the new hotness is more than a little behind the times.<p>&gt; I have exactly the opposite problem though: the kind of problems I have worked on so far would not be &quot;solved&quot; by leveraging &quot;large number of developers that can independently work on an equally large number of small, modular programs with a very well defined, concise interface&quot;.<p>If you don't have multiple teams working on it, and you don't have specific chunks of functionality that you need to scale orthogonally, then you don't have the problems microservices solve. So don't use them.  That seems uncontroversial to me.<p>&gt; I still think that &quot;these scenarios&quot; are prevalent in any company which existed before the 90s, but I might be wrong or biased on this<p>This is survivorship bias, in a sense. Microservices only make sense where access to CPU and network is cheap and on-demand (largely). That's only started to be an assumption you could really make since Amazon's EC2 convinced the world's CIOs that fungible tin was better than their own racks.<p>That means you don't see microservice architectures in older companies, and you don't see problems being solved with them <i>even where it might have made sense retrospectively</i> because IT Ops would never have been set up to enable it.<p>Today you don't need a big rewrite to justify introducing microservices where they're needed. That's a straw man. All you need is a team that will be able to move faster if their deployment is decoupled from everyone else's.<p>But fundamentally if your problem area smells like &quot;bunch of business rules and a database&quot; then, again: if you don't have the problem that the architecture solves, don't use it.";0
34232365;HackerNews;2023-01-03;"Time to throw the cat amongst the proverbial pigeons and start the year 2023 off with discord and disharmony.<p>Microservices are a solution to a problem. TDD is a solution to a problem, the same problem. Both are solutions that themselves create more, and worse, problems. Thanks to the hype driven nature of software development the blast radius of these 'solutions' and their associated problems expands far beyond the people afflicted by the original problem.<p>That problem? Not using statically typed languages.<p>TDD attempts to reconstruct a compiler, poorly. And Microservices tries to reconstruct encapsulation and code structure, poorly. Maybe if you don't use a language which gets hard to reason about beyond a few hundred lines you won't need to keep teams and codebases below a certain size. Maybe if you can't do all kinds of dynamic nonsense with no guardrails you don't have to worry so much about all that code being in the same place. The emperor has no clothes, he never had.<p>Edit: to reduce the flame bait nature of the above a bit. Not in all cases, I'm sure there are a very few places and scales where microservices make sense. If you have one of those and you used this pattern correctly, that's great.<p>And splitting out components as services is not always bad and can make a lot of sense. It's the &quot;micro&quot; part of &quot;microservices&quot; that marks out this dreadful hype/trend pattern I object to. It's clearly a horrible hack to paper over the way dynamically typed codebases become much harder to reason about and maintain at scale. Adding a bunch of much harder problems (distributed transactions, networks, retries, distributed state, etc) in order to preserve teams sanity instead of just using tooling that can enforce some sense of order.";0
34232248;HackerNews;2023-01-03;"&gt; Instagram<p>Does anyone have a microservice &quot;map&quot; of Instagram? I feel that would be helpful here.";0
34232220;HackerNews;2023-01-03;Same thing with microservices, unless you do a blue green deployment, have a planned shutdown, load balancer in between releases,...;0
34232166;HackerNews;2023-01-03;No personal project has any business using microservices, unless it's specifically as a learning toy. Use a monolith. Monoliths can scale more than you can (provided you manage not to limit yourself to the single-thread single-process version of a monolith). Microservices are an <i>organisational</i> tool for when you need to release chunks independently.<p>I first wrote a program which ran on a web server about 25 years ago. In that time, computers have experienced about ten doublings of Moore's law, i.e. are now over a <i>thousand</i> times faster. Computers are very fast if you let them be.;0
34232096;HackerNews;2023-01-03;"&quot;This has been my major criticism of them; you cement the design of the app by creating an organizational structure around your software components.&quot;<p>Conway's Law is basically &quot;You don't have a choice.&quot; You <i>will</i> cement the design of your app around your organizational design. (At least, beyond a certain org size. If you have only 4 engineers you don't really have the sort of structure in question here at all.) je42 narrowly beats me to the point that if this is a problem you can try to match your organization to your problem, but that takes a fairly agile organization.<p>&quot;What happens if you need to redesign the architecture to meet new needs? That's right; it's not going to happen, because people will fight it tooth and nail.&quot;<p>Unfortunately, in the real world, this is not so much &quot;a disadvantage to the microservice approach&quot; as simply &quot;an engineering constraint you will have to work around and take account in your design&quot;.<p>Despite what you may think after I've said that, I'm <i>not</i> a microservice maximalist. Microservices are a valuable tool in such a world but far from the <i>only</i> tool. As with everything, the benefits <i>and</i> the costs must be accounted for. While I've not successfully rearchitected an entire organization from my position as engineer, I have had some modest, but very <i>real</i> success in moving little bits and pieces around to the correct team so that we don't have to build stupid microservices just to deal with internal organizational issues. I don't mean this to be interpreted as a defeatist &quot;you're doomed, get ready for microservices everywhere and just deal with it&quot;; there are other options. Or at least, there are other options in relatively healthy organizations.<p>But you <i>will</i> have code that matches the structure of your organization. You might as well harness that as much as you can for the benefits it can provide because you're stuck with it whether you like it or not. By that I mean, as long as you are going to have teams structured around your services whether you like it or not, go in with eyes open about this fact, and make plans around it to minimize the inevitable costs while maximizing the benefits. Belief that there is another option will inevitably lead to suboptimal outcomes.<p>You can't engineer at an organizational level while thinking that you have an option of breaking the responsibility and authority over a codebase apart and somehow handing them out to separate teams. That never works long term. A lot of institutional malfunctioning that people correctly complain about on HN is at its core people who made this very mistake and the responsibility &amp; authority for something are mismatched. Far from all of it, there are other major pathologies in organizations, of course. But making sure responsibility &amp; authority are more-or-less in sync is one of the major checklist items in doing organization-level engineering.";0
34232094;HackerNews;2023-01-03;You can deploy modules independently, but the technical and organisational measures you need in place to do it safely are an extra step you need to take whereas with microservices they're built in.  Modules live in the same execution context, so you need a good shared ownership model for that context itself.<p>The point is that Parnas never conceived of doing it because he was writing about a world where the interfaces between modules were known ahead of time and were static.;0
34232062;HackerNews;2023-01-03;I usually say that microservices are a good concept. Do everything to enable the split of your monolith, then ..don't.;0
34231991;HackerNews;2023-01-03;"Huh? They can, and will, just add the things they want to the rest api of the microservice A and then call them from B. That doesn't change with microservices.<p>Look up a thing called &quot;distributed monolith&quot;.";0
34231903;HackerNews;2023-01-03;There is a high amount of correlation between people that start with microservices (instead of using them to solve specific problems after they have the problem) and people that lack any awareness about the resources they need.<p>And both are way more common than they should be.;0
34231882;HackerNews;2023-01-03;Microservices are an optimization. Do not premature optimize.;0
34231863;HackerNews;2023-01-03;Organizing teams around microservices makes ... a lot of sense?<p>Also - talking of redesign should be a <i>major</i> lift for any product/service that has real paying clients.  The risk of breaking is huge, and the fact that during that time you won't be delivering incremental value is also going to look bad.;0
34231860;HackerNews;2023-01-03;"The tweet is obviously wrong.<p>&gt; I was told ~1200 RPCs independently by several engineers at Twitter, which matches # of microservices. The ex-employee is wrong.<p>&gt; Same app in US takes ~2 secs to refresh (too long), but ~20 secs in India, due to bad batching/verbose comms.<p>RPCs are on the server side. Why would they app take longer to refresh in India than in the US?<p>Some more explanation:<a href=""https://twitter.com/mjg59/status/1592380440346001408"" rel=""nofollow"">https://twitter.com/mjg59/status/1592380440346001408</a>";0
34231850;HackerNews;2023-01-03;"Are there similar tools for modules like microservices for observability, discoverability and documentation? I'm thinking something like Backstage [1] that was featured on HN lately but for modules.<p>[1]: <a href=""https://backstage.io/"" rel=""nofollow"">https://backstage.io/</a>";0
34231817;HackerNews;2023-01-03;You know what's missing from all microservices discussions? An actual definition. At what point does a microservice stop being micro? 5kloc of python equivalent? 10k? 25k?;0
34231810;HackerNews;2023-01-03;Could this be solved by consolidating service A and service B into one unit while maintaining the overall architecture? I know it's just an example but the whole point of microservices is to have the flexibility to rearchitect pieces without having to rewrite the entire project, so potentially poor initial choices can be reworked over time.;0
34231733;HackerNews;2023-01-03;Twitter seems to have adopted Microservices in 2014, and in 2013 they had ~200M MAU (presumably using a monolith architecture).<p>Even if Microservices are better for scale, most companies will never experience the level of scale of 2013 Twitter.<p>Are Microservices beneficial at much smaller levels of scale? Ex: 1M MAU;0
34231678;HackerNews;2023-01-03;Can you explain why you can deploy microservices independently but not modules?;0
34231677;HackerNews;2023-01-03;"I really like modular designs, but this article is missing some key limitations of monolithic applications, also if they are really well modularized (this is written mostly from the perspective of a Java developer):<p>* they force alignment on one language or at least runtime<p>* they force alignment of dependencies and their versions (yes, you can have different versions e.g. via Java classloaders, but that's getting tricky quickly, you can't share them across module boundaries, etc.)<p>* they can require lots of RAM if you have many modules with many classes (semi-related fun fact: I remember a situation where we hit the maximum number of class files a JAR could have you loaded into WebLogic)<p>* they can be slow to start (again, classloading takes time)<p>* they may be limiting in terms of technology choice (you probably don't want ot have connections to an RDBMS and Neo4j and MongoDB in one process)<p>* they don't provide resource isolation between components: a busy loop in one module eating up lots of CPU? Bad luck for other modules.<p>* they take long to rebuild an redeploy, unless you apply a large degree of discipline and engineering excellence to only rebuild changed modules while making sure no API contracts are broken<p>* they can be hard to test (how does DB set-up of that other team's component work again?)<p>I am not saying that most of these issues cannot be overcome; to the contrary, I would love to see monoliths being built in a way where these problems don't exist. I've worked on massive monoliths which were extremely well modularized. Those practical issues above were what was killing productivity and developer joy in these contexts.<p>Let's not pretend large monoliths don't pose specific challenges and folks moved to microservices for the last 15 years without good reason.";0
34231658;HackerNews;2023-01-03;"Yes. If you design a distributed system you need to consider the network traffic very carefully, and choose your segmentation in such a way that you minimize traffic and still achieve good scalability.<p>For this reason, I've been trying to push for building a monolithic app first, then splitting into components, and introducing libs for common functionality. Only when this is all done, you think about the communication patterns and discuss how to scale the app.<p>Most microservice shops I've been in have instead done the naïve thing; just come up with random functionally separate things and put them in different micro services; &quot;voting service&quot;, &quot;login service&quot;, &quot;user service&quot; etc. This can come with a very very high price. Not only in terms of network traffic, but also in debuggability, having a high amount of code duplication, and getting locked into the existing architecture, cementing the design and functionality.";0
34231640;HackerNews;2023-01-03;"Here is an analogy that can inform the implications of this (so-called, imo) architecture:<p>Imagine if you are responsible, at runtime, for <i>linking</i> object files (.o) where each object is a just the compilation of a function.<p>Now why would anyone think this is a good idea (as a general solution)? Because in software organizations, the “linker’s” job is supposed to be done by the (“unnecessary weight”) software architect.<p>Microservices <i>primarily</i> serve as a patch for teams incapable of designing modular <i>schemas</i>. Because designing schemas is not entry level work and as we “know” s/e are “not as effective” after they pass 30 years of age. :)<p>&gt; monolith<p>Unless monolith now means not-microservice, then be aware that there are a range of possible architectures between a monolith and microservices.";0
34231638;HackerNews;2023-01-03;You shoot yourself in the foot pretty hard regarding point 2 (scalability) if you have your microservices share a DB.;0
34231564;HackerNews;2023-01-03;I agree that monoliths are the way to start many times, especially if you're not actually sure you'll ever need to scale. One reason we do sometimes plan on microservices from the start with projects is separation of <i>security</i> concerns. Easier to lock a public-facing microservice down tight and have what's ostensibly a non public-facing monolith call out to it.<p>Lots of ways to solve a problem, though.;0
34231532;HackerNews;2023-01-03;"This has been my major criticism of them; you cement the design of the app by creating an organizational structure around your software components.<p>What happens if you need to redesign the architecture to meet new needs? That's right; it's not going to happen, because people will fight it tooth and nail.<p>You also cannot produce any meaningful end-user value without involving several teams.<p>Microservices is just &quot;backend, frontend, and database team&quot; reincarnated.<p>My take: do Microservices all you want, but don't organize teams around the services!";0
34231520;HackerNews;2023-01-03;"&gt; At the heart of microservices, we're told we'll find...<p>Well, in our +20 product teams with all serving different workflows for 3 different user types, the separate micro services are doing wonders for us for exactly the things you've listed.<p>My comment should just stop here to be honest.";0
34231519;HackerNews;2023-01-03;Are organizations ever capable of enforcing coding standards even remotely close to that of what microservices _should_ provide? Because I have not seen it.<p>However this is muddied by the fact that I almost never see microservices, I see a lot of distributed monoliths tho.;0
34231490;HackerNews;2023-01-03;"Microservices might be a hack to gain modularity when nothing else works.<p><a href=""https://michaelfeathers.silvrback.com/microservices-and-the-failure-of-encapsulaton"" rel=""nofollow"">https://michaelfeathers.silvrback.com/microservices-and-the-...</a>";0
34231468;HackerNews;2023-01-03;"I agree, and yet most microservice zealots seem to have a different opinion on this.<p>e.g.: <a href=""https://www.baeldung.com/cs/microservices-db-design"" rel=""nofollow"">https://www.baeldung.com/cs/microservices-db-design</a><p>&quot;2.1. Fundamentals
By definition, microservices should be loosely coupled, scalable, and independent in terms of development and deployment. <i>Therefore, the database per service is a preferred approach as it perfectly meets those requirements.</i> Let’s see how it looks:&quot;<p>Please understand that I have worked only on monoliths and will probably retire while still working on monoliths. This kind of absurd positions only come up when someone comes to my office with some grand plan to convert the application I work on to something &quot;more microservice oriented&quot;.";0
34231466;HackerNews;2023-01-03;yeah i've always thought that microservices shine when the org chart defines them. I've been on teams where we were responsible for multiple microservices and it was so annoying to have to bounce back and forth between code bases and deployments and then it was super easy to intertwine different microservices when you were in the them so often. I feel like if you don't have a team dedicated full time per microservice then you probably shouldn't be using that architecture.;0
34231438;HackerNews;2023-01-03;Modules can not constrain resource boundaries, microservices can. This is often overlooked.;0
34231408;HackerNews;2023-01-03;"In theory microservice is cool. In practice, it's not.<p>Microservice and modularity is orthogonal, it's not the same.<p>Modularity is related to business concept, microservice is related to infrastructure concept.<p>For example, i could have a module A which is deployed into microservide A1 and A2. In this case, A is almost abstract concept.<p>And of course, i could deploy all modules A, B, C using 1 big service (monothlic).<p>Moreover, i could share one microservice X for all modules.<p>All confusion from microservice, is made from the misconception that microservice = module.<p>Worse, most of &quot;expert advice&quot; which i've learnt actually relate Domain Driven Design to Microservice. They're not related, again.<p>Microservice to me, is to scale. Scale the infrastructure. Scale the team (management concept).";0
34231406;HackerNews;2023-01-03;"ah come on, there is a reason why we start most estimates with &quot;it depends&quot;.<p>It's on the same page as &quot;yes, we could have written this in assembler better&quot; or &quot;this could simply be a daemon, why is it a container?&quot;<p>As if an agile, gitops based, rootlessly built, microservice oriented, worldwide clustered app will magially solve all your problems :D<p>If i learned anything it's to expect problems and build a stack that is dynamic enough to react. And that any modern stack includes the people managing it just as much as the code.<p>But yes, back when ASP.NET MVC came out i too wanted to rebuild the world using c# modules.";0
34231394;HackerNews;2023-01-03;Those boundaries also increase the cost of development.  If you are institutionally incapable of enforcing coding standards such that you can't prevent juniors from coupling your modules, perhaps it's worth it.  But there are more efficient ways to build and run an engineering organization.<p>The best place for such boundaries is at the team/division/org level, not team-internal or single dev-internal like microservices implies with its name.  Embrace Conway's law in your architecture, and don't subdivide within a service.;0
34231388;HackerNews;2023-01-03;"Did you have a common, centralized data store or did each and every microservice manage their own instance?<p>(Because this is at the same time one of the defining elements of this architecture... and the first one to be opted out when you actually start using it &quot;for real&quot;).";0
34231375;HackerNews;2023-01-03;ive never seen that in practice. you dont have a database for each individual lambda. thats insanity. you can have multiple microservices point to a shared datasource, its not illegal.;0
34231355;HackerNews;2023-01-03;"well, this is a surprisingly common case in my experience, except that the people were not &quot;right out of high school&quot; but &quot;right out of a company funded seminar on microservices&quot;.";0
34231353;HackerNews;2023-01-03;"There are two things that people often misunderstand about Microservices - there is no single definition about what they actually are, and -- arguably more importantly -- there exists no single rationale about why you would want to move to Microservice architecture in the first place.<p>Take for example Gartner's definition:<p>&gt; A microservice is a service-oriented application component that is tightly scoped, strongly encapsulated, loosely coupled, independently deployable and independently scalable.<p>That's not too controversial. But... as a team why and when would you want to implement something like this? Again, let's ask Gartner. Here are excerpts from &quot;Should your Team be using Microservice Architectures?&quot;:<p>&gt;  In fact, if you aren’t trying to implement a continuous delivery practice, you are better off using a more coarse-grained architectural model — what Gartner calls “Mesh App and Service Architecture” and “miniservices.”<p>&gt; If your software engineering team has already adopted miniservices and agile DevOps and continuous delivery practices, but you still aren’t able to achieve your software engineering cadence goals, then it may be time to adopt a microservices architecture.<p>For Gartner, the strength of Microservice Architecture lies in delivery cadence (and it shouldn't even be the first thing you look at to achieve this). For another institution it could be something else. My point is that when people talk about things like Microservices they are often at cross-purposes.";0
34231335;HackerNews;2023-01-03;"I have exactly the opposite problem though: the kind of problems I have worked on so far would not be &quot;solved&quot; by leveraging &quot;large number of developers that can independently work on an equally large number of small, modular programs with a very well defined, concise interface&quot;.<p>And this is not because &quot;my stuff is complicated and your stuff is a toy&quot;, either. It's more like &quot;ERP or Banking Systems&quot; were deployed decades ago, started as monoliths and nobody can really afford to rewrite these from scratch to leverage Microservices (or whatever the next fad will be).
(I am also not sure it is a good idea in general for transactions that have to handle/persist lots of state, but this could be debated).<p>The problem, in fact, is that &quot;new guys&quot; think that Microservices will magically solve that problem, too, want to use these because they are cool and popular (this year), and waste (and make me waste) lots of time before admitting something that was clear from day 1: Microservices are not a good fit for these scenarios.<p>(I still think that &quot;these scenarios&quot; are prevalent in any company which existed before the 90s, but I might be wrong or biased on this).";0
34231327;HackerNews;2023-01-03;"Parnas was writing under an assumption of BDUF, big-bang releases, and expensive hardware instances. As soon as you want to decouple module deployments and accommodate changing requirements over time you need something else. That &quot;something else&quot; might be &quot;making sure your modular monolith has a good enough test suite that any team can deploy it with only their changes&quot; or it might be &quot;microservices for all&quot;, but Parnas' assumption that independently verified modules will need to be built once by independent teams then function correctly when assembled has been comprehensively squashed in the last 50 years.<p>He's right as far as Conway's Law goes, though.";0
34231271;HackerNews;2023-01-03;I think most criticisms around microservices are about good practices and skills beating microservices in theory.<p>And the virtue of microservices is that they create hard boundaries no matter your skill and seniority level. Any unsupervised junior will probably dissolve the module boundaries. But they can't simply dissolve the hard boundary of having a service in another location.;0
34231267;HackerNews;2023-01-03;Would be interesting to learn how your (or any other) team defines borders of a microservice. Iow, how “micro” they are and in which aspect. I guess without these details it will be hard to reason about it.<p>At my last job we created a whole fleet of microservices instead of a single modular project/repo. Some of them required non-trivial dependencies. Some executed pretty long-running tasks or jobs for which network latency is insignificant and will remain so by design. Some were few pages long, some consisted of similar-purpose modules with shared parts factored out. But there was no or little processes like “ah, I’ll just ask M8 and it will ask M11 and it will check auth and refer to a database. I.e. no calls as trivial as foo(bar(baz())) but done all over the infra.;0
34231258;HackerNews;2023-01-03;"<i>No, you don't use separate microservices for writing out that text message.</i><p>But in order to find out that Genua is the name of the port from where the cruise is departing, the appropriate time (converted to the timezone of the port, or the timezone of the client who will see this message, depending on what business rule you want to apply) and that Genua is in IT=Italy... how many microservices do I have to query, considering that port data, timezones, ISO country codes and dep.date/time of the cruise are presumably managed on at least four different &quot;data stores&quot;?";0
34231251;HackerNews;2023-01-03;Couldn’t agree more.<p>The way I usually describe my preferred heuristic to decide between modules and microservices is:<p>If you need to deploy the different parts of your software individually, and there’s a cost of opportunity in simply adopting a release train approach, go for microservices.<p>Otherwise, isolated modules are enough in the vast majority of cases.;0
34231223;HackerNews;2023-01-03;"They solve specific problems. If they don't solve a problem you have, then using them is probably a mistake.<p>The thing is that the framing of &quot;the problems we use computers for&quot; misses the entire domain of problems that microservices solve. They solve organisational problems, not computational ones.";0
34231222;HackerNews;2023-01-03;Both Modularization and Microservices solve scaling problems.<p>Modularization allows development to scale.<p>Microservices allow operations to scale.;0
34231180;HackerNews;2023-01-03;Unfortunately this is also partly correct - The team was young and people were eager to play around and learn how to work with microservices.;0
34231177;HackerNews;2023-01-03;In which case, the next step for your org is a mandate that all microservices be available in all datacenters.<p>Let each microservice owner figure out how to achieve their latency+reliability SLA's in every location - whether replicating datastores, caching, being stateless, or proxying requests to a master location.;0
34231140;HackerNews;2023-01-03;The distinct elements are they compile separately and have versioning on their API calls.<p>No, you don't use separate microservices for writing out that text message.<p>The idea is pretty simple instead of writing one big program, you write many smaller programs.<p>It's useful around the 3 to 4 separate developers mark.<p>It avoids you having to recompile for any minor change, allows you run the tests for just the part you changed and allows you to test the microservices in isolation.<p>If you a production issue, the exception will be in a log file that corresponds to a single microservice or part of your codebase.<p>Microservices are a hard form of encapsulation and gives a lot of benefits when the underlying language lacks that encapsulation. e.g. Python.;0
34231135;HackerNews;2023-01-03;This article nails it, but I still like microservices because I’ve yet to see a team doing a modular architecture in memory keep from creating a spaghetti mess of interdependence.<p>Yes, the same often happens in microservices, but the extra complexity of a distributed system provides a slightly stronger nudge to decouple that means some teams at the margin do achieve something modular.<p>I’m something of a skeptic on modular monoliths until we as an industry adopt practices that encourage decoupling more than we currently do.<p>Yes, in theory they’re the same as microservices, without the distributed complexity, but in practice, microservices provide slightly better friction/incentives to decouple.;0
34231129;HackerNews;2023-01-03;Someone must have read a blog post about microservice and decided it would look good on their resume.;0
34231128;HackerNews;2023-01-03;"&gt; one of the unexpected consequences is that we are now doing a lot of network calls between these microservices<p>Not trying to be harsh here, but <i>not</i> expecting an increase of network call in a system where each component is tied together with... network calls sounds a bit naive.<p>&gt; We are now attempting to solve this with caches and doing batch requests<p>So you have built a complex and bottle-necked application for the sake of scalability, then having to add caching and batching just to make it perform? That sounds like working backwards.<p>Obviously, I have no clue on the scale of the project you are working on, but it sure sounds like you could have built it as a monolith in half of the time with orders of magnitude more performance.<p>Scalability is a feature, you can always add it in the future.";0
34231126;HackerNews;2023-01-03;"Totally agree.
Also microservices shines IF you need different release schedule for two services. If they are managed in the same project/team, the effort you pay is high, the advantage could not pay your bill, so be careful in such scenario.";0
34231121;HackerNews;2023-01-03;Some of the services not being in the same datacentre seems orthoganal. If that solves a problem you have, wouldn't it still be an issue in a non-microservices design?;0
34231113;HackerNews;2023-01-03;"&gt; Microservices [..] actually solve for a human problem in scaling up an organization.<p>So does modularity.<p>&quot;The benefits expected of modular programming are: (1) managerial_development time should be shortened because separate groups would work on each module with little need for communication...&quot;<p><i>On the Criteria To Be Used in Decomposing Systems into Modules</i>, D.L. Parnas 1972.<p><a href=""http://sunnyday.mit.edu/16.355/parnas-criteria.html"" rel=""nofollow"">http://sunnyday.mit.edu/16.355/parnas-criteria.html</a>";0
34231112;HackerNews;2023-01-03;"This article is all over the place. The author acknowledges that microservices are about organizational clarity, then writes &quot;In theory, anyway&quot; without elaboration, and <i>then</i> goes on to talk about the latency impact of network-level IPC.<p>Why do we care about network latency, when we JUST established that microservices are about scaling large development teams? I have no problem with hackers ranting about slow, bloated and messy software architecture...but this is not the focus of discussion as presented in the article.<p>And then this conclusion:<p>&gt; The key is to establish that common architectural backplane with well-understood integration and communication conventions, whatever you want or need it to be.<p>...so, like gRPC over HTTP? Last time I checked, gRPC is pretty well understood from an integration perspective. Much better than Enterprise Java Beans from the last century. Isn't this ironic? And where are the performance considerations for this backplane? Didn't we criticize microservices before because they have substandard performance?";0
34231090;HackerNews;2023-01-03;I think a lot of microservices are defined as separate apps and code repositories. This sounds good for initial build and deployment but the long term maintenance is the issue.  Developers like the idea of independence of other teams writing parts of the overall solution but that trade-off can mean a lot of overhead in maintaining different code repositories of the same stack.<p>When a critical vulnerability comes out for whatever language you are using, you now have to patch, test and deploy X apps/repos vs much fewer if they are consolidated repositories written modularly.  Same can be said for library/framework upgrades, breaking changes in versions, deprecated features, taking advantage of new features, etc.<p>Keeping the definition of runtimes as modular as the code can be instrumental in keeping a bunch of related modules/features in one application/repository.  One way is with k8s deployments and init params where the app starts specific modules which then lends itself to be scaled differently. I'm sure there are home-grown ways to do this too without k8s.;0
34231053;HackerNews;2023-01-03;"&gt; However one of the unexpected consequences<p>How the hell... like... who decided to do Microservices in the first place if they didn't know this? This is such a rookie mistake. It's like somebody right out of high school just read on a blog the new way is &quot;microservices&quot; and then went ahead with it.";0
34231050;HackerNews;2023-01-03;IMO the real problem with microservices comes from dealing with distributed state - going from one data store with usually strong consistency guarantees - to many distributed stores that have no way of ensuring they are in sync is the hard part.<p>RPC vs local calls is trivial in comparison and you can get that level of transparency out of the box with functional programming - it's just data in data out.;0
34231022;HackerNews;2023-01-03;I am working on a project that uses a microservice architecture to make the individual components scalable and separate the concerns. However one of the unexpected consequences is that we are now doing a lot of network calls between these microservices, and this has actually become the main speed bottleneck for our program, especially since some of these services are not even in the same data center. We are now attempting to solve this with caches and doing batch requests, but all of this created additional overhead that could have all been avoided by not using microservices.<p>This experience has strongly impacted my view of microservices and for all personal projects I will develop in the future I will stick with a monolith until much later instead of starting with microservices.;0
34231020;HackerNews;2023-01-03;"Microservices, while often sold as solving a technical problem, usually actually solve for a human problem in scaling up an organization.<p>There's two technical problems that microservices purport to solve: modularization (separation of concerns, hiding implementation, document interface and all that good stuff) and scalability (being able to increase the amount of compute, memory and IO to the specific modules that need it).<p>The first problem, modules, can be solved at the language level. Modules can do that job, and that's the point of this blog post.<p>The second problem, scalability, is harder to solve at the language level in most languages outside those designed to be run in a distributed environment. But most people need it a lot less than they think. Normally the database is your bottleneck and if you keep your application server stateless, you can just run lots of them; the database can eventually be a bottleneck, but you can scale up databases <i>a lot</i>.<p>The real reason that microservices may make sense is because they keep people honest around module boundaries. They make it much harder to retain access to persistent in-memory state, harder to navigate object graphs to take dependencies on things they shouldn't, harder to create PRs with complex changes on either side of a module boundary without a conversation about designing for change and future proofing. Code ownership by teams is something you need as an organization scales, if only to reduce the amount of context switching that developers need to do if treated as fully fungible; owning a service is more defensible than owning a module, since the team will own release schedules and quality gating.<p>I'm not so positive on every microservice maintaining its own copy of state, potentially with its own separate data store. I think that usually adds more ongoing complexity in synchronization than it saves by isolating schemas. A better rule is for one service to own writes for a table, and other services can only read that table, and maybe even then not all columns or all non-owned tables. Problems with state synchronization are one of the most common failure modes in distributed applications, where queues get backed up, retries of &quot;bad&quot; events cause blockages and so on.";0
34231014;HackerNews;2023-01-03;As someone who has personally dealt with files as large as 60K lines, I disagree completely. I believe instead that structure and organization should be added as a business and codebase scales. The problem I think most orgs make is that, as they grow more successful, they don't take the time reorganize the system to support the growth, so, as the business scales 100x in employee account, employee efficiency is hampered by a code organization that was optimized for being small and nimble.<p>It gets worse when the people who made the mess quit or move on, leaving the new hires to deal with it. I've seen this pattern enough times to wonder if it gets repeated with most companies or projects.<p>I do agree that microservices and/or modules aren't magical solutions that should be universally applied. But they can be useful tools, depending on the situation, to organize or re-organize a system for particular purposes.<p>Anecdotally, I've noticed that smart people who aren't good programmers tend to be able to write code quickly that can scale to a particular point, like 10k-100k lines of code. Past that point, productivity falls rapidly. I do believe that part of being a skilled developer is being able to both design a system that scales to millions of lines of code across an organization, and to operate well on one designed by someone else.;0
34230950;HackerNews;2023-01-03;This article seems to have missed 16 years of event-based architectures, domain driven design, bound contexts, CQRS, and pretty much every reason we use microservices.;0
34230947;HackerNews;2023-01-03;you scale the component containing your module to multiple nodes, same with microservices, same with monoliths. the only reason it might be hard is if some other module in the component is aggressively preallocating resources even when lightly used, and that is a problem to be solved by itself, orthogonal to the deployment strategy<p>with a good branching strategy;0
34230923;HackerNews;2023-01-03;"The article above, and most if not all the comments I read right before posting this, seem to be very quiet about what I thought was one of the main &quot;distinctive elements&quot; of Microservices.<p>I.e. the idea that each microservice has direct access to its own, dedicated, maybe duplicated storage schema/instance (or if it needs to know, for example, the country name for ISO code &quot;UK&quot; it is supposed to ... invoke another microservice that will provide the answer for this).<p>I always worked in pretty boring stuff like managing reservations for cruise ships, or planning production for the next six weeks in an automotive plant.<p>The idea of having a federation of services/modules constantly cross-calling each other in order to just write &quot;Your cruise departs from Genova (Italy) at 12:15 on May 24th, 2023&quot; is not really a good fit for this kind of problems.<p>Maybe it is time to accept that not everyone has to work on the next version of Instagram and that Microservices are probably a good strategy... for a not really big subset of the problems we use computers for?";0
34230920;HackerNews;2023-01-03;You want to get away from sweeping generalisations because once the build/test/package/deployment tax of a modules approach bites, you do want to go monorepo microservices - it’s free clawback of time wasted building and deploying all the parts of a huge system that you didn’t change in your PR.;0
34230910;HackerNews;2023-01-03;"I can't say I agree with all your &quot;okays&quot;, although If you prefix them with &quot;In some cases it's okay&quot;, then I understand where you're coming from.<p>The problem is when it's OK and for how long. If you have a team of people working with a codebase with all those &quot;okays&quot;, then they have to be really good developers and know the code inside out. They have to agree when to refactor a business login out instead of adding a hacky &quot;if&quot; condition nested in another hacky &quot;if&quot; condition that depends on another argument and/or state.<p>I guess what I'm trying to say that if those &quot;okays&quot; are in place, then there's a whole bunch of unwritten rules that come in place.<p>But I agree that microservices certainly aren't free (I'd say they are crazy expensive) and modules aren't free either. But all those &quot;okays&quot; can end up costing you your codebase also.";0
34230907;HackerNews;2023-01-03;Yes, generally that's what we want -- modularity. I think the article touches upon a key truth, that There is Nothing New Under the Sun -- we always deal with complexity and we always find the same ways of structuring our responses to it.<p>One thing I've observed in a microservice-heavy shop before was that there was the Preferred Language and the Preferred Best Practices and they were the same or very similar across the multiple teams responsible for different things. It lead to a curious phenomenon, where despite the architectural modularity, the overall SAAS solution built upon these services felt very monolithic. It seemed counter-productive, because it weakened the motivation to keep separation across boundaries.;0
34230904;HackerNews;2023-01-03;If the same thing is said about A and B, it is not guaranteed that A=B, unless that thing specifies equality. Anyway I agree with the article that microservices are basically modules. They extend the domain of modules. They're usually overhyped.;0
34230874;HackerNews;2023-01-03;You want Elixir and Erlang/OTP process trees, not Microservices.;0
34230854;HackerNews;2023-01-03;"I'm unsure how to &quot;sell&quot; this idea. I don't want to force my view on others until I truly understand the problem that they're trying to solve with modules/microservices.<p>For searching multiple files, ripgrep works really well in neovim :)<p>[1] <a href=""https://github.com/BurntSushi/ripgrep"">https://github.com/BurntSushi/ripgrep</a>";0
34230828;HackerNews;2023-01-03;"This is the usual: &quot;don't use a one size fits all solution, sometimes microservices are good, sometimes they're bad. Just be smart and think about why you're doing things before doing them&quot;.";0
34230816;HackerNews;2023-01-03;Modules are lot cheaper if you have a solver for them.<p>Microservices are the same modules. Though they force-add distributiveness, even where it can be avoided, which is fundamentally worse. And they make integration and many other things lot harder.;0
34230782;HackerNews;2023-01-03;How can I sell your idea?<p>I easily find my way in messy codes with grep. With modules, I need to know where to search to begin with, and in which version.<p>Fortunately, I have never had the occasion to deal with microservices.;0
34230748;HackerNews;2023-01-03;"I suspect that most people would be better off favoring inlined code over modules and microservices.<p>It's okay to not organize your code. It's okay to have files with 10,000 lines. It's okay not to put &quot;business logic&quot; in a special place. It's okay to make merge conflicts.<p>The overhead devs spend worrying about code organization may vastly exceed the amount of time floundering with messy programs.<p>Microservices aren't free, and neither are modules.<p>[1] Jonathan Blow rant: <a href=""https://www.youtube.com/watch?v=5Nc68IdNKdg&amp;t=364s"">https://www.youtube.com/watch?v=5Nc68IdNKdg&amp;t=364s</a><p>[2] Jon Carmack rant: <a href=""http://number-none.com/blow/john_carmack_on_inlined_code.html"" rel=""nofollow"">http://number-none.com/blow/john_carmack_on_inlined_code.htm...</a>";0
