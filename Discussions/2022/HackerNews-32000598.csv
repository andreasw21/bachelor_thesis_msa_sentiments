ID;Source;Creation Date;Content;Sentiment
32000598;HackerNews;2022-07-06;Title:How to Improve Your Monolith Before Transitioning to Microservices, Content: https://semaphoreci.com/blog/monolith-microservices;0

32029726;HackerNews;2022-07-09;smart experienced developers use the least complex tool to solve a problem. and monoliths are inherently less complex than microservices. so its quite simple really.unfortunately beginner experts tends to pick the most complex tool possible to solve a problem because they think it somehow demonstrate how skilledsmart they are. which always amuses the more experienced developers. its like watching a train wreck in slow motion i am looking forward to reading the future we picked microservices because we thought we were clever and it turned into a cluster f stories.;0
32025714;HackerNews;2022-07-08;i suspect a lot of companies are pushing for ms architecture because its trendy not because it makes sense for their own use case which is what is causing such a strong reaction on hn. moreover i suspect that the services end up being very small and as such rather poorly self contained. all i wanted to say with my comment is that microservices are a tool and there are certain scenarios where they could be a good solution to a problem although perhaps not the only one.i do want to provide a counter point example against everything must be a monolith. years ago i worked at a medium sized company that worshiped at the altar of monolith and the mantra of this is how google does it was often repeated. unfortunately what they were doing was far from what google was doing. their monolith incorporated solutions for multiple largely unrelated business lines. all of the code deployed across all of the hundreds of servers and data was shared without any sense of boundaries across the entire app. the company didn't want to invest significantly into the appropriate tooling to make such a large app function well multiple gigabytes source code written in php. the result was a terrible dev experience where deployments took 4 to 6 hours on a good day and the blast radius of a given change was sometimes hard to verify. its akin to sharing servers between gmail and google docs and mixing up the code together for good measure so it can be reused. this created a culture of slow moving large development cycles as well as a lot of defensiveness and fear within the software engineering group. suffice to say it was not a pleasant experience.before i get down voted a bunch i should say i also tend to prefer monoliths as much as possible. they are much simpler to work with much simpler to test and easier to analyze. also if using a good compiled language the compiler can help a lot to eliminate a lot of common silly regressions. however that being said i would consider making a new service in certain cases. for example if i was building a new unrelated product or if there was a part of the app that was functionally very different from the rest of the app.i also tend to distinguish between a mono repo single repo can have more than one service in it and monolith single app. if you are willing to setup some more sophisticated cicd tooling i think mono repo is the way to go even when it makes sense to have more than one service in the design of the app.;0
32017713;HackerNews;2022-07-07;iand i now work for an org with a monorepo with 100 developers that probably should have been broken up into microservices a while ago.iif its a monolith then i think its not a monorepo?;0
32017702;HackerNews;2022-07-07;microservices are incompatible with monlithic text based logging maybe they meant that?;0
32015170;HackerNews;2022-07-07;if you have shared data with relationships in the data that is shared infrastructure whether it is physically manifested in one place or not.if you choose to parcel that information out into multiple pieces of infrastructure to avoid a single point of failure you've now moved the nature of your problem from maintaining the shared database to maintaining the iprocessi of managing that data in multiple places.you'll be doing clientside or serviceside joins all over in order to produce a unified piece of data. but note you still haven't removed the dependency on the shared state. you've simply moved the dependency. and in the process made it more complicated.this might have the advantage of making it not the problem of the opssysadminsre. but it has the problem of making it the problem for either the customer in the case of shitty data in the client or the developer in the case of having to fix bugs. and i can guarantee you that the developers working on mycoolmicroservice are way shittier at understanding data serialization and coherence and transaction management than the people who wrote your database engine.the acid relational model was developed for a reason. the set of compromises and problems we are dealing with in infrastructure has been known since the 60s when dateampcodd et al proposed it. the right thing to do for engineering amp the infrastructure level is to make the pieces of shared database super reliable and performant at scale not to try to handwave them away by pushing the problem elsewhere.;0
32014040;HackerNews;2022-07-07;i think their point is that trying to continue to work inside such a monolith is soulcrushing but attempts to replace the monolith in one step fail because it's too big.i do think there's some confusion though because microservices are not the only solution to this problem. you can solve it with two services the big legacy service hosts all the logic you haven't cleaned up yet the smallbutgrowing modern service has the logic that you've cleaned up and made livable.this way you don't have to replace the old monolith in one step but you also don't need to go to microservicesthe target is still one wellfactored monolith.edit there's a risk here of course that your new code becomes another legacy ball of mud that everyone hates and the cycle repeats but this time with two services...;0
32011025;HackerNews;2022-07-07;the advantages of services and the complexity of distributed systems are obviously at odds with each other and proper architecture is going to be a requirement to be able to use a services oriented setup to its advantage.if your team was bad at systems architecture before attempting such a project then they will do much worse than before. but this is akin to saying that cooks should not use sharp knives because they can cut themselves. yes they can. but expert cooks would much rather use sharp knives than blunt ones even if they run the risk of cutting themselves.a team of alsorans that go for a services oriented solution in a cargo cult fashion is going to get bogged down by complexity. that's no change from them getting bogged down by using a monolith that turned into a bowl of spaghetti.i've seen microservices applied in ways that made my hair stand on end every shitty little function was its own service and had its own api. utter madness. but i've also seen a monolith with several major functional blocks cut up on sensible lines and then dealt with by a much larger number of teams than before with success. like everything else if you are doing it wrong no amount of magic is going to help you you first need to know what it is that you are doing.my best advice if this sounds familiar is that you should up the hiring bar considerably so. but that will also require paying more per person and companies that have a problem with the former usually also have a problem with the latter.;0
32010956;HackerNews;2022-07-07;factoring their shit correctlywhen is shit ever factored correctly? next week your product owner will come over with a new idea for a feature spanning multiple modules and suddenly you will realize you should have factored your shit differently and maybe not split things up into multiple microservices prematurely.so what i'm trying to say is grug is right. factoring a piece of software correctly is one of the hardest issues. the iassumptioni that you can do it correctly is the reason why so many microservice architectures are such a pita to work with.;0
32010946;HackerNews;2022-07-07;if you suck at architecture then yes microservices won't solve that problem. but used properly like with every other tool this is one problem that can be solved this way.the whole idea that you take a monolith and then explode it into 50 or even 100 pieces with all the added complexity that involves without thinking about it beforehand and aiming for specific goals is obviously broken and that's not what i'm advocating for. but when properly used you can design your services in such a way that those problems do not arise. some ecosystems notably erlang have elevated this concept to first class status and from personal experience and looking at some companies that did it properly i can tell you that it works and that it works very well.;0
32010420;HackerNews;2022-07-07;great now do multiple versions of typescript. and jest. and tsjest.why would i do that?there is absolutely no reason a single application should be using two versions of typescript at the same time. what you're talking about is a combinatorial explosion of packages and versions it's bad bad bad for software quality.upgrade paths can be done gradually. i've done and seen it done more times than i can count. for how long? until it gets to what size?that depends a great deal on the type of software and how it was engineered.if you inherit a mess and your engineering team is incapable of not creating a mess then sure drawing heavy handed microservice boundaries might make sense. but in that case you're solving an organizational problem not a technical problem. all of the technical benefits you've been claiming are moot. so generating multiple executables from one repo? that is a monorepo if you have a bunch of processes that communicate with each other through some channel be it pipes or sockets or whatever then i'm going to argue you have microservices. they may be running on one machine but again you have multiple processing talking to each other.you could generate multiple executables. or you can generate a single executable that's able to run in different modes so to speak.what you've shown throughout your writing is you don't quite understand what microservice architecture is. multiple applications communicating over the network or whatever is not a microservice. why wouldn't you just call that a service?a microservice is a very small application that encapsulates some unit of your larger application. where that boundary is drawn is obviously up for debate.i don't wanna digress but i can assure that two applications on the same server talking over a network is not a microservice. that's just... like... software lol. now i'll also argue that such code bases are more likely to have strong coupling between components. it doesn't have to be that way but it becomes harder to resist or to just stop junior devs from inadvertently doing.creating a network boundary a huge performance cost just to prevent people from doing stupid stuff is not good software architecture. so one executable with multiple network endpoints exposed? sure. but you have lost some security boundaries in the process. if the only system that can ever have customer pii lives inside a firewall with no public ip address you've gained security vs pii floating around in the same process memory address as your public endpoints.your pii lives in a database. restrict read access to that database or subset of that database to applications running on the internal network. the most straightforward way to do that would be through configuration management.applications accessible to the outside world will never even have read access.with microservices there is nothing stopping some tiny internal service from exposing data to a public service. maybe the internal service wrote their acls wrong and the data leaked out.what you're describing again has nothing to do with microservices and is a problem you need to deal with either way.pii is a idatai problem not a icodei problem. microservicemonolith is a code problem not a data problem. also the unix philosophy is small dedicated programs that do one thing really well. kind of like... microservices.so now all programs that communicate over the network are microservices. do you not see how silly that sounds? vs a monolith where you have everything running on one machine under one process.that's not how anyone deploys monolithic applications. you're now trying to claim that monolithic applications only run one server. confusing. different problem domains are best solved with different programming paradigms.that's why we create multiple applications that do different things. microservices are something totally different. if you have well defined interfaces you don't need atomic builds. that is kind of the entire point! unless there are some legal requirements which mandate blessed builds.the benefit of atomic builds is it's very easy to reproduce the behavior of your application at any given moment.so for example a user reports a difficult to find bug and you're only investigating it 2 weeks later. you'll need to rewind your application's code state to whatever it was at the time that the user was using your application. for a monolithic application this is as easy as pointing the monolithic repo to some commit sha.with microservices this is much harder to do without tooling. this can be for many reasons. sometimes every microservice is a separate repo. sometimes your development environment isn't running every microservice. pure functional peeps say no state at all and arguably the functional paradigm often works but the performance hit is insane at times.i'm not even that into fp and this is painful to read. such a gross misrepresentation of what fp is about. microservices say you need to decouple components and that components can only talk through preestablished and agreed upon messages.you mean like function calls? it enforces this decoupling by isolating different bits of code on the other sides of boundariesyou mean like... visibility? as in publicprivate interfaces? so that network connections of some type have to be used to communicate between modulesenforcing correctness by placing a network boundary is too heavy handed. there are other ways to achieve the same thing that doesn't involve adding orders of magnitude latency for no reason. you get some benefits with this i still maintain it is easier to update to new breaking changes of dependencies on smaller chunks of code rather than adopt a breaking change to a global dependency across possibly hundreds of thousands of lines of code.you do realize that large software existed before microservices became a thing right? and it was maintainable right? there are so many ways to solve this problem without affecting thousands of lines of code blindly.there's also just as much risk in having 10 services that are running slightly different versions of the same dependency. in fact that's a freaking nightmare. because you only need to maintain the api contract microservices can be deployed in a true cicd fashion with teams constantly releasing changes to their services throughout the day every workday.sir i'm afraid of you have a bad case of buzzworditis.;0
32010287;HackerNews;2022-07-07;i sympathize with both positions however spend any time working somewhere like a bank or hardwareelectronics company founded before 1980 and youll develop a distinct distaste for monoliths.ive seen monoliths create teams of career software bureaucrats who exist to choke out companies to their last breath. companies will go underserved for decades while underfunded projects fail to replace a monolith one after another. all crossroads lead to the monolith that was written in some language that died 30 years ago performs like it did 30 years ago and is maintained by people hired 30 years ago creating imminent crises with their looming retirements.i think a lot of people here read this article as writing monoliths vs microservices not so. there are many very old inherited monoliths that are actively creating maintenance crises at many businesses. these need to be modernized in chunks because full rewrites take years to fail and often do eg. the mythical data warehouse. microservices offer some incremental path out of the quagmire.;0
32010149;HackerNews;2022-07-07;i've honestly never understood this argument. there's some changes that are intractable. just being in a separate codebase doesn't mean you don't need to deal with it. team a just modified their service to require a new field in a request? now you just have teams bg having to play a card to update their corresponding code if they consume that service. and unless you have everything feature flagged across all teams in a consistent way or are very careful about api versioning you'll all need to release at the same time anyways. nothing magical about microservices solves this no?;0
32010121;HackerNews;2022-07-07;that definition of strong coupling is in fact standard. like if you ask people why they don't want strong coupling they tell you exactly that when you change a strongly coupled thing you induce bugs far away from the thing you changed and that sucks.now you might iwanti this strong coupling between frontend and backend and that's okjust version them together! always version strongly coupled things together. you should not be guessing about what versions are compatible with what other versions based on some sort of timestamp instead just have a hash and invest a halfweek of devops work to detecting whether you need to deploy it or not. indeed the idea of versioning a frontend separate from a backend is somewhat of an abdication of domaindriven design you are splitting one bounded context into two parts over what programming language they are written inliterally an implementation detail rather than a domain concern.other patterns which give flexibility in this sense include subscription to events. an event is carefully defined as saying this happened over here and receivers have to decide what that means to them. there's no reason the frontend can't send these to a backend component indeed that was the mvc definition of a controller. netflix's ill take anything you got requests. the key here is saying i will display whatever i can display but i'm not expecting i can display everything. hateoas which can function as a sort of dynamic capability discovery. tell me how to query you and when the backend downgrades the frontend automatically stops asking for the new functionality because it can see it no longer knows how. http headers. i think people will probably think that i am being facetious here what do http headers have to do with anything. but actually the core of this protocol that we use the true heart and soul of it was always about content negotiation. comsumers are always supposed to be stating upfront their capabilities they are allowed a preflight options request to interrogate the servers capabilities before they reveal their own servers always try to respond with something within those capabilities or else there are standard error codes to indicate that they can't. we literally live on top of a content negotiation protocol and most folks don't do content negotiation with it. but you can.the key to most of these is encapsulation the actual api request whatever it is it does not change its form over that 6 month period. in 12 months we will still be requesting all of these messages from these pubsub topics in 12 months time our hateoas entry point will still be suchandso. kind of any agreed starting point can work as a basis the problem is purely that folks want to be able to revise the protocol with each backend release which is fine but it forces coupling.there's nothing wrong with strong coupling if you are honest about it and version the things together so that you can test them together and understand that if you are going to split the responsibilities between different teams than they will need to have regular meetings to communicate. that's fine it's a valid choice. i don't see why people who are committing to microservices think that making these choices is okay as long as you lie about what they are. that's not me saying that the choices are not okay it's me saying that the selfdeception is not okay.;0
32010004;HackerNews;2022-07-07;they are referring to software structure and decomposition.this is a hard problem that spans architectures you can have a poorly factored microservice architecture just as you can have a poorly factored monolith.these two posts from shopify are good;0
32009818;HackerNews;2022-07-07;that's the problem with a lot of these discussions. conclusions are often based on layers of other conclusions that could be wrong.great now do multiple versions of typescript. and jest. and tsjest. and while you are at it how would you change over from using a legacy test system such as sinon to jest? with microservices it is easy newly generated services use jest old ones can update when they want to.could you engineer a code base so different folders use different testing frameworks and different versions of different testing frameworks? sure. at the cost of added complexity. i don't see what this story has to do with microservices. that kind of velocity can easily be achieved with a single codebase too.for how long? until it gets to what size?i've spent my life working on large code bases the velocity always falls off typically it is best in the first 6 months steady state for another year or 2 and then undergoes a steady decline for another 2 or 3 years after that until it levels off at well it's legacy what you do expect? a monolithic application can run in different modes. for example of if you run .myapp api then it'll start an api server. if you run .mayapp queue then it'll run the message queue processor. and so on.so generating multiple executables from one repo? that is a monorepo if you have a bunch of processes that communicate with each other through some channel be it pipes or sockets or whatever then i'm going to argue you have microservices. they may be running on one machine but again you have multiple processing talking to each other.now i'll also argue that such code bases are more likely to have strong coupling between components. it doesn't have to be that way but it becomes harder to resist or to just stop junior devs from inadvertently doing. the whole publicprivate networking thing is an infrastructure decision. your monolithic application could easily have internal endpoints that are only exposed when certain flags are set.so one executable with multiple network endpoints exposed? sure. but you have lost some security boundaries in the process. if the only system that can ever have customer pii lives inside a firewall with no public ip address you've gained security vs pii floating around in the same process memory address as your public endpoints.also now teams have to maintain two versions of their api one internal for binary callers another for the exposed network endpoint. odds are that exposed network api is just not going to ever be written or if it is it will quickly become out of date unless it is very highly often used. which means if in a few years someone has a great idea for an underutilized api it will likely be missing major version updates and be old and crufty and barely functioning. that has nothing to do with microservices. you can thank the unix architecture for that. most computers run more than one program written in more than one programming language.the characteristics of hardware that do db queries are different than the hw that does video transcoding. with microservices you can shove your video encoding service on some machines with powerful gpus and the part of your code that talks to the db on another machine and when your s3 bucket gets full of files you need to transcode you can spin up more transcoding machines.vs a monolith where you have everything running on one machine under one process. sure you can just scale up your entire app but that is absurd and i'm sure literally no one does that people who need to transcode lots of video have idedicatedi machines that do the transcoding because having the same machine that serves up your website also transcode video is beyond inefficient.also the unix philosophy is small dedicated programs that do one thing really well. kind of like... microservices. what are those limits praytell?different problem domains are best solved with different programming paradigms. having dramatic tonal shifts within one application is confusing really fast. having part of an app use mobx and another part be completely stateless and a third part use complex oo domain modeling is going to give maintainers whiplash.and then you have to have all those different systems talk to each other. which means you need translation layers for get shit out of mobx and put it into this other system.at which point you either have well defined boundaries or a ball of spaghetti but once an app has grown to the point of absurdly different problem domains it may be time to start thinking about breaking it up into imultiple appsi and figuring out how they should talk to each other. by the way the big problems with microservice architectures is you don't get atomic builds. very difficult problem to work around. usually with lots of tooling.if you have well defined interfaces you don't need atomic builds. that is kind of the entire point! unless there are some legal requirements which mandate blessed builds.microservices of course have a huge performance penalty but so does every other programming paradigm. imho paradigms exist to irestricti what programmers can do. oo people say you need to shove your nouns and verbs together and only expose a limited amount of state. those are some serious limitations and as the java ecosystem has demonstrated to us they aren't enough to prevent complex balls of mud from being developed.pure functional peeps say no state at all and arguably the functional paradigm often works but the performance hit is insane at times.microservices say you need to decouple components and that components can only talk through preestablished and agreed upon messages. it enforces this decoupling by isolating different bits of code on the other sides of boundaries so that network connections of some type have to be used to communicate between modules.you get some benefits with this i still maintain it is easier to update to new ibreakingi changes of dependencies on smaller chunks of code rather than adopt a breaking change to a global dependency across possibly hundreds of thousands of lines of code.also you can deploy a service that does a thing to the appropriate hardware. i'm still not sure what you are talking about in reference to a monolith that spits out multiple executables that sounds like a monorepo that generates multiple services each of which i presume has to talk to each other somehow.because you only need to maintain the api contract microservices can be deployed in a true cicd fashion with teams constantly releasing changes to their services throughout the day every workday.there are downsides. microservices have a huge performance overhead. refactoring across microservices isucksi thus why some teams adopt a monorepo approach but that brings along its own set of complications refactors across multiple services means you have to deploy all those services at the same time. for an organization that may be used to managing a hundred microservices independently of each other all at once deployments can be a huge productivity loss.microservices also have build and deployment complexity. it is largely an up front tooling cost but it is a huge cost to pay.;0
32009617;HackerNews;2022-07-07;i think services became really popular from amazon and that quickly went to microservices imho. it's perhaps analogous to say that's what amazon does. seems to work fine for them. it's very interesting there are big techs now with well known monoliths vs amazon services.though amazon's services are so that any internally useful tool can be externally exposed and then rented out to generate more revenue. the reasonsbenefits are very different compared to say decoupling or the other reasons given for service orientated architectures.;0
32009602;HackerNews;2022-07-07;ipick something easy to start with like edge services that have little overlap with the rest of the monolith. you could for instance build an authentication microservice and route login requests as a first step.i;0
32009596;HackerNews;2022-07-07;when you have a very large number of employees developing software it means that you can keep your teams out of each others' hairtwo things here. one is that it often looks like the tail wagging the dog. microservices are often introduced to manage and support development teams that grew too large. unfortunately the correct course of action in such cases is layoffs not microservices.two. in my experience the places i worked at where microservices were extensively used had even more issues of employees stepping on each other as compatibility issues and upgrade sequence between services were a frequent concern and the independent testing was a total myth as most teams did not provide good mocks for their api surfaces. meanwhile troubleshooting such distributed systems was very real and very hard.;0
32009395;HackerNews;2022-07-07;the world is not so black and white and silos have legitimate business purposes. the reality is that any one contributor or team can only handle so much. when duties must be split between teams for effective ownership of responsibilities separation of concerns becomes paramount to the continued progress in any one domain.if all you have is one team microservices make no sense.;0
32009295;HackerNews;2022-07-07;nope. microservices are iguaranteedi to be more complex than an iequivalenti monolith. it constantly blows my mind that it isnt obvious to some developers. a idistributedi system microservices is ialwaysi more complex than a inondistributedi system monolith.;0
32009271;HackerNews;2022-07-07;not my experience at all. it takes the isamei skills to manage a monolith as it does managing microservices. however microservices are inherently imorei complex than monoliths. so they are harder to keep cleanmaintainable. all complex problemssystems are solved by breaking them down into smaller problemssystems that can be solved. using microservices doesnt make that easier. it actually makes it iharderi because you now also have to deal with the complexity of a distributed system.;0
32009238;HackerNews;2022-07-07;apparently google is doing fine without microservices.;0
32009155;HackerNews;2022-07-07;if you dont have the skills to write modular imaintainablei monoliths then you most idefinitelyi dont have the skills to implement modular maintainable microservices. its the isamei skills required to do both the ability to break down a complex systemproblem into a number of isimpleri systemssolutionsmoduleslibrariesservices so that the complex systemproblem can be solved by icomposingi those simpler systemssolutionsmoduleslibraries into a single systemmonolith;0
32008910;HackerNews;2022-07-07;heck even with js yarn and npm are not fun. that's the problem with a lot of these discussions. conclusions are often based on layers of other conclusions that could be wrong. that website runs in its own microservice with a customized version of the org's build system something that was possible because as an organization we have scripts that allow for the easy creation of new services in just a matter of minutes.i don't see what this story has to do with microservices. that kind of velocity can easily be achieved with a single codebase too. scaling different parts of a system need to scale based on different criteria.that's not at all unique to microservices.a monolithic application can run in different modes. for example of if you run .myapp api then it'll start an api server. if you run .mayapp queue then it'll run the message queue processor. and so on.this way you can run 10 api servers and 50 queue processors and scale them independently. how an application is deployed isn't necessarily tied to how it's built. another cool feature of microservices is you can choose what parts are exposed to the public internet vs internal to your network. holy cow so nice! could you do that with a monolith? sure i guess. is it as simple as a command line option when creating a new service? if you have an absurdly well defined monolith maybe.i'm confused.is there some magical program called microservice that takes command line options? what does a systems architecture approach have anything to do ease of deployment?the whole publicprivate networking thing is an infrastructure decision. your monolithic application could easily have internal endpoints that are only exposed when certain flags are set. with microservices impedance mismatches are hidden behind network call boundaries. yes you can architect monoliths in vastly different fashions throughout and i've done such but there is a limit to that.what are those limits praytell? e.g. with microservices you can have one running bare metal written in c on a hard real time os and other written in python.that has nothing to do with microservices. you can thank the unix architecture for that. most computers run more than one program written in more than one programming language. oh and well defined builds and deployments is another thing i like about microservices. i've encountered monoliths where literally no one knew how to completely rebuild the production environment i overheard from another engineer that xbox live services existed in that state for awhile...so it was architected poorly. why is that a strike against monoliths? are you saying that messy builds are impossible with a microservice architecture? one of the top arguments against microservices is how much of a rats nest they are in production in practice.some companies are able to do it right with discipline and good engineering. the same can be said for monoliths.by the way the big problems with microservice architectures is you don't get atomic builds. very difficult problem to work around. usually with lots of tooling.;0
32008837;HackerNews;2022-07-07;90 of transitions to microservices occur because the developers involved need to give the impression they are doing something in the absence of being allowed to build something new like they would prefer and want to put microservices on their resume for when they try to leave their current shithole of a company for a slightly better paying trendier shithole;0
32008759;HackerNews;2022-07-07;i've tried searching this and couldn't find anything related to microservices what is the factoring problem or system that grugbrain is referring to?is it something to do with calculating the cost of splitting off a monolith into a microservice vs. some other method?;0
32008216;HackerNews;2022-07-07;another issue is backwards compatibility. with microservices you have to keep your old endpoints open until everyone has migrated and make sure the new endpoint is always available when upgrading.much simpler to verify with tests with a monolith.;0
32008209;HackerNews;2022-07-07;this sounds like multiple frontend apps talking to a single api service.frontend apps are a different beast here the general monolith microservice transition like discussed here is talking just about the backend services. for standalone app code that i only share 10 of the stuff problem can be fairly easily solved with libraries.for backend services libraries most likely aren't what you want because you don't iwanti 5 different services all using the same library to talk directly to the same sql database or whatever. you'd rather have a single service responsible for that database communication.in a microservices world you tend towards one logical domain object in the system? one service. in a more monolithic world you have much larger groupings where a single service might be related to say user accounts and user text content and references to photo libraries or whatever. it's probably not actually ieverythingi some stuff scales at wildly different rates than others but you aren't nearly as aggressive at looking for ways to split stuff up and your default for new functionality tends to be to find the service to add it to.;0
32008154;HackerNews;2022-07-07;dividing areas amongst teams is only a theoretical benefit if you haven't solved the factoring problem. otherwise teams are still going to be crossdependent on other teams constantly.but if you've solved the factoring problem your team and another team can happily work next to each other in the same codebase with less backandforth anyway. and the question reduces largely to if you deploy it all at once or not. sometimes all at once is much easier anyway.i've seen microservices used by management as a way to iforcei engineering into factoring their shit correctly far more often than i've seen it done because things were already factored well because crossteam coordination in different services is much harder than just jumping around in the monolith's single repo in a single pr. it's an easy lever for management to pull too because most devs don't see it as something they're being forced to do they think they're getting their wish at rewriting and modernizing things.;0
32008148;HackerNews;2022-07-07;hold on if we have half a dozen web apps that serve different needs but all share similar guts a monolith doesn't really make sense because app b will have all the code of app a but only use like 10 of it...so if i split app a from app b and app c d etc. but create a single backend monolith for both apps that makes sense right? is that still microservices?and if half of them need authentication but i want to keep my auth data separate from my other backend data shouldn't i create a regular db backend and an auth backend for my many web apps?essentially this is what i've done. i don't start with microservices but at the same time i don't want to glom all my random sites and apps' frontend and backends into the same code base... that makes upkeep way too difficult.is this a monolith a microservices or none of those? i'm not really a real engineer and haven't drank any koolaid so i honestly don't know if this is the right way to do it. most of my sites and web apps are sveltekit vercel with cf workers supabase deta and railway doing some other stuff vercel can't do.i don't have a hosted machine or anything lol;0
32007902;HackerNews;2022-07-07;if you're a company releasing changes daily hourly monoliths make progressively less sense and become progressively harder to work with.counter argument your overall cicd infrastructure landscape will be much simpler and muss less errorprone.as will be your release and test pipelines. for instance if you have a few dozen microservices each being released every other hour how do you run e2e tests across all services before you release anything? let's say you take your microservice a in version v1.2.3 soon to be released and test it against microservice b's current prod version v2.0.1. meanwhile team b is also working on releasing the new version v2.1.0 of microservice b and testing it against a's current prod version v1.2.2. both test runs work fine. but no one ever bothered to test a v1.2.3 and b v2.1.0 against each other;0
32007783;HackerNews;2022-07-07;in all my years i've never seen a code freeze due to a dependency update. maybe the project you were working was poorly engineered?i spent a decade at microsoft i started before cloud was a thing. all code lived in monoliths1. i once had the displeasure of looking at the source tree for xbox live circa 2008 or so. nasty stuff.don't check anything in today we're trying to finish up this merge was not an uncommon refrain.but you are right often times there wasn't code freezes instead system wide changes involved obscene engineering efforts so developers could keep the change branch up to date with mainline while dependencies were being updated.i'll confess my experience with large monolithic code bases are all around nonnetworked code but imho the engineering maintenance challenges are the same. there should be nothing stopping you from running multiple versions of a dependency within a single monolothic project.build systems. they are complicated. i spent most of my life pre js in native cc land. adopting a library at all was an undertaking. trying to add 2 versions of a library to a code base? bad idea.heck even with js yarn and npm are not fun. and once a build system for a monolith is in place well the entire idea is that a monolith is one code base compiled into one executable so you don't really swap out parts of the build system.hope none of your code is dependent upon a compiler extension that got dropped 2 years back. and if it is better find time in the schedule to have developers rewrite code that still works just fine.contrast that in my current role each microservice can have its own build tools and version of build tools. when my team needed to update to the latest version of typescript to support the new aws sdk which gave us an insane double digit perf improvement we were able to even though the organization as a whole was not yet moving over.meanwhile in monolith land you have a build system that is so complicated that the dedicated team in charge of maintaining it is the only team who has even the slightest grasp on how it works and even then the build systems i've seen are literally decades old and no one person or even group of people have a complete understanding of it.another benefit is that microservices force well defined api boundaries. they force developers to consider up front what api consumers are going to want. they force teams to make a choice between engineering around versioning apis or accepting breaking changes.finally having a rest api for everything is just a nice way to do things. i've found myself able to build tools on top of various microservices that would otherwise not have been possible if those services were locked up behind a monolith instead of having an exposed api.in fact i just got done designinglaunching an internal tool that was only possible because my entire organization uses microservices. another team already had made an internal web tool and as part of it they made a separate internal auth microservice because ieverythingi is a microservice. i was able to wire up my team's microservices with their auth service and throw a web ui on top of it all. that website runs in its own microservice with a customized version of the org's build system something that was possible because as an organization we have scripts that allow for the easy creation of new services in just a matter of minutes.back when i was at microsoft inonei of the projects i worked on would have allowed for that sort of absurd code velocity.another cool feature of microservices is you can choose what parts are exposed to the public internet vs internal to your network. holy cow so nice! could you do that with a monolith? sure i guess. is it as simple as a command line option when creating a new service? if you have an absurdly well defined monolith maybe.scaling different parts of a system need to scale based on different criteria. if you have a monolith that is running on some of vms how do you determine when to scale it up and by how much? for microservices you get insane granularity. the microservice pulling data from a queue can autoscale when the queue gets too big the microservice doing video transcoding can pull in some more gpus when its pool of tasks grows too large. with a monolith you have to scale the entire thing up at once and choose if you want vertical or horizontal scaling.you can also architect each microservice in a way that is appropriate for the task at hand. maybe pure functions and completely stateless makes sense for one service where as a complex oo object hierarchy makes sense someplace else. with microservices impedance mismatches are hidden behind network call boundaries. yes you can architect monoliths in vastly different fashions throughout and i've done such but there is a limit to that.e.g. with microservices you can have one running bare metal written in c on a hard real time os and other written in python.oh and well defined builds and deployments is another thing i like about microservices. i've encountered monoliths where literally no one knew how to completely rebuild the production environment i overheard from another engineer that xbox live services existed in that state for awhile...and again my bias is that i've only ever worked on large systems. outside my startup i've never worked on a project that didn't end up with at least a couple hundred software engineers writing code all towards one goal.is k8s and microservices a good idea for a 5 person startup? hell no. i ran my startup off a couple vms that i scp'd deployments to along side some firebase functions. worked great.1 this is not completely true office is divided up pretty well and you can pull in bits and pieces of code pretty independently so if you want a rich text editor that is its own module. imho they've done as good of a job as is possible for native.;0
32007777;HackerNews;2022-07-07;there are two ways to interpret this question and i'm not sure which you're asking. you should not have two microservices isharingi a single database there lies race conditions and schema nightmares but it is totally fine for some microservices to not have any database at all.;0
32007731;HackerNews;2022-07-07;strong agree. i worked on a distributed monolith once and now i loudly make it a requirement that all my team's microservices can easily be run locally. running one stack locally required starting up 12 different microservices all in a particular order before you could do anything with any of them. insanity.;0
32007683;HackerNews;2022-07-07;advice. dont bother if you have a monolith. just keep trucking on with it and partition your stuff vertically with shared auth and marketing site.fuck microservices unless you have a tiny little product with a few million users. which is almost none of us.;0
32007634;HackerNews;2022-07-07;the benefit of microservices is that you can divide areas of responsibility among teams and theoretically uncouple the change processes for each;0
32007598;HackerNews;2022-07-07;i have a strong feeling that the author never in their career transitioned from monolith to microservices. even to the point we are getting somewhere not to mention we are successful at this. text reads like self complacency.;0
32007455;HackerNews;2022-07-07;fundamental problem is cargo cult developers trying to copy massive companies architectures as a startup. they fail to realize those companies only moved to microservices because they had no other option.this.microservices add complexity therefore they should be avoided unless necessary. that's engineering 101 folks.;0
32007094;HackerNews;2022-07-06;i'm skeptical of over using microservices but i don't quite understand how they make an app incompatible with logging.;0
32006809;HackerNews;2022-07-06;is there ever a good reason to change from monolith to microservices unless you have already solved the factoring problem in the monolith? the factoring problem doesn't get easier because you add network calls into the mix but being well factored first makes adding the network calls a lot easier. if you're lucky your framework or platform already has that part figured out.maybe one exception is if you absolutely must change the programming language at the same time but even then i would suggest doing the rewrite as a monolith first for the same reason so you again don't have to deal with network calls at the same time as solving an already insanely hard problem.there's the argument that microservices lets you gradually replace the old monolith piece by piece but there's nothing special about microservices for that you can do that with two monoliths and a reverse proxy.and at the end of either you might find that you didn't need microservices in the first place you just needed to factor the application better.;0
32006730;HackerNews;2022-07-06;i agree that we need to at least inamei nanoservices microservices that are too small. like isurelyi we can all agree that if your current microservices were 100x smaller so that each handled exactly one property of whatever they're meant to track it'd be a nightmare. so there imusti be a lower limit we want to go this small and no smaller.i think we also need to name something about coupling. coupling is a really fluid term as used in the microservice world. our microservices are not strongly coupled. really so could i take this one roll it back by 6 months in response to an emergency and that one would still work? err... no that one is a frontend it consumes an api provided by the former if you roll back the api by 6 months the frontend will break. well i am sorry my definition of strong coupling is can i make a change over here without something over there breaking ifor example rolling back something by 6 monthsi. maybe we found out that this service's codebase had unauthorized entries from some developer 5 months ago and we want to step through every single damn thing that developer wrote one by one to make sure it's not leaking everyone's data. idk. make up your own scenario.;0
32006445;HackerNews;2022-07-06;10 modularize the monolitha couple paragraphs on a couple of tools for the middle to late stages of such an effort is tantamount to and then draw the rest of the fucking owl.decomposition is hard. it's doubly hard when you have coworkers who are addicted to the vast namespace of possibilities in the code and are reaching halfway across the codebase to grab data to do something and now those things can never be separated.one of the best tools i know for breaking up a monolith is to start writing little command line debugging tools for these concerns. this exposes the decision making process the dependency tree and how they complicate each other. clis are much easier to run in a debugger than trying to spin up the application and step through some integration tests.if you can't get feature parity between the running system and the cli then you aren't going to be able to reach feature parity running it in a microservice either. it's an easier milestone to reach and it has applications to more immediate problems like trying to figure out what change just broke preprod.i have things that will never be microservices that benefit from this. i have things that used to be microservices that didn't need to be especially once you had a straightforward way to run the code without it.;0
32006223;HackerNews;2022-07-06;microservices have one big advantage over monoliths when you have a very large number of employees developing software it means that you can keep your teams out of each others' hair. if you don't have a very large team as in 50 developers you are iprobablyi better off with a monolith or at best a couple of much larger services that can be developed tested and released independently of each other. that will get you very far further than most startups will ever go.;0
32006162;HackerNews;2022-07-06;seriously! i think there is a good space for the concept of midservices cluster similar and interdependent services and service fragments together so they split in logical groups for updating.it would be sort of like module a is authentication and session management module b is data handling layer and module 3 is the presentation and processing layer. each of those under a microservices dogma would be two to four microservices struggling to interoperate.i read the book written by the dev that advocated for microservices. i wanted to throw it across the room but it was an ebook. he literally went for over half the book before he even addressed operability. everything was about developer convenience not operating it with an eye toward user satisfaction. the guy was clueless.;0
32006143;HackerNews;2022-07-06;i fully understand serverless billing which is why i told you its advantage scaling to 0 for functions you almost never use. but if you are running literally anything else you can get that advantage yourself run your serverless microservice as a library inside its caller. you don't need the overhead of an rpc to enforce separation of concerns.a small startup can pay 5month to run a monolith on a tiny server commensurate with its use. it can scale that monolith up with use from a 5 vm offering 1 core and a tiny bit of ram all the way to a twosocket server vm offering 110 cores and 512 gb of ram. alternatively a large company can scale nearly infinitely with horizontal scaling. when i worked on a service with a trillion qps and 50 usage swings at a megacorp that's what we did. all our customers even the ones with a measly 1 million qps did the same. and their customers and their customers and so on.serverless was something sold to fashionable tech startups and nontechnical people who didn't have the expertise to maintain the vmscontainers they needed. the serverless systems carried a huge price premium too. everyone with true scale understood that there are servers there and you are going to pay to manage them whether you want to or not.;0
32006070;HackerNews;2022-07-06;yeah i've seen stuff carved into tiny fragile microservices when the number of nodes was under ten. stupid imo and it took a stable service and made it a flaky mess. it was done because of dogmatic it must be in containers in the cloud with microservices because that is the waytm. literally there was an initiative to move ieverythingi possible to the cloud in containers with lots of microservices because one of the place's gurus got that religion. it increased complexity decreased reliability and cost a lot of money for not much benefit.until you have well over 20 systems doing one thingapplication trying to treat bespoke services like cattle instead of pets is silly. it will also drive your ops people to drink especially if it's done by devops that never get paged and refer to your group in meetings with other companies as just ops. yes i'm still salty about it.often i think it's resume driven development especially if the people pushing for it want to abandon all your existing tools and languages for whatever is hot currently.;0
32006062;HackerNews;2022-07-06;second comment after i had some time to think about itactually i think microservices serve as a tool for ienforcingi modularity. when pressure is high corners are cut and when unrelated code is easy to reach as in case of a monolithic codebase it's easy to fall into temptation a small dirty hack is faster than refactoring. and when you consider different maintainers it's easy to lose track of the original monolith architecture idea in all the dirty hacks.microservices enforce some kind of strict separation so in theory nobody can do anything that they're not supposed to. in practice a lot of coupling can happen at the microservices level the most common symptom being some weird isolated apis whose only purpose is to do that one thing that another service needs for some reason. those kind of adhoc dependencies tend to make services implementationspecific and noninterchangeable therefore breaking modularity.so in conclusion some approaches are easier to keep modular than others but there seems to be no silver bullet for replacing care and effort.;0
32005916;HackerNews;2022-07-06;if they won't have it then they're not microservices.the main premise is independent deployability. you need to be able to work on microservice independently of the rest deploy it independently it has to support partial rollouts ie. half of replicas on version x and half on version y rollbacks including partial rollbacks etc.you could stretch it in some kind of quasimodo to have separate schemas within single database for each microservice where each would be responsible for managing migrations of that schema and you'd employ some kind of policy of isolation. you pretty much wouldn't be able to use anything from other schemas as that would almost always violate those principles making the whole thing just unnecessary complexity at best. overall it would be a stretch and a weird one.of course it implies that before simple few liners in sql with transaction isolationatomicity now become phdlevellike complex distributed problems to solve with sagas two phase commits doundo actions complex error handling because comms can break at arbitrary places performance cam be a problem ordering of events you don't have immediate consistency anymore you have to switch to eventual consistency very likely have to do some form of event sourcing duplicate data in multiple places think about forward and backward compatibility a lot ie. on event schema taking care of apis and their compatibility contracts choosing well orchestration vs choreography etc.you want to employ those kind of techniques not for fun but because you simply have to you have no other choice ie. you have hundreds or thousands of developers scale at hundreds or thousands of servers etc.it's also worth mentioning that you can have independent deployability with servicesplatforms as well if they're conceptually distinct and have relatively low api surface they are potentially extractable you can form dedicated team around them etc.;0
32005786;HackerNews;2022-07-06;microservices move the complexity rather than solve it.the dependency boundaries between portions of the data model can never be cleanly demarcated because that's not how information works especially in a growing business so there's always going to be either some loss of flexibility or addition of complexity over time.individual developers getting out of each other's way just ends up getting pushed to getting in each other's way at release time as the matrix of dependencies between services explodes.engineers jobs become more about the lives and dramas of the services they work on than about business domain. you end up building your organization and reporting structure around these services rather than the business needs of the customer. and then you end up indirectly or directly shipping that org chart to the world in delays or bugs caused by your fragmentation.instead of modeling facts about data and their relationships and constructing the relational model which can capture this the developer in the microservice model becomes bogged down in service roles and activities instead again taking them away from the actual problem which is organizing information and making it accessible to userscustomers.it's a shell game.the facebook monolith works because engineers there invested time in ibuildingi the tooling you're complaining is not available to others. same with google google invested in f1 etc. because it evaluated the cost to do otherwise and it made sense to invest in infrastructure.yes small companies can't often afford this. luckily they have two things on their sidemost small companies don't have a fraction of the scale issues that a fb or a google have. so they can afford to monolith away for a lot longer than they seem to think they can while they put in infrastructure to scale the monolith.the industry as a whole has invested a lot in making existing things scale. e.g. you can do things with a single postgres instance that we never would have dreamed about 10 years ago. and when that falls over there's replication etc. and when that falls over guess what? there's now high performance distributed acid sql databases available for use.microservices is surely one of the longest lived biggest cargo cults in our industry. i've seen others come and go but microservices really seems to cling. i think because it has the iperceptioni of breaking business problems down into very small elegant independent atomic pieces so it has a very.. industrial revolution automation factory floor economies of scale vibe. but that's not what it is.there are places for it i'm sure. but systems with highly interelated data and quickly changing requirements are not well suited.imho.;0
32005374;HackerNews;2022-07-06;authenticationsso logging metrics persisted data stores ie. sql server caches ie. redis events workflows and few others are all well known understood isolated behaviors with good implementations that doesn't need to be embeddedreinvented it can and in many cases should run separately to your core services. it doesn't imply microservices in any way.;0
32005213;HackerNews;2022-07-06;i was once working with a guy that was hell bent on microservices.when our banking application became incompatible with logging due to his microservice design he really argued fought and sulked that logging wasn't important and we didn't need it.;0
32005105;HackerNews;2022-07-06;microservices are a heavy handed way to draw boundaries around your software so that bad technical decisions don't bleed across different teams. obviously there is some benefit to that but there is also a massive tradeoff especially for certain types of software like complex uis. with a monolith dependency updates especially breaking ones often mean either all development stops for a code freeze so the update can happen or you have a team responsible for doing the update and they are trying to update code faster than other devs add new code.in all my years i've never seen a code freeze due to a dependency update. maybe the project you were working was poorly engineered? the result of this is that updates get pushed back to the last minute or are never just done. i've seen old ancient versions of openssl checked into codebases way too often.there should be nothing stopping you from running multiple versions of a dependency within a single monolothic project. with microservices you can have a team that isn't as busy take a sprint to update their codebase carefully document best practices for fixing breaking changes document best practices for testing the changes and then spread the learning out to other teams who can then update as they have time or based on importance exposure of their maintained services.gradual adoption of new dependencies has nothing to do with microservices.;0
32005055;HackerNews;2022-07-06;typically monolith implies services ie the backing services from a traditional 12factor monolith monolith vs. microservices comes about because microservices proponents specifically set it up as an alternative to a traditional monolith services stack;0
32005006;HackerNews;2022-07-06;fb doesn't have those problems because they use different tools.exactly instead of using microserviceoriented tools they use tools organized around monoliths. and that decision serves them well. ithat's the whole point.i;0
32005000;HackerNews;2022-07-06;yes not sure why we have so many brainwashed fanatics who see world as hotdog and nothotdog microservices and monoliths only.;0
32004235;HackerNews;2022-07-06;one awesome and often overlooked benefit of microservices is how they simplify securitydependency updates.with a monolith dependency updates especially breaking ones often mean either all development stops for a code freeze so the update can happen or you have a team responsible for doing the update and they are trying to update code faster than other devs add new code.the result of this is that updates get pushed back to the last minute or are never just done. i've seen old ancient versions of openssl checked into codebases way too often.with microservices you can have a team that isn't as busy take a sprint to update their codebase carefully document best practices for fixing breaking changes document best practices for testing the changes and then spread the learning out to other teams who can then update as they have time or based on importance exposure of their maintained services.it is a much better way of doing things.it also means some teams can experiment with different technologies or tool chains and see how things work out. the cost of failure is low and there isn't an impact to other teams and build systems for microservices tend to be much simpler than for monoliths understatement...;0
32003795;HackerNews;2022-07-06;re copy massive companies i don't recall seeing a single microservice at google. granted in the 10 years i was there i mostly worked on noncloud type stuff. but still.google has perfected the art of the giant distributed horizontally scalable mostlyrelational database. they have iservicesi yes. but in large part... they generally all talk to f1 or similar.imicroservicesi with each thing having its own schema andor db seems to me to be a phenomenally stupid idea which will simply lead to abusing your relational model and doing dumb things like your own custom bespoke serverside joins with your own custom bespoke two phase commit or other transaction logic.before google i worked in one shop that did 'microservices' and the release process was a complicated nightmare that would have been better solved by a complicated combinatorial graph optimization library. there were cross service rpcish calls made all over the place to piece data together that in a more monolithic system would be resolved by a simple fast relational join. i shudder to remember it.but i'm just an old man. pay no heed.;0
32003524;HackerNews;2022-07-06;5 years ago this was very much true but with serverless services it drastically lowered the cost of overhead.it is more work but the goal is always to move away from monolith and to reap the benefits.we are past the backbone.js phase of microservices from jquery phase into react phase. an established standard with dividends that pay later is being realized.i just no longer follow these microservice bashing tropes in 2022 a lot has changed since that netflix diagram went viral;0
32003495;HackerNews;2022-07-06;it is not fair to compare the facebooks monolith and the monolith at the average company as they are not really the same thing. the tooling available at facebook is built and maintained by a team larger than the engineering departments at most companies.there comes a point where regular off the shelf tooling does not scale sufficiently well for a monolith. tests suits and builds start to take too long. deployments get increasingly complicated. developers start to get into each other's way even when working on unrelated features. additionally if you are using an untyped interpreted language keeping a large app well organized can also be a problem.microservices is a tool for dealing with complexity and certainly not the only one. however building the tooling and infra for a large and sophisticated monolith is not simple and not guaranteed to be an easier solution to the problems listed above.;0
32003329;HackerNews;2022-07-06;a lot of those steps just seem like good engineering. agreed. i always wonder why people think that their inability to write libraries with good modularization will be solved by introducing microservices.;0
32003298;HackerNews;2022-07-06;in the context of microservices 'micro' means that the service itself is small. thus each service performs a 'micro' and preferably independent task. it is the opposite of a monolith which you could call a 'macro' service.the system as a whole whether it being monolith or microservices still requires a dedicated team to maintain. switching to microservices will not magically remove the team requirement. in fact splitting a monolith into smaller services creates overhead so you'll probably end up with a larger team then what you'd have to maintain a monolith.;0
32003015;HackerNews;2022-07-06;fundamental problem is cargo cult developers trying to copy massive companies architectures as a startup. they fail to realize those companies only moved to microservices because they had no other option. lots of startups hurting themselves by blindly following these practices without knowing why they were created in the first place. some of it is also done by people who know it isn't good for the company but they want to pad their resume and leave before the consequences are seen.same thing applies to leetcode style interviews no startup should be using them honestly. they are for established companies that have so many quality applicants they can afford to filter out great candidates;0
32002943;HackerNews;2022-07-06;and best of luck to anyone attempting to extract authorization to a microservice in a way that doesn't create new problems.;0
32002931;HackerNews;2022-07-06;isolated datastores is really the thing that differentiates microservice architecture datastores meant in the most broad sense possible queues caches rdbmss nosql catalogs s3 buckets whatever.if you share a datastore across multiple services you have a serviceoriented architecture but it is not a microservice architecture.note that i'm saying this without any judgement as to the validity of either architectural choice just making a definitional point. a nonmicroservice architecture might be valid for your usecase but there is no such thing as 'microservices with a shared database'.it's like if you're making a cupcake recipe saying 'but does each cake actually need its own tin? i was planning on just putting all the batter in one large caketin'.it's fine that's a perfectly valid way to make a cake but... you're not making cupcakes any more.;0
32002910;HackerNews;2022-07-06;why microservices called micro? when it's almost implied it requires a dedicated team to develop and maintain? looks it's like soa but with json and k8s.;0
32002749;HackerNews;2022-07-06;i like microservices owning their databases. it allows you to choose the correct database for the job and for the team. sharing state across these microservices is often a bad sign for how youve split your services. often a simple orchestrator can aggregate the relevant data that it needs.;0
32002507;HackerNews;2022-07-06;looks like microservices became a selfgoal. however author can be praised buy giving a context implicit of a huge team which should be split.;0
32002438;HackerNews;2022-07-06;you can actually use microservices to reduce the complexity of a monolith.one example which i built just for this purpose is barricade which extracts authentication out of your app and into a container.;0
32002388;HackerNews;2022-07-06;i'm agreeing with your other other replies but with one caveat. each service needs its own isolated place to store data. this programming and integration layer concern is very important. what's less important is having those data stores physically isolated from each other which becomes a performance and cost concern. if your database has the ability to isolate schemas namespaces then you can share the physical db as long as the data is only used by a single service. i've seen a lot of microservices laid out with different writeread side concerns. these are often due to scaling concerns as readside and writeside often have very different scaling needs. this causes data coupling between these two services but they together form the facade of a single purpose service like any single microservices for outside parties.additionally you can probably get by having low criticality reports fed through direct db access as well. if you can afford to have them broken after an update for a time it's probably easier than needing to run queries through the api.;0
32002315;HackerNews;2022-07-06;enjoyed the article and found 11 and 12 to be almost a requirement for most teams.i've worked for an org that adopted microservices when it's small size didn't justify it but eventually found its footing with good containerization k8s from a growing devops team. individual teams were able to eventually deploy and release to various environments independently test on qa environments easily.and i now work for an org with a monorepo with 100 developers that probably should have been broken up into microservices a while ago. everything just feels broken and we're constantly running around wondering who broke what build when. we have like 6 sres for a team of 100 devs? i think a lot depends on how well cicd is developed and the devopssre team.;0
32002117;HackerNews;2022-07-06;agreed but i'll go a step further and say microservices are really valuable when you have products that are powered through a reasonable devops and cicd support within and organization. if you're a company that only releases quarterly a monolith probably makes sense. if you're a company releasing changes daily hourly monoliths make progressively less sense and become progressively harder to work with. when we release software a lot our downtime slo is generally zero minutes. if you're a well out together outfit with strict discipline this can be achieved with microservices.inversely monoliths almost never have to deal with multiple components at different release levels so they don't do a particularly good job to support it which is why you often see hours long upgrade windows for monoliths. shut everything down deploy updates start everything back up and hope the house is still working plus the changes.;0
32002074;HackerNews;2022-07-06;here's a e from discussed here on hn a while ago which seems very appropriate microservices grug wonder why big brain take hardest problem factoring system correctly and introduce network call too. seem very confusing to grug;0
32001988;HackerNews;2022-07-06;yes you need it. imagine having to make a change to the db for one service. you'll have to coordinate between all microservices using that db.;0
32001944;HackerNews;2022-07-06;does each microservice really need its own database? i have recently proposed my team initially inoti do this and i'm wondering if i am creating a huge problem.;0
32001869;HackerNews;2022-07-06;kinda reminds me of how you need to have a horizontally scaling database setup because 1 million rows a day are impossible to handle via a normal database serverpeople really underestimate the power that vertical scaling can achieve along with the long tail that microservices can bring. the more calls between services you need to handle x the more likely it is that you get into a case where one call takes exceptionally long;0
32001815;HackerNews;2022-07-06;often times folks are using microservices to achieve good modularity at a cost.and even more often folks use microservices but make them so coupled that you can't really runtesthack one without running all the others... basically creating a distributed monolith.;0
32001804;HackerNews;2022-07-06;right. i feel like it's a better article without any reference to microservices.;0
32001723;HackerNews;2022-07-06;i personally prefer modular monoliths over microservices though in all but very few cases.couldn't agree more. often times folks are using microservices to achieve good modularity at a cost.;0
32001261;HackerNews;2022-07-06;a lot of those steps just seem like good engineering. i personally prefer modular monoliths over microservices though in all but very few cases.;0
